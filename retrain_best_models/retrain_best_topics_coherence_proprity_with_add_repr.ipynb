{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"16rPidZMyOaYcykI9zB0Ul0phx9suxIvz","timestamp":1730562240174}],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyNoRpOTbMX5MKNjCDwb5EIt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# ==============================\n","# 1. Setup and Installation\n","# ==============================\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Check CUDA and driver versions\n","!nvcc --version  # Check CUDA version\n","!nvidia-smi      # Check driver version\n","\n","# Install RAPIDS and other required libraries\n","!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n","!python rapidsai-csp-utils/colab/pip-install.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"9OivEorQmNym","executionInfo":{"status":"ok","timestamp":1730585645815,"user_tz":-60,"elapsed":141916,"user":{"displayName":"Polina Bakhturina","userId":"07881954271877753559"}},"outputId":"08446e2e-80e7-4339-c483-36f9640262f8"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n","Sat Nov  2 22:12:04 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   39C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n","Cloning into 'rapidsai-csp-utils'...\n","remote: Enumerating objects: 535, done.\u001b[K\n","remote: Counting objects: 100% (266/266), done.\u001b[K\n","remote: Compressing objects: 100% (172/172), done.\u001b[K\n","remote: Total 535 (delta 174), reused 130 (delta 94), pack-reused 269 (from 1)\u001b[K\n","Receiving objects: 100% (535/535), 172.47 KiB | 19.16 MiB/s, done.\n","Resolving deltas: 100% (276/276), done.\n","Collecting pynvml\n","  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n","Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 5.6 MB/s eta 0:00:00\n","Installing collected packages: pynvml\n","Successfully installed pynvml-11.5.3\n","Installing RAPIDS remaining 24.10.* libraries\n","Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n","Requirement already satisfied: cudf-cu12==24.10.* in /usr/local/lib/python3.10/dist-packages (24.10.1)\n","Collecting cuml-cu12==24.10.*\n","  Downloading https://pypi.nvidia.com/cuml-cu12/cuml_cu12-24.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (567.7 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 567.7/567.7 MB 2.6 MB/s eta 0:00:00\n","Collecting cugraph-cu12==24.10.*\n","  Downloading https://pypi.nvidia.com/cugraph-cu12/cugraph_cu12-24.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (1315.2 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 GB 1.5 MB/s eta 0:00:00\n","Collecting cuspatial-cu12==24.10.*\n","  Downloading https://pypi.nvidia.com/cuspatial-cu12/cuspatial_cu12-24.10.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (4.3 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.3/4.3 MB 112.7 MB/s eta 0:00:00\n","Collecting cuproj-cu12==24.10.*\n","  Downloading https://pypi.nvidia.com/cuproj-cu12/cuproj_cu12-24.10.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (915 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 915.5/915.5 kB 62.7 MB/s eta 0:00:00\n","Collecting cuxfilter-cu12==24.10.*\n","  Downloading https://pypi.nvidia.com/cuxfilter-cu12/cuxfilter_cu12-24.10.0-py3-none-any.whl (83 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.6/83.6 kB 9.7 MB/s eta 0:00:00\n","Collecting cucim-cu12==24.10.*\n","  Downloading https://pypi.nvidia.com/cucim-cu12/cucim_cu12-24.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.6 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 123.9 MB/s eta 0:00:00\n","Requirement already satisfied: pylibraft-cu12==24.10.* in /usr/local/lib/python3.10/dist-packages (24.10.0)\n","Collecting raft-dask-cu12==24.10.*\n","  Downloading https://pypi.nvidia.com/raft-dask-cu12/raft_dask_cu12-24.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (196.9 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.9/196.9 MB 6.1 MB/s eta 0:00:00\n","Requirement already satisfied: nx-cugraph-cu12==24.10.* in /usr/local/lib/python3.10/dist-packages (24.10.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.10.10)\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (5.5.0)\n","Requirement already satisfied: cuda-python<13.0a0,>=12.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (12.2.1)\n","Requirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (12.2.0)\n","Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (2024.10.0)\n","Requirement already satisfied: libcudf-cu12==24.10.* in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (24.10.1)\n","Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (0.60.0)\n","Requirement already satisfied: numpy<3.0a0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (1.26.4)\n","Requirement already satisfied: nvtx>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (0.2.10)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (24.1)\n","Requirement already satisfied: pandas<2.2.3dev0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (2.2.2)\n","Requirement already satisfied: pyarrow<18.0.0a0,>=14.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (17.0.0)\n","Requirement already satisfied: pylibcudf-cu12==24.10.* in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (24.10.1)\n","Requirement already satisfied: pynvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (0.4.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (13.9.3)\n","Requirement already satisfied: rmm-cu12==24.10.* in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (24.10.0)\n","Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (4.12.2)\n","Collecting cuvs-cu12==24.10.* (from cuml-cu12==24.10.*)\n","  Downloading https://pypi.nvidia.com/cuvs-cu12/cuvs_cu12-24.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (836.6 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 836.6/836.6 MB 1.9 MB/s eta 0:00:00\n","Collecting dask-cuda==24.10.* (from cuml-cu12==24.10.*)\n","  Downloading https://pypi.nvidia.com/dask-cuda/dask_cuda-24.10.0-py3-none-any.whl (133 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.2/133.2 kB 14.1 MB/s eta 0:00:00\n","Collecting dask-cudf-cu12==24.10.* (from cuml-cu12==24.10.*)\n","  Downloading https://pypi.nvidia.com/dask-cudf-cu12/dask_cudf_cu12-24.10.1-py3-none-any.whl (56 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 kB 5.9 MB/s eta 0:00:00\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.10.*) (1.4.2)\n","Requirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.10.*) (12.6.3.3)\n","Requirement already satisfied: nvidia-cufft-cu12 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.10.*) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.10.*) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.10.*) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.10.*) (12.5.4.2)\n","Collecting rapids-dask-dependency==24.10.* (from cuml-cu12==24.10.*)\n","  Downloading https://pypi.nvidia.com/rapids-dask-dependency/rapids_dask_dependency-24.10.0-py3-none-any.whl (15 kB)\n","Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.10.*) (1.13.1)\n","Collecting treelite==4.3.0 (from cuml-cu12==24.10.*)\n","  Downloading treelite-4.3.0-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: pylibcugraph-cu12==24.10.* in /usr/local/lib/python3.10/dist-packages (from cugraph-cu12==24.10.*) (24.10.0)\n","Collecting ucx-py-cu12==0.40.* (from cugraph-cu12==24.10.*)\n","  Downloading https://pypi.nvidia.com/ucx-py-cu12/ucx_py_cu12-0.40.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.1 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 89.7 MB/s eta 0:00:00\n","Requirement already satisfied: geopandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from cuspatial-cu12==24.10.*) (1.0.1)\n","Collecting libcuspatial-cu12==24.10.* (from cuspatial-cu12==24.10.*)\n","  Downloading https://pypi.nvidia.com/libcuspatial-cu12/libcuspatial_cu12-24.10.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (17.7 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.7/17.7 MB 107.4 MB/s eta 0:00:00\n","Requirement already satisfied: bokeh>=3.1 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.10.*) (3.4.3)\n","Collecting datashader>=0.15 (from cuxfilter-cu12==24.10.*)\n","  Downloading datashader-0.16.3-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: holoviews>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.10.*) (1.19.1)\n","Collecting jupyter-server-proxy (from cuxfilter-cu12==24.10.*)\n","  Downloading jupyter_server_proxy-4.4.0-py3-none-any.whl.metadata (8.7 kB)\n","Requirement already satisfied: panel>=1.0 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.10.*) (1.4.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.10.*) (8.1.7)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.10.*) (0.4)\n","Requirement already satisfied: scikit-image<0.25.0a0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.10.*) (0.24.0)\n","Collecting distributed-ucxx-cu12==0.40.* (from raft-dask-cu12==24.10.*)\n","  Downloading https://pypi.nvidia.com/distributed-ucxx-cu12/distributed_ucxx_cu12-0.40.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from nx-cugraph-cu12==24.10.*) (3.4.2)\n","Collecting pynvml<11.5,>=11.0.0 (from dask-cuda==24.10.*->cuml-cu12==24.10.*)\n","  Downloading pynvml-11.4.1-py3-none-any.whl.metadata (7.7 kB)\n","Collecting zict>=2.0.0 (from dask-cuda==24.10.*->cuml-cu12==24.10.*)\n","  Downloading zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\n","Collecting ucxx-cu12==0.40.* (from distributed-ucxx-cu12==0.40.*->raft-dask-cu12==24.10.*)\n","  Downloading https://pypi.nvidia.com/ucxx-cu12/ucxx_cu12-0.40.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (722 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 722.7/722.7 kB 48.2 MB/s eta 0:00:00\n","Collecting dask==2024.9.0 (from rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*)\n","  Downloading dask-2024.9.0-py3-none-any.whl.metadata (3.7 kB)\n","Collecting distributed==2024.9.0 (from rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*)\n","  Downloading distributed-2024.9.0-py3-none-any.whl.metadata (3.3 kB)\n","Collecting dask-expr==1.1.14 (from rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*)\n","  Downloading dask_expr-1.1.14-py3-none-any.whl.metadata (2.5 kB)\n","Collecting libucx-cu12<1.18,>=1.15.0 (from ucx-py-cu12==0.40.*->cugraph-cu12==24.10.*)\n","  Downloading libucx_cu12-1.17.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.9 kB)\n","Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (3.1.0)\n","Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (1.4.2)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (6.0.2)\n","Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (0.12.1)\n","Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (8.5.0)\n","Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (3.1.4)\n","Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (1.0.0)\n","Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (1.1.0)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (5.9.5)\n","Collecting sortedcontainers>=2.0.5 (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*)\n","  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n","Collecting tblib>=1.6.0 (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*)\n","  Downloading tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (6.3.3)\n","Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (2.2.3)\n","Collecting libucxx-cu12==0.40.* (from ucxx-cu12==0.40.*->distributed-ucxx-cu12==0.40.*->raft-dask-cu12==24.10.*)\n","  Downloading https://pypi.nvidia.com/libucxx-cu12/libucxx_cu12-0.40.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (511 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 511.7/511.7 kB 39.4 MB/s eta 0:00:00\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.17.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (4.0.3)\n","Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.10.*) (1.3.0)\n","Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.10.*) (10.4.0)\n","Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.10.*) (2024.9.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from cuda-python<13.0a0,>=12.0->cudf-cu12==24.10.*) (3.0.11)\n","Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x>=12.0.0->cudf-cu12==24.10.*) (0.8.2)\n","Requirement already satisfied: colorcet in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.10.*) (3.1.0)\n","Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.10.*) (1.0.0)\n","Requirement already satisfied: param in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.10.*) (2.1.1)\n","Collecting pyct (from datashader>=0.15->cuxfilter-cu12==24.10.*)\n","  Downloading pyct-0.5.0-py2.py3-none-any.whl.metadata (7.4 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.10.*) (2.32.3)\n","Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.10.*) (2024.10.0)\n","Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from geopandas>=1.0.0->cuspatial-cu12==24.10.*) (0.10.0)\n","Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas>=1.0.0->cuspatial-cu12==24.10.*) (3.7.0)\n","Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from geopandas>=1.0.0->cuspatial-cu12==24.10.*) (2.0.6)\n","Requirement already satisfied: pyviz-comms>=2.1 in /usr/local/lib/python3.10/dist-packages (from holoviews>=1.16.0->cuxfilter-cu12==24.10.*) (3.0.3)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57->cudf-cu12==24.10.*) (0.43.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.3dev0,>=2.0->cudf-cu12==24.10.*) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.3dev0,>=2.0->cudf-cu12==24.10.*) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.3dev0,>=2.0->cudf-cu12==24.10.*) (2024.2)\n","Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.10.*) (3.7)\n","Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.10.*) (3.0.0)\n","Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.10.*) (2.0.3)\n","Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.10.*) (0.4.2)\n","Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.10.*) (4.66.6)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.10.*) (6.2.0)\n","Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.25.0a0,>=0.19.0->cucim-cu12==24.10.*) (2.36.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.25.0a0,>=0.19.0->cucim-cu12==24.10.*) (2024.9.20)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp) (3.10)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp) (0.2.0)\n","Requirement already satisfied: jupyter-server>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-proxy->cuxfilter-cu12==24.10.*) (1.24.0)\n","Collecting simpervisor>=1.0.0 (from jupyter-server-proxy->cuxfilter-cu12==24.10.*)\n","  Downloading simpervisor-1.0.0-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-proxy->cuxfilter-cu12==24.10.*) (5.7.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cufft-cu12->cuml-cu12==24.10.*) (12.6.77)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->cudf-cu12==24.10.*) (2.18.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (3.0.2)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (3.7.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (23.1.0)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (6.1.12)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (5.7.2)\n","Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (7.16.4)\n","Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (5.10.4)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.21.0)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (24.0.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.18.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (1.8.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.0->cuxfilter-cu12==24.10.*) (0.1.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyogrio>=0.7.2->geopandas>=1.0.0->cuspatial-cu12==24.10.*) (2024.8.30)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.2.3dev0,>=2.0->cudf-cu12==24.10.*) (1.16.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.0->cuxfilter-cu12==24.10.*) (0.5.1)\n","Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.0->cuxfilter-cu12==24.10.*) (1.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->datashader>=0.15->cuxfilter-cu12==24.10.*) (3.4.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (1.2.2)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (3.20.2)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (4.3.6)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (4.12.3)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (3.0.2)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.10.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (1.4.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (2.20.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (4.23.0)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.7.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (21.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.20.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (2.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (2.22)\n","Downloading treelite-4.3.0-py3-none-manylinux2014_x86_64.whl (915 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 916.0/916.0 kB 41.2 MB/s eta 0:00:00\n","Downloading dask-2024.9.0-py3-none-any.whl (1.3 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 64.2 MB/s eta 0:00:00\n","Downloading dask_expr-1.1.14-py3-none-any.whl (242 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 242.6/242.6 kB 21.7 MB/s eta 0:00:00\n","Downloading distributed-2024.9.0-py3-none-any.whl (1.0 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 60.7 MB/s eta 0:00:00\n","Downloading datashader-0.16.3-py2.py3-none-any.whl (18.3 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.3/18.3 MB 32.6 MB/s eta 0:00:00\n","Downloading jupyter_server_proxy-4.4.0-py3-none-any.whl (37 kB)\n","Downloading libucx_cu12-1.17.0-py3-none-manylinux_2_28_x86_64.whl (26.9 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.9/26.9 MB 47.8 MB/s eta 0:00:00\n","Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.0/47.0 kB 4.2 MB/s eta 0:00:00\n","Downloading simpervisor-1.0.0-py3-none-any.whl (8.3 kB)\n","Downloading zict-3.0.0-py2.py3-none-any.whl (43 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.3/43.3 kB 4.3 MB/s eta 0:00:00\n","Downloading pyct-0.5.0-py2.py3-none-any.whl (15 kB)\n","Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n","Downloading tblib-3.0.0-py3-none-any.whl (12 kB)\n","Installing collected packages: sortedcontainers, zict, tblib, simpervisor, pynvml, pyct, libucx-cu12, libcuspatial-cu12, ucx-py-cu12, treelite, libucxx-cu12, dask, cuproj-cu12, ucxx-cu12, distributed, dask-expr, cucim-cu12, rapids-dask-dependency, datashader, cuvs-cu12, distributed-ucxx-cu12, dask-cudf-cu12, dask-cuda, cuspatial-cu12, raft-dask-cu12, cuml-cu12, cugraph-cu12, jupyter-server-proxy, cuxfilter-cu12\n","  Attempting uninstall: pynvml\n","    Found existing installation: pynvml 11.5.3\n","    Uninstalling pynvml-11.5.3:\n","      Successfully uninstalled pynvml-11.5.3\n","  Attempting uninstall: dask\n","    Found existing installation: dask 2024.10.0\n","    Uninstalling dask-2024.10.0:\n","      Successfully uninstalled dask-2024.10.0\n","Successfully installed cucim-cu12-24.10.0 cugraph-cu12-24.10.0 cuml-cu12-24.10.0 cuproj-cu12-24.10.0 cuspatial-cu12-24.10.0 cuvs-cu12-24.10.0 cuxfilter-cu12-24.10.0 dask-2024.9.0 dask-cuda-24.10.0 dask-cudf-cu12-24.10.1 dask-expr-1.1.14 datashader-0.16.3 distributed-2024.9.0 distributed-ucxx-cu12-0.40.0 jupyter-server-proxy-4.4.0 libcuspatial-cu12-24.10.0 libucx-cu12-1.17.0 libucxx-cu12-0.40.0 pyct-0.5.0 pynvml-11.4.1 raft-dask-cu12-24.10.0 rapids-dask-dependency-24.10.0 simpervisor-1.0.0 sortedcontainers-2.4.0 tblib-3.0.0 treelite-4.3.0 ucx-py-cu12-0.40.0 ucxx-cu12-0.40.0 zict-3.0.0\n","\n","        ***********************************************************************\n","        The pip install of RAPIDS is complete.\n","        \n","        Please do not run any further installation from the conda based installation methods, as they may cause issues!\n","        \n","        Please ensure that you're pulling from the git repo to remain updated with the latest working install scripts.\n","\n","        Troubleshooting:\n","            - If there is an installation failure, please check back on RAPIDSAI owned templates/notebooks to see how to update your personal files. \n","            - If an installation failure persists when using the latest script, please make an issue on https://github.com/rapidsai-community/rapidsai-csp-utils\n","        ***********************************************************************\n","        \n"]}]},{"cell_type":"code","source":["## After restarting, install remaining necessary libraries\n","# Run this cell after restarting the runtime\n","!pip install bertopic==0.16.3\n","!pip install octis\n","!pip install sentence-transformers\n","!pip install umap-learn==0.5.3  # Specify a compatible version\n","!pip install hdbscan\n","!pip install tqdm\n","!pip install pandas\n","!pip install gensim\n","!pip install wandb\n","!pip install umap\n","!pip install scipy\n","!pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oco0mYO-p5BY","executionInfo":{"status":"ok","timestamp":1730585698427,"user_tz":-60,"elapsed":52625,"user":{"displayName":"Polina Bakhturina","userId":"07881954271877753559"}},"outputId":"9792acbe-6638-4d6a-fa03-964d42b828d6","collapsed":true},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bertopic==0.16.3\n","  Downloading bertopic-0.16.3-py3-none-any.whl.metadata (23 kB)\n","Collecting hdbscan>=0.8.29 (from bertopic==0.16.3)\n","  Downloading hdbscan-0.8.39-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic==0.16.3) (1.26.4)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic==0.16.3) (2.2.2)\n","Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic==0.16.3) (5.24.1)\n","Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic==0.16.3) (1.5.2)\n","Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from bertopic==0.16.3) (3.2.1)\n","Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic==0.16.3) (4.66.6)\n","Collecting umap-learn>=0.5.0 (from bertopic==0.16.3)\n","  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic==0.16.3) (1.13.1)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic==0.16.3) (1.4.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic==0.16.3) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic==0.16.3) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic==0.16.3) (2024.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic==0.16.3) (9.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic==0.16.3) (24.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic==0.16.3) (3.5.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic==0.16.3) (4.44.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic==0.16.3) (2.5.0+cu121)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic==0.16.3) (0.24.7)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic==0.16.3) (10.4.0)\n","Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic==0.16.3) (0.60.0)\n","Collecting pynndescent>=0.5 (from umap-learn>=0.5.0->bertopic==0.16.3)\n","  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (2024.10.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (4.12.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic==0.16.3) (0.43.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic==0.16.3) (1.16.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (0.19.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (2024.8.30)\n","Downloading bertopic-0.16.3-py3-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hdbscan-0.8.39-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pynndescent, hdbscan, umap-learn, bertopic\n","Successfully installed bertopic-0.16.3 hdbscan-0.8.39 pynndescent-0.5.13 umap-learn-0.5.7\n","Collecting octis\n","  Downloading octis-1.14.0-py2.py3-none-any.whl.metadata (27 kB)\n","Requirement already satisfied: gensim<5.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from octis) (4.3.3)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from octis) (3.8.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from octis) (2.2.2)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from octis) (3.7.5)\n","Collecting scikit-learn==1.1.0 (from octis)\n","  Downloading scikit_learn-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n","Collecting scikit-optimize>=0.8.1 (from octis)\n","  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from octis) (3.8.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from octis) (2.5.0+cu121)\n","Requirement already satisfied: numpy<2.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from octis) (1.26.4)\n","Collecting libsvm (from octis)\n","  Downloading libsvm-3.23.0.4.tar.gz (170 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.6/170.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from octis) (2.2.5)\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (from octis) (3.2.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from octis) (2.32.3)\n","Collecting tomotopy (from octis)\n","  Downloading tomotopy-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (30 kB)\n","Collecting scipy<1.13 (from octis)\n","  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.0->octis) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.0->octis) (3.5.0)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0,>=4.2.0->octis) (7.0.5)\n","Collecting pyaml>=16.9 (from scikit-optimize>=0.8.1->octis)\n","  Downloading pyaml-24.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize>=0.8.1->octis) (24.1)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->octis) (3.0.6)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask->octis) (3.1.4)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->octis) (2.2.0)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->octis) (8.1.7)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (1.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (2.8.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->octis) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->octis) (4.66.6)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->octis) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->octis) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->octis) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->octis) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->octis) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->octis) (2024.8.30)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->octis) (4.44.2)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->octis) (0.24.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->octis) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->octis) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->octis) (3.4.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->octis) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->octis) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->octis) (1.3.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (0.12.5)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (2.9.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (75.1.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (3.4.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers->octis) (6.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask->octis) (3.0.2)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->octis) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->octis) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->octis) (2.23.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->octis) (1.16.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim<5.0,>=4.2.0->octis) (1.16.0)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->octis) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->octis) (0.1.5)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->octis) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->octis) (0.19.1)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->octis) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->octis) (13.9.3)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->octis) (0.20.0)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->octis) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->octis) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->octis) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->octis) (0.1.2)\n","Downloading octis-1.14.0-py2.py3-none-any.whl (130 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_learn-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomotopy-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyaml-24.9.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: libsvm\n","  Building wheel for libsvm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for libsvm: filename=libsvm-3.23.0.4-cp310-cp310-linux_x86_64.whl size=251405 sha256=9b9f4830000e19a73a14a98aaf13a40525aa2f71c60aaff50ad701295deae79a\n","  Stored in directory: /root/.cache/pip/wheels/79/c7/19/a8c85928f8e629654b8e1adb3c8091f0bb77344d0ee9954a85\n","Successfully built libsvm\n","Installing collected packages: tomotopy, scipy, pyaml, libsvm, scikit-learn, scikit-optimize, octis\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.13.1\n","    Uninstalling scipy-1.13.1:\n","      Successfully uninstalled scipy-1.13.1\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.5.2\n","    Uninstalling scikit-learn-1.5.2:\n","      Successfully uninstalled scikit-learn-1.5.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","bigframes 1.25.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed libsvm-3.23.0.4 octis-1.14.0 pyaml-24.9.0 scikit-learn-1.1.0 scikit-optimize-0.10.2 scipy-1.12.0 tomotopy-0.13.0\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.0+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.1.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.12.0)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n","Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n","Collecting umap-learn==0.5.3\n","  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.3) (1.26.4)\n","Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.3) (1.1.0)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.3) (1.12.0)\n","Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.3) (0.60.0)\n","Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.3) (0.5.13)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.3) (4.66.6)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn==0.5.3) (0.43.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn==0.5.3) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn==0.5.3) (3.5.0)\n","Building wheels for collected packages: umap-learn\n","  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82808 sha256=cc27c34a3dcaf9f843867c5806a3eed07fce36606f7aef531fcf42ede0b79a05\n","  Stored in directory: /root/.cache/pip/wheels/a0/e8/c6/a37ea663620bd5200ea1ba0907ab3c217042c1d035ef606acc\n","Successfully built umap-learn\n","Installing collected packages: umap-learn\n","  Attempting uninstall: umap-learn\n","    Found existing installation: umap-learn 0.5.7\n","    Uninstalling umap-learn-0.5.7:\n","      Successfully uninstalled umap-learn-0.5.7\n","Successfully installed umap-learn-0.5.3\n","Requirement already satisfied: hdbscan in /usr/local/lib/python3.10/dist-packages (0.8.39)\n","Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from hdbscan) (1.26.4)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan) (1.12.0)\n","Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.10/dist-packages (from hdbscan) (1.1.0)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->hdbscan) (3.5.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n","Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n","Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.12.0)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.5)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.17.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n","Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","Collecting umap\n","  Downloading umap-0.1.1.tar.gz (3.2 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: umap\n","  Building wheel for umap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap: filename=umap-0.1.1-py3-none-any.whl size=3542 sha256=e066c5a97f3d9302973be7b48536d3ec3821ee3ee66fc6ef0033042bcee63971\n","  Stored in directory: /root/.cache/pip/wheels/15/f1/28/53dcf7a309118ed35d810a5f9cb995217800f3f269ab5771cb\n","Successfully built umap\n","Installing collected packages: umap\n","Successfully installed umap-0.1.1\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.12.0)\n","Requirement already satisfied: numpy<1.29.0,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.4)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"]}]},{"cell_type":"code","source":["# =====================================\n","# 1. Import Libraries\n","# =====================================\n","\n","import os\n","import time\n","import logging\n","import pandas as pd\n","import numpy as np\n","import re\n","from datetime import datetime\n","import torch\n","import gc\n","from tqdm import tqdm\n","from bertopic import BERTopic\n","from sentence_transformers import SentenceTransformer\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Import RAPIDS' UMAP and HDBSCAN\n","from cuml.manifold import UMAP  # GPU-accelerated UMAP\n","from cuml.cluster import HDBSCAN  # GPU-accelerated HDBSCAN\n","import cupy as cp  # For GPU arrays\n","\n","# Import NLTK modules for text processing\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","# Import BERTopic's representation models\n","from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, PartOfSpeech\n","\n","# Import json module\n","import json\n","\n","# Import string module for punctuation handling\n","import string\n","\n","# =====================================\n","# 2. Configure Logging\n","# =====================================\n","\n","# Define logging configuration\n","LOG_FILENAME = '/content/drive/MyDrive/bertopic_training.log'\n","\n","# Create a custom logger\n","logger = logging.getLogger('BERTopic_Training')\n","logger.setLevel(logging.DEBUG)  # Set to DEBUG to capture all levels of logs\n","\n","# Prevent adding multiple handlers in environments like Google Colab\n","if not logger.handlers:\n","    # Create handlers\n","    c_handler = logging.StreamHandler()\n","    f_handler = logging.FileHandler(LOG_FILENAME)\n","    c_handler.setLevel(logging.INFO)  # Console handler set to INFO\n","    f_handler.setLevel(logging.DEBUG)  # File handler set to DEBUG\n","\n","    # Create formatters and add them to handlers\n","    c_format = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s',\n","                                 datefmt='%Y-%m-%d %H:%M:%S')\n","    f_format = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s',\n","                                 datefmt='%Y-%m-%d %H:%M:%S')\n","    c_handler.setFormatter(c_format)\n","    f_handler.setFormatter(f_format)\n","\n","    # Add handlers to the logger\n","    logger.addHandler(c_handler)\n","    logger.addHandler(f_handler)\n","\n","# =====================================\n","# 3. Define Paths and Load Stop Words\n","# =====================================\n","\n","# Define the paths for datasets, models, and resources\n","dataset_path = '/content/drive/MyDrive/processed_novels_sentences_new.csv'\n","additional_stop_words_characters_names = '/content/drive/MyDrive/character_names.txt'\n","\n","def preprocess_stopwords(stopwords_file_path):\n","    \"\"\"\n","    Preprocess the stop words list by lowercasing, removing punctuation, and splitting multi-word entries.\n","\n","    Args:\n","        stopwords_file_path (str): Path to the stop words text file.\n","\n","    Returns:\n","        set: A set of preprocessed stop words.\n","    \"\"\"\n","    try:\n","        with open(stopwords_file_path, 'r', encoding='utf-8') as file:\n","            raw_stop_words = file.read().splitlines()\n","\n","        # Initialize a set to store processed stop words\n","        processed_stop_words = set()\n","\n","        # Define a translation table to remove punctuation\n","        translator = str.maketrans('', '', string.punctuation)\n","\n","        for stop_word in raw_stop_words:\n","            # Lowercase the stop word\n","            stop_word = stop_word.lower()\n","            # Remove punctuation\n","            stop_word = stop_word.translate(translator)\n","            # Split into individual words if it's a multi-word stop word\n","            words = stop_word.split()\n","            for word in words:\n","                if word:  # Ensure the word is not empty\n","                    processed_stop_words.add(word)\n","\n","        logger.info(f\"Processed stop words count: {len(processed_stop_words)}\")\n","        return processed_stop_words\n","\n","    except Exception as e:\n","        logger.error(f\"Error processing stop words: {e}\")\n","        return set(stopwords.words('english'))  # Fallback to NLTK's stop words\n","\n","# 1. Load additional stop words (character names) and standard English stop words\n","logger.info(\"Loading and preprocessing additional stop words...\")\n","custom_stop_words = preprocess_stopwords(additional_stop_words_characters_names)\n","\n","# Combine with NLTK's stop words\n","stop_words = set(stopwords.words('english'))\n","stop_words.update(custom_stop_words)\n","logger.info(f\"Total stop words after preprocessing: {len(stop_words)}\")\n","\n","# =====================================\n","# 4. Load and Preprocess the Dataset\n","# =====================================\n","\n","def load_dataset(path, stop_words, test_mode=False, sample_size=10000, chunksize=None):\n","    \"\"\"\n","    Load and preprocess the dataset.\n","\n","    Args:\n","        path (str): Path to the dataset CSV file.\n","        stop_words (set): Set of stop words to remove.\n","        test_mode (bool): If True, use a subset of the dataset for testing.\n","        sample_size (int): Number of sentences to sample if test_mode is True.\n","        chunksize (int, optional): If specified, read the CSV in chunks of this size.\n","\n","    Returns:\n","        list: A list of raw, preprocessed sentences.\n","    \"\"\"\n","    logger.info(\"Loading and preprocessing dataset...\")\n","    start_time = time.time()\n","\n","    try:\n","        if test_mode:\n","            logger.info(f\"Test mode enabled. Sampling {sample_size} sentences from the dataset.\")\n","            if chunksize is None:\n","                chunksize = 1000  # Set a default chunksize\n","            df_iter = pd.read_csv(path, chunksize=chunksize)\n","            sampled_chunks = []\n","            total_sampled = 0\n","            for chunk in df_iter:\n","                remaining = sample_size - total_sampled\n","                if remaining <= 0:\n","                    break\n","                n_samples = min(remaining, len(chunk))\n","                sampled = chunk.sample(n=n_samples, random_state=42)\n","                sampled_chunks.append(sampled)\n","                total_sampled += n_samples\n","            df = pd.concat(sampled_chunks) if sampled_chunks else pd.DataFrame()\n","            logger.info(f\"Sampled {len(df)} sentences.\")\n","        else:\n","            # Read the entire CSV file\n","            df = pd.read_csv(path)\n","            logger.info(f\"Dataset loaded. Total sentences: {len(df)}\")\n","\n","        # Preprocess the sentences: remove newlines, extra spaces, convert to lowercase\n","        logger.debug(\"Removing newline characters and extra spaces, converting to lowercase...\")\n","        df['Sentence'] = df['Sentence'].astype(str).apply(lambda x: re.sub(r'\\n+', ' ', x))\n","        df['Sentence'] = df['Sentence'].str.replace(r'\\s+', ' ', regex=True).str.strip().str.lower()\n","\n","        # Tokenize sentences and remove stop words\n","        logger.debug(\"Tokenizing sentences and removing stop words...\")\n","        processed_docs = []\n","        for sentence in df['Sentence']:\n","            tokens = word_tokenize(sentence)\n","            # Keep only alphabetic tokens and remove stop words\n","            tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n","            processed_sentence = ' '.join(tokens)  # Join tokens back into string\n","            processed_docs.append(processed_sentence)\n","\n","        # Additional Data Quality Checks\n","        logger.debug(\"Performing additional data quality checks...\")\n","        sentence_lengths = [len(sentence.split()) for sentence in processed_docs]\n","        average_length = np.mean(sentence_lengths)\n","        min_length = np.min(sentence_lengths)\n","        max_length = np.max(sentence_lengths)\n","        logger.info(f\"Average sentence length: {average_length:.2f}\")\n","        logger.info(f\"Minimum sentence length: {min_length}\")\n","        logger.info(f\"Maximum sentence length: {max_length}\")\n","\n","        # Optionally, filter out sentences with too few words\n","        corpus_filtered = [sentence for sentence in processed_docs if len(sentence.split()) >= 3]  # Adjust as needed\n","        logger.info(f\"Filtered corpus size: {len(corpus_filtered)} out of {len(processed_docs)}\")\n","\n","        logger.info(f\"Dataset loaded and preprocessed. Total sentences: {len(corpus_filtered)}\")\n","        logger.info(f\"Time taken for loading and preprocessing: {time.time() - start_time:.2f} seconds\")\n","        return corpus_filtered\n","\n","    except Exception as e:\n","        logger.error(f\"Failed to load and preprocess dataset: {e}\")\n","        return []\n","\n","# Set TEST_MODE to True for initial testing with a subset of the dataset\n","TEST_MODE = False  # Change to False to process the entire dataset\n","SAMPLE_SIZE = 10000  # Number of sentences to sample if TEST_MODE is True\n","\n","# Load and preprocess the dataset\n","logger.info(\"Starting data loading and preprocessing...\")\n","corpus = load_dataset(\n","    path=dataset_path,\n","    stop_words=stop_words,\n","    test_mode=TEST_MODE,\n","    sample_size=SAMPLE_SIZE\n","    # chunksize is set internally when test_mode=True\n",")\n","if not corpus:\n","    logger.error(\"No data to train on. Exiting.\")\n","    raise SystemExit\n","logger.info(\"Data loading and preprocessing completed.\")\n","\n","# =====================================\n","# 5. Create Parameters DataFrame\n","# =====================================\n","\n","def create_dataframe():\n","    \"\"\"\n","    Create the dataframe containing model parameters.\n","\n","    Returns:\n","        pd.DataFrame: The dataframe with model parameters.\n","    \"\"\"\n","    logger.info(\"Creating dataframe with model parameters...\")\n","    # Define the data as a list of dictionaries to handle each embedding model\n","    data = []\n","\n","    # Define your models and their parameters\n","    models = [\n","        {\n","            'Embeddings_Model': 'all-MiniLM-L12-v2',\n","            'Iteration': 66,\n","            'Coherence': 0.577551,\n","            'Topic_Diversity': 0.45,\n","            'bertopic__min_topic_size': 102,\n","            'bertopic__top_n_words': 30,\n","            'hdbscan__min_cluster_size': 281,\n","            'hdbscan__min_samples': 72,\n","            'umap__min_dist': 0.005022,\n","            'umap__n_components': 2,\n","            'umap__n_neighbors': 7,\n","            'vectorizer__min_df': 0.001504\n","        },\n","        {\n","            'Embeddings_Model': 'paraphrase-mpnet-base-v2',\n","            'Iteration': 14,\n","            'Coherence': 0.469187,\n","            'Topic_Diversity': 0.8,\n","            'bertopic__min_topic_size': 63,\n","            'bertopic__top_n_words': 22,\n","            'hdbscan__min_cluster_size': 500,\n","            'hdbscan__min_samples': 72,\n","            'umap__min_dist': 0.077818,\n","            'umap__n_components': 9,\n","            'umap__n_neighbors': 11,\n","            'vectorizer__min_df': 0.009372\n","        },\n","        {\n","            'Embeddings_Model': 'all-MiniLM-L12-v2',\n","            'Iteration': 75,\n","            'Coherence': 0.543105,\n","            'Topic_Diversity': 0.466667,\n","            'bertopic__min_topic_size': 142,\n","            'bertopic__top_n_words': 10,\n","            'hdbscan__min_cluster_size': 473,\n","            'hdbscan__min_samples': 14,\n","            'umap__min_dist': 0.004634,\n","            'umap__n_components': 5,\n","            'umap__n_neighbors': 15,\n","            'vectorizer__min_df': 0.001947\n","        },\n","        {\n","            'Embeddings_Model': 'paraphrase-mpnet-base-v2',\n","            'Iteration': 0,\n","            'Coherence': 0.463245,\n","            'Topic_Diversity': 0.82,\n","            'bertopic__min_topic_size': 127,\n","            'bertopic__top_n_words': 31,\n","            'hdbscan__min_cluster_size': 494,\n","            'hdbscan__min_samples': 28,\n","            'umap__min_dist': 0.058341,\n","            'umap__n_components': 10,\n","            'umap__n_neighbors': 11,\n","            'vectorizer__min_df': 0.007313\n","        },\n","        {\n","            'Embeddings_Model': 'paraphrase-MiniLM-L6-v2',\n","            'Iteration': 19,\n","            'Coherence': 0.425237,\n","            'Topic_Diversity': 0.94,\n","            'bertopic__min_topic_size': 64,\n","            'bertopic__top_n_words': 27,\n","            'hdbscan__min_cluster_size': 143,\n","            'hdbscan__min_samples': 32,\n","            'umap__min_dist': 0.085702,\n","            'umap__n_components': 9,\n","            'umap__n_neighbors': 44,\n","            'vectorizer__min_df': 0.005932\n","        },\n","        {\n","            'Embeddings_Model': 'paraphrase-mpnet-base-v2',\n","            'Iteration': 13,\n","            'Coherence': 0.452912,\n","            'Topic_Diversity': 0.8,\n","            'bertopic__min_topic_size': 14,\n","            'bertopic__top_n_words': 18,\n","            'hdbscan__min_cluster_size': 497,\n","            'hdbscan__min_samples': 32,\n","            'umap__min_dist': 0.086975,\n","            'umap__n_components': 8,\n","            'umap__n_neighbors': 9,\n","            'vectorizer__min_df': 0.009857\n","        },\n","        {\n","            'Embeddings_Model': 'multi-qa-mpnet-base-cos-v1',\n","            'Iteration': 23,\n","            'Coherence': 0.430575,\n","            'Topic_Diversity': 0.797059,\n","            'bertopic__min_topic_size': 28,\n","            'bertopic__top_n_words': 28,\n","            'hdbscan__min_cluster_size': 492,\n","            'hdbscan__min_samples': 12,\n","            'umap__min_dist': 0.095922,\n","            'umap__n_components': 9,\n","            'umap__n_neighbors': 19,\n","            'vectorizer__min_df': 0.008294\n","        },\n","        {\n","            'Embeddings_Model': 'all-MiniLM-L12-v2',\n","            'Iteration': 67,\n","            'Coherence': 0.489419,\n","            'Topic_Diversity': 0.527273,\n","            'bertopic__min_topic_size': 99,\n","            'bertopic__top_n_words': 24,\n","            'hdbscan__min_cluster_size': 258,\n","            'hdbscan__min_samples': 37,\n","            'umap__min_dist': 0.004852,\n","            'umap__n_components': 7,\n","            'umap__n_neighbors': 42,\n","            'vectorizer__min_df': 0.001174\n","        },\n","        {\n","            'Embeddings_Model': 'multi-qa-mpnet-base-cos-v1',\n","            'Iteration': 28,\n","            'Coherence': 0.439447,\n","            'Topic_Diversity': 0.749474,\n","            'bertopic__min_topic_size': 29,\n","            'bertopic__top_n_words': 14,\n","            'hdbscan__min_cluster_size': 427,\n","            'hdbscan__min_samples': 11,\n","            'umap__min_dist': 0.008103,\n","            'umap__n_components': 9,\n","            'umap__n_neighbors': 18,\n","            'vectorizer__min_df': 0.005862\n","        },\n","        {\n","            'Embeddings_Model': 'multi-qa-mpnet-base-cos-v1',\n","            'Iteration': 11,\n","            'Coherence': 0.419208,\n","            'Topic_Diversity': 0.828571,\n","            'bertopic__min_topic_size': 105,\n","            'bertopic__top_n_words': 24,\n","            'hdbscan__min_cluster_size': 497,\n","            'hdbscan__min_samples': 13,\n","            'umap__min_dist': 0.022149,\n","            'umap__n_components': 8,\n","            'umap__n_neighbors': 14,\n","            'vectorizer__min_df': 0.009229\n","        }\n","    ]\n","\n","    # Create a DataFrame from the models list\n","    df = pd.DataFrame(models)\n","    logger.info(f\"Dataframe created with {len(df)} embedding models.\")\n","    return df\n","\n","# Create the parameters dataframe\n","params_df = create_dataframe()\n","logger.info(f\"Parameters DataFrame Sample:\\n{params_df.head()}\")\n","\n","# =====================================\n","# 6. Load Embedding Models\n","# =====================================\n","\n","def load_embedding_models(model_names):\n","    \"\"\"\n","    Load all unique embedding models.\n","\n","    Args:\n","        model_names (list): List of embedding model names to load.\n","\n","    Returns:\n","        dict: A dictionary mapping model names to loaded embedding models.\n","    \"\"\"\n","    embedding_models = {}\n","    # Use GPU if available\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    logger.info(f\"Using device for embeddings: {device}\")\n","\n","    for model_name in model_names:\n","        logger.info(f\"Loading embedding model: {model_name}\")\n","        try:\n","            # Load the embedding model onto the specified device\n","            embedding_model = SentenceTransformer(model_name, device=device)\n","            embedding_models[model_name] = embedding_model\n","            logger.info(f\"Model {model_name} loaded successfully.\")\n","        except Exception as e:\n","            logger.error(f\"Failed to load embedding model {model_name}: {e}\")\n","    logger.info(\"All embedding models loaded.\")\n","    return embedding_models\n","\n","# Extract unique embedding model names from the dataframe\n","embedding_model_names = params_df['Embeddings_Model'].unique()\n","logger.info(f\"Unique embedding models to load: {embedding_model_names}\")\n","\n","# Load the embedding models\n","embedding_models = load_embedding_models(embedding_model_names)\n","\n","# =====================================\n","# 7. Train and Save BERTopic Models with Representations\n","# =====================================\n","\n","def train_and_save_models(corpus, params_df, embedding_models, stop_words, pos_configuration='a'):\n","    \"\"\"\n","    Train and save BERTopic models based on parameters.\n","\n","    Args:\n","        corpus (list): List of preprocessed sentences.\n","        params_df (pd.DataFrame): DataFrame containing model parameters.\n","        embedding_models (dict): Dictionary of embedding models.\n","        stop_words (set): Set of stop words to use in CountVectorizer.\n","        pos_configuration (str): POS configuration to use ('a', 'b', or 'c').\n","\n","    Configurations:\n","        a) 'a' - ONLY NOUNS\n","        b) 'b' - individual NOUNS AND individual ADJECTIVES\n","        c) 'c' - individual NOUNS AND individual VERBS\n","    \"\"\"\n","    # Define the main output directory\n","    main_output_dir = \"/content/drive/MyDrive/BERTTopic_Models\"\n","    os.makedirs(main_output_dir, exist_ok=True)\n","    logger.info(f\"Main output directory created at: {main_output_dir}\")\n","\n","    for idx, row in tqdm(params_df.iterrows(), total=params_df.shape[0], desc=\"Training Models\"):\n","        embedding_model_name = row['Embeddings_Model']\n","        model_number = idx + 1\n","        iteration = row['Iteration']\n","        logger.info(f\"\\nStarting training for model {model_number}/{len(params_df)} with embedding: {embedding_model_name}\")\n","\n","        # Retrieve the embedding model\n","        embedding_model = embedding_models.get(embedding_model_name)\n","        if embedding_model is None:\n","            logger.error(f\"Embedding model {embedding_model_name} not found. Skipping model {model_number}.\")\n","            continue\n","\n","        # Parameter validation and conversion\n","        try:\n","            umap_n_neighbors = int(row['umap__n_neighbors'])\n","            umap_n_components = int(row['umap__n_components'])\n","            umap_min_dist = float(row['umap__min_dist'])\n","            hdbscan_min_cluster_size = int(row['hdbscan__min_cluster_size'])\n","            hdbscan_min_samples = int(row['hdbscan__min_samples'])\n","            vectorizer_min_df = float(row['vectorizer__min_df'])\n","            bertopic_top_n_words = int(row['bertopic__top_n_words'])\n","            bertopic_min_topic_size = int(row['bertopic__min_topic_size'])\n","        except ValueError as e:\n","            logger.error(f\"Parameter conversion error for model {model_number}: {e}\")\n","            continue\n","\n","        # Initialize RAPIDS' UMAP model\n","        logger.debug(\"Initializing UMAP model...\")\n","        try:\n","            umap_model = UMAP(\n","                n_neighbors=umap_n_neighbors,\n","                n_components=umap_n_components,\n","                min_dist=umap_min_dist,\n","                metric='cosine',\n","                random_state=42\n","            )\n","            logger.debug(\"UMAP model initialized.\")\n","        except Exception as e:\n","            logger.error(f\"Failed to initialize UMAP model for model {model_number}: {e}\")\n","            continue\n","\n","        # Initialize RAPIDS' HDBSCAN model\n","        logger.debug(\"Initializing HDBSCAN model...\")\n","        try:\n","            hdbscan_model = HDBSCAN(\n","                min_cluster_size=hdbscan_min_cluster_size,\n","                min_samples=hdbscan_min_samples,\n","                cluster_selection_method='eom',\n","                prediction_data=True,\n","                gen_min_span_tree=True\n","            )\n","            logger.debug(\"HDBSCAN model initialized.\")\n","        except Exception as e:\n","            logger.error(f\"Failed to initialize HDBSCAN model for model {model_number}: {e}\")\n","            continue\n","\n","        # Initialize CountVectorizer (CPU-based) with custom stop words\n","        logger.debug(\"Initializing CountVectorizer...\")\n","        try:\n","            vectorizer_model = CountVectorizer(\n","                stop_words=stop_words,  # Use the preprocessed stop words\n","                min_df=vectorizer_min_df,\n","                ngram_range=(1, 1)  # Ensure single-word tokens\n","            )\n","            logger.debug(\"CountVectorizer initialized.\")\n","        except Exception as e:\n","            logger.error(f\"Failed to initialize CountVectorizer for model {model_number}: {e}\")\n","            continue\n","\n","        # Define the representation model based on POS configuration\n","        logger.debug(\"Defining representation model based on POS configuration...\")\n","        try:\n","            # The main representation of a topic\n","            main_representation = KeyBERTInspired(top_n_words=bertopic_top_n_words)\n","\n","            # Initialize representation models based on configuration\n","            if pos_configuration == 'a':\n","                # a) ONLY NOUNS\n","                pos_nouns = PartOfSpeech(pos_patterns=[[{\"POS\": \"NOUN\"}]])\n","                representation_model = {\n","                    \"Main\": main_representation,\n","                    \"NOUNS\": pos_nouns,\n","                    \"KeyBERT_MMR\": [KeyBERTInspired(top_n_words=30), MaximalMarginalRelevance(diversity=0.5)]\n","                }\n","            elif pos_configuration == 'b':\n","                # b) individual NOUNS AND individual ADJECTIVES\n","                pos_nouns = PartOfSpeech(pos_patterns=[[{\"POS\": \"NOUN\"}]])\n","                pos_adjectives = PartOfSpeech(pos_patterns=[[{\"POS\": \"ADJ\"}]])\n","                representation_model = {\n","                    \"Main\": main_representation,\n","                    \"NOUNS\": pos_nouns,\n","                    \"ADJECTIVES\": pos_adjectives,\n","                    \"KeyBERT_MMR\": [KeyBERTInspired(top_n_words=30), MaximalMarginalRelevance(diversity=0.5)]\n","                }\n","            elif pos_configuration == 'c':\n","                # c) individual NOUNS and individual VERBS\n","                pos_nouns = PartOfSpeech(pos_patterns=[[{\"POS\": \"NOUN\"}]])\n","                pos_verbs = PartOfSpeech(pos_patterns=[[{\"POS\": \"VERB\"}]])\n","                representation_model = {\n","                    \"Main\": main_representation,\n","                    \"NOUNS\": pos_nouns,\n","                    \"VERBS\": pos_verbs,\n","                    \"KeyBERT_MMR\": [KeyBERTInspired(top_n_words=30), MaximalMarginalRelevance(diversity=0.5)]\n","                }\n","            else:\n","                logger.error(f\"Invalid POS configuration: {pos_configuration}. Skipping model {model_number}.\")\n","                continue\n","\n","            logger.debug(\"Representation model defined successfully.\")\n","        except Exception as e:\n","            logger.error(f\"Failed to define representation model for model {model_number}: {e}\")\n","            continue\n","\n","        # Initialize BERTopic model with the embedding_model and multiple representations\n","        logger.debug(\"Initializing BERTopic model with multiple representations...\")\n","        try:\n","            topic_model = BERTopic(\n","                embedding_model=embedding_model,\n","                umap_model=umap_model,\n","                hdbscan_model=hdbscan_model,\n","                vectorizer_model=vectorizer_model,\n","                representation_model=representation_model,  # Include multiple representation models\n","                top_n_words=bertopic_top_n_words,\n","                min_topic_size=bertopic_min_topic_size,\n","                language='english',\n","                calculate_probabilities=True,\n","                verbose=False  # Set to False to reduce verbosity\n","            )\n","            logger.debug(\"BERTopic model initialized with multiple representations.\")\n","        except Exception as e:\n","            logger.error(f\"Failed to initialize BERTopic model for model {model_number}: {e}\")\n","            continue\n","\n","        # Train BERTopic model\n","        logger.info(\"Training BERTopic model...\")\n","        start_train_time = time.time()\n","        try:\n","            # Fit the model with the corpus only\n","            topics, probs = topic_model.fit_transform(corpus)\n","            logger.info(f\"Model {model_number} training completed in {time.time() - start_train_time:.2f} seconds.\")\n","        except Exception as e:\n","            logger.error(f\"Error during model {model_number} training: {e}\")\n","            continue\n","\n","        # Define output directories\n","        safe_embedding = embedding_model_name.replace('/', '_').replace('\\\\', '_')\n","        model_output_dir = os.path.join(main_output_dir, safe_embedding)\n","        os.makedirs(model_output_dir, exist_ok=True)\n","        logger.info(f\"Model output directory created at: {model_output_dir}\")\n","\n","        # Save the model\n","        logger.debug(\"Saving BERTopic model...\")\n","        try:\n","            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","            model_filename = f\"bertopic_model_{model_number}_iter_{iteration}_{safe_embedding}_{timestamp}.pkl\"\n","            model_path = os.path.join(model_output_dir, model_filename)\n","            topic_model.save(model_path)\n","            logger.info(f\"Model {model_number} saved at: {model_path}\")\n","        except Exception as e:\n","            logger.error(f\"Failed to save model {model_number}: {e}\")\n","            continue\n","\n","        # Save output topics in CSV and JSON files\n","        logger.info(\"Saving topics to CSV and JSON...\")\n","        try:\n","            # Extract topics information\n","            topics_info = topic_model.get_topic_info()\n","            topics_dict = topic_model.get_topics()\n","\n","            # Create output subdirectories for topics\n","            topics_output_dir = os.path.join(model_output_dir, f\"topics_{model_number}_{timestamp}\")\n","            os.makedirs(topics_output_dir, exist_ok=True)\n","\n","            # Save topics to CSV using get_topic_info()\n","            csv_filename = f\"bertopic_model_{model_number}_iter_{iteration}_{safe_embedding}_{timestamp}_topics_info.csv\"\n","            csv_path = os.path.join(topics_output_dir, csv_filename)\n","            topics_info.to_csv(csv_path, index=False)\n","            logger.info(f\"Topics info saved to {csv_path}\")\n","\n","            # Save topics to JSON using get_topics(), excluding empty strings and logging occurrences\n","            topics_json = {}\n","            for topic_num, words in topics_dict.items():\n","                # Skip -1 topic which usually represents outliers\n","                if topic_num == -1:\n","                    continue\n","                # Filter out empty strings and ensure words are valid\n","                filtered_words = [word for word, _ in words if word.strip()]\n","                empty_count = len(words) - len(filtered_words)\n","                if empty_count > 0:\n","                    logger.warning(f\"Topic {topic_num} has {empty_count} empty words.\")\n","                topics_json[str(topic_num)] = filtered_words\n","\n","            json_filename = f\"bertopic_model_{model_number}_iter_{iteration}_{safe_embedding}_{timestamp}_topics.json\"\n","            json_path = os.path.join(topics_output_dir, json_filename)\n","            with open(json_path, 'w') as json_file:\n","                json.dump(topics_json, json_file, indent=4)\n","            logger.info(f\"Topics JSON saved to {json_path}\")\n","        except Exception as e:\n","            logger.error(f\"Failed to save topics for model {model_number}: {e}\")\n","\n","        # Cleanup to free memory\n","        del topic_model\n","        gc.collect()\n","\n","    logger.info(\"All models trained and saved.\")\n","\n","# =====================================\n","# 8. Execute the Training Pipeline\n","# =====================================\n","\n","def main():\n","    \"\"\"\n","    Main function to orchestrate data loading, model training, and saving.\n","    \"\"\"\n","    # Define POS configuration\n","    # Options:\n","    # 'a' - ONLY NOUNS\n","    # 'b' - individual NOUNS AND individual ADJECTIVES\n","    # 'c' - individual NOUNS AND individual VERBS\n","    POS_CONFIGURATION = 'a'  # Change to 'b' or 'c' as needed\n","\n","    logger.info(f\"Starting BERTopic model training with POS configuration: {POS_CONFIGURATION}\")\n","    train_and_save_models(\n","        corpus=corpus,\n","        params_df=params_df,\n","        embedding_models=embedding_models,\n","        stop_words=stop_words,\n","        pos_configuration=POS_CONFIGURATION\n","    )\n","    logger.info(\"BERTopic model training and saving completed.\")\n","\n","if __name__ == \"__main__\":\n","    main()\n","\n","# =====================================\n","# 9. Verify Installed RAPIDS Libraries\n","# =====================================\n","\n","import cuml\n","logger.info(f\"cuML version: {cuml.__version__}\")\n","\n","import cugraph\n","logger.info(f\"cuGraph version: {cugraph.__version__}\")\n","\n","import cuspatial\n","logger.info(f\"cuSpatial version: {cuspatial.__version__}\")\n","\n","import cuxfilter\n","logger.info(f\"cuxfilter version: {cuxfilter.__version__}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"4d6eryq5fCe5","executionInfo":{"status":"ok","timestamp":1730583353973,"user_tz":-60,"elapsed":4467516,"user":{"displayName":"Polina Bakhturina","userId":"07881954271877753559"}},"outputId":"1b4ba9a6-ce7b-44a0-cae0-c132b515fa4b"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","2024-11-02 20:21:26 - INFO - Loading and preprocessing additional stop words...\n","2024-11-02 20:21:26 - INFO - Loading and preprocessing additional stop words...\n","2024-11-02 20:21:26 - INFO - Loading and preprocessing additional stop words...\n","INFO:BERTopic_Training:Loading and preprocessing additional stop words...\n","2024-11-02 20:21:26 - INFO - Processed stop words count: 4923\n","2024-11-02 20:21:26 - INFO - Processed stop words count: 4923\n","2024-11-02 20:21:26 - INFO - Processed stop words count: 4923\n","INFO:BERTopic_Training:Processed stop words count: 4923\n","2024-11-02 20:21:26 - INFO - Total stop words after preprocessing: 5038\n","2024-11-02 20:21:26 - INFO - Total stop words after preprocessing: 5038\n","2024-11-02 20:21:26 - INFO - Total stop words after preprocessing: 5038\n","INFO:BERTopic_Training:Total stop words after preprocessing: 5038\n","2024-11-02 20:21:26 - INFO - Starting data loading and preprocessing...\n","2024-11-02 20:21:26 - INFO - Starting data loading and preprocessing...\n","2024-11-02 20:21:26 - INFO - Starting data loading and preprocessing...\n","INFO:BERTopic_Training:Starting data loading and preprocessing...\n","2024-11-02 20:21:26 - INFO - Loading and preprocessing dataset...\n","2024-11-02 20:21:26 - INFO - Loading and preprocessing dataset...\n","2024-11-02 20:21:26 - INFO - Loading and preprocessing dataset...\n","INFO:BERTopic_Training:Loading and preprocessing dataset...\n","2024-11-02 20:21:27 - INFO - Dataset loaded. Total sentences: 680822\n","2024-11-02 20:21:27 - INFO - Dataset loaded. Total sentences: 680822\n","2024-11-02 20:21:27 - INFO - Dataset loaded. Total sentences: 680822\n","INFO:BERTopic_Training:Dataset loaded. Total sentences: 680822\n","DEBUG:BERTopic_Training:Removing newline characters and extra spaces, converting to lowercase...\n","DEBUG:BERTopic_Training:Tokenizing sentences and removing stop words...\n","DEBUG:BERTopic_Training:Performing additional data quality checks...\n","2024-11-02 20:22:54 - INFO - Average sentence length: 3.77\n","2024-11-02 20:22:54 - INFO - Average sentence length: 3.77\n","2024-11-02 20:22:54 - INFO - Average sentence length: 3.77\n","INFO:BERTopic_Training:Average sentence length: 3.77\n","2024-11-02 20:22:54 - INFO - Minimum sentence length: 0\n","2024-11-02 20:22:54 - INFO - Minimum sentence length: 0\n","2024-11-02 20:22:54 - INFO - Minimum sentence length: 0\n","INFO:BERTopic_Training:Minimum sentence length: 0\n","2024-11-02 20:22:54 - INFO - Maximum sentence length: 77\n","2024-11-02 20:22:54 - INFO - Maximum sentence length: 77\n","2024-11-02 20:22:54 - INFO - Maximum sentence length: 77\n","INFO:BERTopic_Training:Maximum sentence length: 77\n","2024-11-02 20:22:54 - INFO - Filtered corpus size: 394947 out of 680822\n","2024-11-02 20:22:54 - INFO - Filtered corpus size: 394947 out of 680822\n","2024-11-02 20:22:54 - INFO - Filtered corpus size: 394947 out of 680822\n","INFO:BERTopic_Training:Filtered corpus size: 394947 out of 680822\n","2024-11-02 20:22:54 - INFO - Dataset loaded and preprocessed. Total sentences: 394947\n","2024-11-02 20:22:54 - INFO - Dataset loaded and preprocessed. Total sentences: 394947\n","2024-11-02 20:22:54 - INFO - Dataset loaded and preprocessed. Total sentences: 394947\n","INFO:BERTopic_Training:Dataset loaded and preprocessed. Total sentences: 394947\n","2024-11-02 20:22:54 - INFO - Time taken for loading and preprocessing: 88.26 seconds\n","2024-11-02 20:22:54 - INFO - Time taken for loading and preprocessing: 88.26 seconds\n","2024-11-02 20:22:54 - INFO - Time taken for loading and preprocessing: 88.26 seconds\n","INFO:BERTopic_Training:Time taken for loading and preprocessing: 88.26 seconds\n","2024-11-02 20:22:54 - INFO - Data loading and preprocessing completed.\n","2024-11-02 20:22:54 - INFO - Data loading and preprocessing completed.\n","2024-11-02 20:22:54 - INFO - Data loading and preprocessing completed.\n","INFO:BERTopic_Training:Data loading and preprocessing completed.\n","2024-11-02 20:22:54 - INFO - Creating dataframe with model parameters...\n","2024-11-02 20:22:54 - INFO - Creating dataframe with model parameters...\n","2024-11-02 20:22:54 - INFO - Creating dataframe with model parameters...\n","INFO:BERTopic_Training:Creating dataframe with model parameters...\n","2024-11-02 20:22:54 - INFO - Dataframe created with 10 embedding models.\n","2024-11-02 20:22:54 - INFO - Dataframe created with 10 embedding models.\n","2024-11-02 20:22:54 - INFO - Dataframe created with 10 embedding models.\n","INFO:BERTopic_Training:Dataframe created with 10 embedding models.\n","2024-11-02 20:22:54 - INFO - Parameters DataFrame Sample:\n","           Embeddings_Model  Iteration  Coherence  Topic_Diversity  \\\n","0         all-MiniLM-L12-v2         66   0.577551         0.450000   \n","1  paraphrase-mpnet-base-v2         14   0.469187         0.800000   \n","2         all-MiniLM-L12-v2         75   0.543105         0.466667   \n","3  paraphrase-mpnet-base-v2          0   0.463245         0.820000   \n","4   paraphrase-MiniLM-L6-v2         19   0.425237         0.940000   \n","\n","   bertopic__min_topic_size  bertopic__top_n_words  hdbscan__min_cluster_size  \\\n","0                       102                     30                        281   \n","1                        63                     22                        500   \n","2                       142                     10                        473   \n","3                       127                     31                        494   \n","4                        64                     27                        143   \n","\n","   hdbscan__min_samples  umap__min_dist  umap__n_components  \\\n","0                    72        0.005022                   2   \n","1                    72        0.077818                   9   \n","2                    14        0.004634                   5   \n","3                    28        0.058341                  10   \n","4                    32        0.085702                   9   \n","\n","   umap__n_neighbors  vectorizer__min_df  \n","0                  7            0.001504  \n","1                 11            0.009372  \n","2                 15            0.001947  \n","3                 11            0.007313  \n","4                 44            0.005932  \n","2024-11-02 20:22:54 - INFO - Parameters DataFrame Sample:\n","           Embeddings_Model  Iteration  Coherence  Topic_Diversity  \\\n","0         all-MiniLM-L12-v2         66   0.577551         0.450000   \n","1  paraphrase-mpnet-base-v2         14   0.469187         0.800000   \n","2         all-MiniLM-L12-v2         75   0.543105         0.466667   \n","3  paraphrase-mpnet-base-v2          0   0.463245         0.820000   \n","4   paraphrase-MiniLM-L6-v2         19   0.425237         0.940000   \n","\n","   bertopic__min_topic_size  bertopic__top_n_words  hdbscan__min_cluster_size  \\\n","0                       102                     30                        281   \n","1                        63                     22                        500   \n","2                       142                     10                        473   \n","3                       127                     31                        494   \n","4                        64                     27                        143   \n","\n","   hdbscan__min_samples  umap__min_dist  umap__n_components  \\\n","0                    72        0.005022                   2   \n","1                    72        0.077818                   9   \n","2                    14        0.004634                   5   \n","3                    28        0.058341                  10   \n","4                    32        0.085702                   9   \n","\n","   umap__n_neighbors  vectorizer__min_df  \n","0                  7            0.001504  \n","1                 11            0.009372  \n","2                 15            0.001947  \n","3                 11            0.007313  \n","4                 44            0.005932  \n","2024-11-02 20:22:54 - INFO - Parameters DataFrame Sample:\n","           Embeddings_Model  Iteration  Coherence  Topic_Diversity  \\\n","0         all-MiniLM-L12-v2         66   0.577551         0.450000   \n","1  paraphrase-mpnet-base-v2         14   0.469187         0.800000   \n","2         all-MiniLM-L12-v2         75   0.543105         0.466667   \n","3  paraphrase-mpnet-base-v2          0   0.463245         0.820000   \n","4   paraphrase-MiniLM-L6-v2         19   0.425237         0.940000   \n","\n","   bertopic__min_topic_size  bertopic__top_n_words  hdbscan__min_cluster_size  \\\n","0                       102                     30                        281   \n","1                        63                     22                        500   \n","2                       142                     10                        473   \n","3                       127                     31                        494   \n","4                        64                     27                        143   \n","\n","   hdbscan__min_samples  umap__min_dist  umap__n_components  \\\n","0                    72        0.005022                   2   \n","1                    72        0.077818                   9   \n","2                    14        0.004634                   5   \n","3                    28        0.058341                  10   \n","4                    32        0.085702                   9   \n","\n","   umap__n_neighbors  vectorizer__min_df  \n","0                  7            0.001504  \n","1                 11            0.009372  \n","2                 15            0.001947  \n","3                 11            0.007313  \n","4                 44            0.005932  \n","INFO:BERTopic_Training:Parameters DataFrame Sample:\n","           Embeddings_Model  Iteration  Coherence  Topic_Diversity  \\\n","0         all-MiniLM-L12-v2         66   0.577551         0.450000   \n","1  paraphrase-mpnet-base-v2         14   0.469187         0.800000   \n","2         all-MiniLM-L12-v2         75   0.543105         0.466667   \n","3  paraphrase-mpnet-base-v2          0   0.463245         0.820000   \n","4   paraphrase-MiniLM-L6-v2         19   0.425237         0.940000   \n","\n","   bertopic__min_topic_size  bertopic__top_n_words  hdbscan__min_cluster_size  \\\n","0                       102                     30                        281   \n","1                        63                     22                        500   \n","2                       142                     10                        473   \n","3                       127                     31                        494   \n","4                        64                     27                        143   \n","\n","   hdbscan__min_samples  umap__min_dist  umap__n_components  \\\n","0                    72        0.005022                   2   \n","1                    72        0.077818                   9   \n","2                    14        0.004634                   5   \n","3                    28        0.058341                  10   \n","4                    32        0.085702                   9   \n","\n","   umap__n_neighbors  vectorizer__min_df  \n","0                  7            0.001504  \n","1                 11            0.009372  \n","2                 15            0.001947  \n","3                 11            0.007313  \n","4                 44            0.005932  \n","2024-11-02 20:22:54 - INFO - Unique embedding models to load: ['all-MiniLM-L12-v2' 'paraphrase-mpnet-base-v2' 'paraphrase-MiniLM-L6-v2'\n"," 'multi-qa-mpnet-base-cos-v1']\n","2024-11-02 20:22:54 - INFO - Unique embedding models to load: ['all-MiniLM-L12-v2' 'paraphrase-mpnet-base-v2' 'paraphrase-MiniLM-L6-v2'\n"," 'multi-qa-mpnet-base-cos-v1']\n","2024-11-02 20:22:54 - INFO - Unique embedding models to load: ['all-MiniLM-L12-v2' 'paraphrase-mpnet-base-v2' 'paraphrase-MiniLM-L6-v2'\n"," 'multi-qa-mpnet-base-cos-v1']\n","INFO:BERTopic_Training:Unique embedding models to load: ['all-MiniLM-L12-v2' 'paraphrase-mpnet-base-v2' 'paraphrase-MiniLM-L6-v2'\n"," 'multi-qa-mpnet-base-cos-v1']\n","2024-11-02 20:22:54 - INFO - Using device for embeddings: cuda\n","2024-11-02 20:22:54 - INFO - Using device for embeddings: cuda\n","2024-11-02 20:22:54 - INFO - Using device for embeddings: cuda\n","INFO:BERTopic_Training:Using device for embeddings: cuda\n","2024-11-02 20:22:54 - INFO - Loading embedding model: all-MiniLM-L12-v2\n","2024-11-02 20:22:54 - INFO - Loading embedding model: all-MiniLM-L12-v2\n","2024-11-02 20:22:54 - INFO - Loading embedding model: all-MiniLM-L12-v2\n","INFO:BERTopic_Training:Loading embedding model: all-MiniLM-L12-v2\n","2024-11-02 20:22:56 - INFO - Model all-MiniLM-L12-v2 loaded successfully.\n","2024-11-02 20:22:56 - INFO - Model all-MiniLM-L12-v2 loaded successfully.\n","2024-11-02 20:22:56 - INFO - Model all-MiniLM-L12-v2 loaded successfully.\n","INFO:BERTopic_Training:Model all-MiniLM-L12-v2 loaded successfully.\n","2024-11-02 20:22:56 - INFO - Loading embedding model: paraphrase-mpnet-base-v2\n","2024-11-02 20:22:56 - INFO - Loading embedding model: paraphrase-mpnet-base-v2\n","2024-11-02 20:22:56 - INFO - Loading embedding model: paraphrase-mpnet-base-v2\n","INFO:BERTopic_Training:Loading embedding model: paraphrase-mpnet-base-v2\n","2024-11-02 20:22:56 - INFO - Model paraphrase-mpnet-base-v2 loaded successfully.\n","2024-11-02 20:22:56 - INFO - Model paraphrase-mpnet-base-v2 loaded successfully.\n","2024-11-02 20:22:56 - INFO - Model paraphrase-mpnet-base-v2 loaded successfully.\n","INFO:BERTopic_Training:Model paraphrase-mpnet-base-v2 loaded successfully.\n","2024-11-02 20:22:56 - INFO - Loading embedding model: paraphrase-MiniLM-L6-v2\n","2024-11-02 20:22:56 - INFO - Loading embedding model: paraphrase-MiniLM-L6-v2\n","2024-11-02 20:22:56 - INFO - Loading embedding model: paraphrase-MiniLM-L6-v2\n","INFO:BERTopic_Training:Loading embedding model: paraphrase-MiniLM-L6-v2\n","2024-11-02 20:22:57 - INFO - Model paraphrase-MiniLM-L6-v2 loaded successfully.\n","2024-11-02 20:22:57 - INFO - Model paraphrase-MiniLM-L6-v2 loaded successfully.\n","2024-11-02 20:22:57 - INFO - Model paraphrase-MiniLM-L6-v2 loaded successfully.\n","INFO:BERTopic_Training:Model paraphrase-MiniLM-L6-v2 loaded successfully.\n","2024-11-02 20:22:57 - INFO - Loading embedding model: multi-qa-mpnet-base-cos-v1\n","2024-11-02 20:22:57 - INFO - Loading embedding model: multi-qa-mpnet-base-cos-v1\n","2024-11-02 20:22:57 - INFO - Loading embedding model: multi-qa-mpnet-base-cos-v1\n","INFO:BERTopic_Training:Loading embedding model: multi-qa-mpnet-base-cos-v1\n","2024-11-02 20:22:57 - INFO - Model multi-qa-mpnet-base-cos-v1 loaded successfully.\n","2024-11-02 20:22:57 - INFO - Model multi-qa-mpnet-base-cos-v1 loaded successfully.\n","2024-11-02 20:22:57 - INFO - Model multi-qa-mpnet-base-cos-v1 loaded successfully.\n","INFO:BERTopic_Training:Model multi-qa-mpnet-base-cos-v1 loaded successfully.\n","2024-11-02 20:22:58 - INFO - All embedding models loaded.\n","2024-11-02 20:22:58 - INFO - All embedding models loaded.\n","2024-11-02 20:22:58 - INFO - All embedding models loaded.\n","INFO:BERTopic_Training:All embedding models loaded.\n","2024-11-02 20:22:58 - INFO - Starting BERTopic model training with POS configuration: a\n","2024-11-02 20:22:58 - INFO - Starting BERTopic model training with POS configuration: a\n","2024-11-02 20:22:58 - INFO - Starting BERTopic model training with POS configuration: a\n","INFO:BERTopic_Training:Starting BERTopic model training with POS configuration: a\n","2024-11-02 20:22:58 - INFO - Main output directory created at: /content/drive/MyDrive/BERTTopic_Models\n","2024-11-02 20:22:58 - INFO - Main output directory created at: /content/drive/MyDrive/BERTTopic_Models\n","2024-11-02 20:22:58 - INFO - Main output directory created at: /content/drive/MyDrive/BERTTopic_Models\n","INFO:BERTopic_Training:Main output directory created at: /content/drive/MyDrive/BERTTopic_Models\n","Training Models:   0%|          | 0/10 [00:00<?, ?it/s]2024-11-02 20:22:58 - INFO - \n","Starting training for model 1/10 with embedding: all-MiniLM-L12-v2\n","2024-11-02 20:22:58 - INFO - \n","Starting training for model 1/10 with embedding: all-MiniLM-L12-v2\n","2024-11-02 20:22:58 - INFO - \n","Starting training for model 1/10 with embedding: all-MiniLM-L12-v2\n","INFO:BERTopic_Training:\n","Starting training for model 1/10 with embedding: all-MiniLM-L12-v2\n","DEBUG:BERTopic_Training:Initializing UMAP model...\n","DEBUG:BERTopic_Training:UMAP model initialized.\n","DEBUG:BERTopic_Training:Initializing HDBSCAN model...\n","DEBUG:BERTopic_Training:HDBSCAN model initialized.\n","DEBUG:BERTopic_Training:Initializing CountVectorizer...\n","DEBUG:BERTopic_Training:CountVectorizer initialized.\n","DEBUG:BERTopic_Training:Defining representation model based on POS configuration...\n","DEBUG:BERTopic_Training:Representation model defined successfully.\n","DEBUG:BERTopic_Training:Initializing BERTopic model with multiple representations...\n","DEBUG:BERTopic_Training:BERTopic model initialized with multiple representations.\n","2024-11-02 20:22:58 - INFO - Training BERTopic model...\n","2024-11-02 20:22:58 - INFO - Training BERTopic model...\n","2024-11-02 20:22:58 - INFO - Training BERTopic model...\n","INFO:BERTopic_Training:Training BERTopic model...\n","2024-11-02 20:28:00 - INFO - Model 1 training completed in 301.52 seconds.\n","2024-11-02 20:28:00 - INFO - Model 1 training completed in 301.52 seconds.\n","2024-11-02 20:28:00 - INFO - Model 1 training completed in 301.52 seconds.\n","INFO:BERTopic_Training:Model 1 training completed in 301.52 seconds.\n","2024-11-02 20:28:00 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2\n","2024-11-02 20:28:00 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2\n","2024-11-02 20:28:00 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2\n","INFO:BERTopic_Training:Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2\n","DEBUG:BERTopic_Training:Saving BERTopic model...\n","2024-11-02 20:28:00,161 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n","2024-11-02 20:28:07 - INFO - Model 1 saved at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/bertopic_model_1_iter_66_all-MiniLM-L12-v2_20241102_202800.pkl\n","2024-11-02 20:28:07 - INFO - Model 1 saved at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/bertopic_model_1_iter_66_all-MiniLM-L12-v2_20241102_202800.pkl\n","2024-11-02 20:28:07 - INFO - Model 1 saved at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/bertopic_model_1_iter_66_all-MiniLM-L12-v2_20241102_202800.pkl\n","INFO:BERTopic_Training:Model 1 saved at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/bertopic_model_1_iter_66_all-MiniLM-L12-v2_20241102_202800.pkl\n","2024-11-02 20:28:07 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 20:28:07 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 20:28:07 - INFO - Saving topics to CSV and JSON...\n","INFO:BERTopic_Training:Saving topics to CSV and JSON...\n","2024-11-02 20:28:07 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_1_20241102_202800/bertopic_model_1_iter_66_all-MiniLM-L12-v2_20241102_202800_topics_info.csv\n","2024-11-02 20:28:07 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_1_20241102_202800/bertopic_model_1_iter_66_all-MiniLM-L12-v2_20241102_202800_topics_info.csv\n","2024-11-02 20:28:07 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_1_20241102_202800/bertopic_model_1_iter_66_all-MiniLM-L12-v2_20241102_202800_topics_info.csv\n","INFO:BERTopic_Training:Topics info saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_1_20241102_202800/bertopic_model_1_iter_66_all-MiniLM-L12-v2_20241102_202800_topics_info.csv\n","2024-11-02 20:28:07 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_1_20241102_202800/bertopic_model_1_iter_66_all-MiniLM-L12-v2_20241102_202800_topics.json\n","2024-11-02 20:28:07 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_1_20241102_202800/bertopic_model_1_iter_66_all-MiniLM-L12-v2_20241102_202800_topics.json\n","2024-11-02 20:28:07 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_1_20241102_202800/bertopic_model_1_iter_66_all-MiniLM-L12-v2_20241102_202800_topics.json\n","INFO:BERTopic_Training:Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_1_20241102_202800/bertopic_model_1_iter_66_all-MiniLM-L12-v2_20241102_202800_topics.json\n","Training Models:  10%|█         | 1/10 [05:10<46:30, 310.08s/it]2024-11-02 20:28:08 - INFO - \n","Starting training for model 2/10 with embedding: paraphrase-mpnet-base-v2\n","2024-11-02 20:28:08 - INFO - \n","Starting training for model 2/10 with embedding: paraphrase-mpnet-base-v2\n","2024-11-02 20:28:08 - INFO - \n","Starting training for model 2/10 with embedding: paraphrase-mpnet-base-v2\n","INFO:BERTopic_Training:\n","Starting training for model 2/10 with embedding: paraphrase-mpnet-base-v2\n","DEBUG:BERTopic_Training:Initializing UMAP model...\n","DEBUG:BERTopic_Training:UMAP model initialized.\n","DEBUG:BERTopic_Training:Initializing HDBSCAN model...\n","DEBUG:BERTopic_Training:HDBSCAN model initialized.\n","DEBUG:BERTopic_Training:Initializing CountVectorizer...\n","DEBUG:BERTopic_Training:CountVectorizer initialized.\n","DEBUG:BERTopic_Training:Defining representation model based on POS configuration...\n","DEBUG:BERTopic_Training:Representation model defined successfully.\n","DEBUG:BERTopic_Training:Initializing BERTopic model with multiple representations...\n","DEBUG:BERTopic_Training:BERTopic model initialized with multiple representations.\n","2024-11-02 20:28:08 - INFO - Training BERTopic model...\n","2024-11-02 20:28:08 - INFO - Training BERTopic model...\n","2024-11-02 20:28:08 - INFO - Training BERTopic model...\n","INFO:BERTopic_Training:Training BERTopic model...\n","2024-11-02 20:36:36 - INFO - Model 2 training completed in 507.88 seconds.\n","2024-11-02 20:36:36 - INFO - Model 2 training completed in 507.88 seconds.\n","2024-11-02 20:36:36 - INFO - Model 2 training completed in 507.88 seconds.\n","INFO:BERTopic_Training:Model 2 training completed in 507.88 seconds.\n","2024-11-02 20:36:36 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2\n","2024-11-02 20:36:36 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2\n","2024-11-02 20:36:36 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2\n","INFO:BERTopic_Training:Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2\n","DEBUG:BERTopic_Training:Saving BERTopic model...\n","2024-11-02 20:36:36,666 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n","2024-11-02 20:36:47 - INFO - Model 2 saved at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/bertopic_model_2_iter_14_paraphrase-mpnet-base-v2_20241102_203636.pkl\n","2024-11-02 20:36:47 - INFO - Model 2 saved at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/bertopic_model_2_iter_14_paraphrase-mpnet-base-v2_20241102_203636.pkl\n","2024-11-02 20:36:47 - INFO - Model 2 saved at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/bertopic_model_2_iter_14_paraphrase-mpnet-base-v2_20241102_203636.pkl\n","INFO:BERTopic_Training:Model 2 saved at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/bertopic_model_2_iter_14_paraphrase-mpnet-base-v2_20241102_203636.pkl\n","2024-11-02 20:36:47 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 20:36:47 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 20:36:47 - INFO - Saving topics to CSV and JSON...\n","INFO:BERTopic_Training:Saving topics to CSV and JSON...\n","2024-11-02 20:36:47 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_2_20241102_203636/bertopic_model_2_iter_14_paraphrase-mpnet-base-v2_20241102_203636_topics_info.csv\n","2024-11-02 20:36:47 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_2_20241102_203636/bertopic_model_2_iter_14_paraphrase-mpnet-base-v2_20241102_203636_topics_info.csv\n","2024-11-02 20:36:47 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_2_20241102_203636/bertopic_model_2_iter_14_paraphrase-mpnet-base-v2_20241102_203636_topics_info.csv\n","INFO:BERTopic_Training:Topics info saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_2_20241102_203636/bertopic_model_2_iter_14_paraphrase-mpnet-base-v2_20241102_203636_topics_info.csv\n","2024-11-02 20:36:47 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_2_20241102_203636/bertopic_model_2_iter_14_paraphrase-mpnet-base-v2_20241102_203636_topics.json\n","2024-11-02 20:36:47 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_2_20241102_203636/bertopic_model_2_iter_14_paraphrase-mpnet-base-v2_20241102_203636_topics.json\n","2024-11-02 20:36:47 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_2_20241102_203636/bertopic_model_2_iter_14_paraphrase-mpnet-base-v2_20241102_203636_topics.json\n","INFO:BERTopic_Training:Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_2_20241102_203636/bertopic_model_2_iter_14_paraphrase-mpnet-base-v2_20241102_203636_topics.json\n","Training Models:  20%|██        | 2/10 [13:49<57:47, 433.48s/it]2024-11-02 20:36:47 - INFO - \n","Starting training for model 3/10 with embedding: all-MiniLM-L12-v2\n","2024-11-02 20:36:47 - INFO - \n","Starting training for model 3/10 with embedding: all-MiniLM-L12-v2\n","2024-11-02 20:36:47 - INFO - \n","Starting training for model 3/10 with embedding: all-MiniLM-L12-v2\n","INFO:BERTopic_Training:\n","Starting training for model 3/10 with embedding: all-MiniLM-L12-v2\n","DEBUG:BERTopic_Training:Initializing UMAP model...\n","DEBUG:BERTopic_Training:UMAP model initialized.\n","DEBUG:BERTopic_Training:Initializing HDBSCAN model...\n","DEBUG:BERTopic_Training:HDBSCAN model initialized.\n","DEBUG:BERTopic_Training:Initializing CountVectorizer...\n","DEBUG:BERTopic_Training:CountVectorizer initialized.\n","DEBUG:BERTopic_Training:Defining representation model based on POS configuration...\n","DEBUG:BERTopic_Training:Representation model defined successfully.\n","DEBUG:BERTopic_Training:Initializing BERTopic model with multiple representations...\n","DEBUG:BERTopic_Training:BERTopic model initialized with multiple representations.\n","2024-11-02 20:36:48 - INFO - Training BERTopic model...\n","2024-11-02 20:36:48 - INFO - Training BERTopic model...\n","2024-11-02 20:36:48 - INFO - Training BERTopic model...\n","INFO:BERTopic_Training:Training BERTopic model...\n","2024-11-02 20:41:51 - INFO - Model 3 training completed in 302.54 seconds.\n","2024-11-02 20:41:51 - INFO - Model 3 training completed in 302.54 seconds.\n","2024-11-02 20:41:51 - INFO - Model 3 training completed in 302.54 seconds.\n","INFO:BERTopic_Training:Model 3 training completed in 302.54 seconds.\n","2024-11-02 20:41:51 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2\n","2024-11-02 20:41:51 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2\n","2024-11-02 20:41:51 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2\n","INFO:BERTopic_Training:Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2\n","DEBUG:BERTopic_Training:Saving BERTopic model...\n","2024-11-02 20:41:51,209 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n","2024-11-02 20:42:00 - INFO - Model 3 saved at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/bertopic_model_3_iter_75_all-MiniLM-L12-v2_20241102_204151.pkl\n","2024-11-02 20:42:00 - INFO - Model 3 saved at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/bertopic_model_3_iter_75_all-MiniLM-L12-v2_20241102_204151.pkl\n","2024-11-02 20:42:00 - INFO - Model 3 saved at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/bertopic_model_3_iter_75_all-MiniLM-L12-v2_20241102_204151.pkl\n","INFO:BERTopic_Training:Model 3 saved at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/bertopic_model_3_iter_75_all-MiniLM-L12-v2_20241102_204151.pkl\n","2024-11-02 20:42:00 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 20:42:00 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 20:42:00 - INFO - Saving topics to CSV and JSON...\n","INFO:BERTopic_Training:Saving topics to CSV and JSON...\n","2024-11-02 20:42:00 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_3_20241102_204151/bertopic_model_3_iter_75_all-MiniLM-L12-v2_20241102_204151_topics_info.csv\n","2024-11-02 20:42:00 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_3_20241102_204151/bertopic_model_3_iter_75_all-MiniLM-L12-v2_20241102_204151_topics_info.csv\n","2024-11-02 20:42:00 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_3_20241102_204151/bertopic_model_3_iter_75_all-MiniLM-L12-v2_20241102_204151_topics_info.csv\n","INFO:BERTopic_Training:Topics info saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_3_20241102_204151/bertopic_model_3_iter_75_all-MiniLM-L12-v2_20241102_204151_topics_info.csv\n","2024-11-02 20:42:00 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_3_20241102_204151/bertopic_model_3_iter_75_all-MiniLM-L12-v2_20241102_204151_topics.json\n","2024-11-02 20:42:00 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_3_20241102_204151/bertopic_model_3_iter_75_all-MiniLM-L12-v2_20241102_204151_topics.json\n","2024-11-02 20:42:00 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_3_20241102_204151/bertopic_model_3_iter_75_all-MiniLM-L12-v2_20241102_204151_topics.json\n","INFO:BERTopic_Training:Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_3_20241102_204151/bertopic_model_3_iter_75_all-MiniLM-L12-v2_20241102_204151_topics.json\n","Training Models:  30%|███       | 3/10 [19:03<44:11, 378.73s/it]2024-11-02 20:42:01 - INFO - \n","Starting training for model 4/10 with embedding: paraphrase-mpnet-base-v2\n","2024-11-02 20:42:01 - INFO - \n","Starting training for model 4/10 with embedding: paraphrase-mpnet-base-v2\n","2024-11-02 20:42:01 - INFO - \n","Starting training for model 4/10 with embedding: paraphrase-mpnet-base-v2\n","INFO:BERTopic_Training:\n","Starting training for model 4/10 with embedding: paraphrase-mpnet-base-v2\n","DEBUG:BERTopic_Training:Initializing UMAP model...\n","DEBUG:BERTopic_Training:UMAP model initialized.\n","DEBUG:BERTopic_Training:Initializing HDBSCAN model...\n","DEBUG:BERTopic_Training:HDBSCAN model initialized.\n","DEBUG:BERTopic_Training:Initializing CountVectorizer...\n","DEBUG:BERTopic_Training:CountVectorizer initialized.\n","DEBUG:BERTopic_Training:Defining representation model based on POS configuration...\n","DEBUG:BERTopic_Training:Representation model defined successfully.\n","DEBUG:BERTopic_Training:Initializing BERTopic model with multiple representations...\n","DEBUG:BERTopic_Training:BERTopic model initialized with multiple representations.\n","2024-11-02 20:42:02 - INFO - Training BERTopic model...\n","2024-11-02 20:42:02 - INFO - Training BERTopic model...\n","2024-11-02 20:42:02 - INFO - Training BERTopic model...\n","INFO:BERTopic_Training:Training BERTopic model...\n","2024-11-02 20:50:31 - INFO - Model 4 training completed in 509.18 seconds.\n","2024-11-02 20:50:31 - INFO - Model 4 training completed in 509.18 seconds.\n","2024-11-02 20:50:31 - INFO - Model 4 training completed in 509.18 seconds.\n","INFO:BERTopic_Training:Model 4 training completed in 509.18 seconds.\n","2024-11-02 20:50:31 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2\n","2024-11-02 20:50:31 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2\n","2024-11-02 20:50:31 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2\n","INFO:BERTopic_Training:Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2\n","DEBUG:BERTopic_Training:Saving BERTopic model...\n","2024-11-02 20:50:31,406 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n","2024-11-02 20:50:37 - INFO - Model 4 saved at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/bertopic_model_4_iter_0_paraphrase-mpnet-base-v2_20241102_205031.pkl\n","2024-11-02 20:50:37 - INFO - Model 4 saved at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/bertopic_model_4_iter_0_paraphrase-mpnet-base-v2_20241102_205031.pkl\n","2024-11-02 20:50:37 - INFO - Model 4 saved at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/bertopic_model_4_iter_0_paraphrase-mpnet-base-v2_20241102_205031.pkl\n","INFO:BERTopic_Training:Model 4 saved at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/bertopic_model_4_iter_0_paraphrase-mpnet-base-v2_20241102_205031.pkl\n","2024-11-02 20:50:37 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 20:50:37 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 20:50:37 - INFO - Saving topics to CSV and JSON...\n","INFO:BERTopic_Training:Saving topics to CSV and JSON...\n","2024-11-02 20:50:39 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_4_20241102_205031/bertopic_model_4_iter_0_paraphrase-mpnet-base-v2_20241102_205031_topics_info.csv\n","2024-11-02 20:50:39 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_4_20241102_205031/bertopic_model_4_iter_0_paraphrase-mpnet-base-v2_20241102_205031_topics_info.csv\n","2024-11-02 20:50:39 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_4_20241102_205031/bertopic_model_4_iter_0_paraphrase-mpnet-base-v2_20241102_205031_topics_info.csv\n","INFO:BERTopic_Training:Topics info saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_4_20241102_205031/bertopic_model_4_iter_0_paraphrase-mpnet-base-v2_20241102_205031_topics_info.csv\n","2024-11-02 20:50:39 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_4_20241102_205031/bertopic_model_4_iter_0_paraphrase-mpnet-base-v2_20241102_205031_topics.json\n","2024-11-02 20:50:39 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_4_20241102_205031/bertopic_model_4_iter_0_paraphrase-mpnet-base-v2_20241102_205031_topics.json\n","2024-11-02 20:50:39 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_4_20241102_205031/bertopic_model_4_iter_0_paraphrase-mpnet-base-v2_20241102_205031_topics.json\n","INFO:BERTopic_Training:Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_4_20241102_205031/bertopic_model_4_iter_0_paraphrase-mpnet-base-v2_20241102_205031_topics.json\n","Training Models:  40%|████      | 4/10 [27:41<43:23, 433.87s/it]2024-11-02 20:50:39 - INFO - \n","Starting training for model 5/10 with embedding: paraphrase-MiniLM-L6-v2\n","2024-11-02 20:50:39 - INFO - \n","Starting training for model 5/10 with embedding: paraphrase-MiniLM-L6-v2\n","2024-11-02 20:50:39 - INFO - \n","Starting training for model 5/10 with embedding: paraphrase-MiniLM-L6-v2\n","INFO:BERTopic_Training:\n","Starting training for model 5/10 with embedding: paraphrase-MiniLM-L6-v2\n","DEBUG:BERTopic_Training:Initializing UMAP model...\n","DEBUG:BERTopic_Training:UMAP model initialized.\n","DEBUG:BERTopic_Training:Initializing HDBSCAN model...\n","DEBUG:BERTopic_Training:HDBSCAN model initialized.\n","DEBUG:BERTopic_Training:Initializing CountVectorizer...\n","DEBUG:BERTopic_Training:CountVectorizer initialized.\n","DEBUG:BERTopic_Training:Defining representation model based on POS configuration...\n","DEBUG:BERTopic_Training:Representation model defined successfully.\n","DEBUG:BERTopic_Training:Initializing BERTopic model with multiple representations...\n","DEBUG:BERTopic_Training:BERTopic model initialized with multiple representations.\n","2024-11-02 20:50:40 - INFO - Training BERTopic model...\n","2024-11-02 20:50:40 - INFO - Training BERTopic model...\n","2024-11-02 20:50:40 - INFO - Training BERTopic model...\n","INFO:BERTopic_Training:Training BERTopic model...\n","2024-11-02 20:55:23 - INFO - Model 5 training completed in 282.83 seconds.\n","2024-11-02 20:55:23 - INFO - Model 5 training completed in 282.83 seconds.\n","2024-11-02 20:55:23 - INFO - Model 5 training completed in 282.83 seconds.\n","INFO:BERTopic_Training:Model 5 training completed in 282.83 seconds.\n","2024-11-02 20:55:23 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-MiniLM-L6-v2\n","2024-11-02 20:55:23 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-MiniLM-L6-v2\n","2024-11-02 20:55:23 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-MiniLM-L6-v2\n","INFO:BERTopic_Training:Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-MiniLM-L6-v2\n","DEBUG:BERTopic_Training:Saving BERTopic model...\n","2024-11-02 20:55:23,450 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n","2024-11-02 20:55:32 - INFO - Model 5 saved at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-MiniLM-L6-v2/bertopic_model_5_iter_19_paraphrase-MiniLM-L6-v2_20241102_205523.pkl\n","2024-11-02 20:55:32 - INFO - Model 5 saved at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-MiniLM-L6-v2/bertopic_model_5_iter_19_paraphrase-MiniLM-L6-v2_20241102_205523.pkl\n","2024-11-02 20:55:32 - INFO - Model 5 saved at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-MiniLM-L6-v2/bertopic_model_5_iter_19_paraphrase-MiniLM-L6-v2_20241102_205523.pkl\n","INFO:BERTopic_Training:Model 5 saved at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-MiniLM-L6-v2/bertopic_model_5_iter_19_paraphrase-MiniLM-L6-v2_20241102_205523.pkl\n","2024-11-02 20:55:32 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 20:55:32 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 20:55:32 - INFO - Saving topics to CSV and JSON...\n","INFO:BERTopic_Training:Saving topics to CSV and JSON...\n","2024-11-02 20:55:32 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-MiniLM-L6-v2/topics_5_20241102_205523/bertopic_model_5_iter_19_paraphrase-MiniLM-L6-v2_20241102_205523_topics_info.csv\n","2024-11-02 20:55:32 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-MiniLM-L6-v2/topics_5_20241102_205523/bertopic_model_5_iter_19_paraphrase-MiniLM-L6-v2_20241102_205523_topics_info.csv\n","2024-11-02 20:55:32 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-MiniLM-L6-v2/topics_5_20241102_205523/bertopic_model_5_iter_19_paraphrase-MiniLM-L6-v2_20241102_205523_topics_info.csv\n","INFO:BERTopic_Training:Topics info saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-MiniLM-L6-v2/topics_5_20241102_205523/bertopic_model_5_iter_19_paraphrase-MiniLM-L6-v2_20241102_205523_topics_info.csv\n","2024-11-02 20:55:32 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-MiniLM-L6-v2/topics_5_20241102_205523/bertopic_model_5_iter_19_paraphrase-MiniLM-L6-v2_20241102_205523_topics.json\n","2024-11-02 20:55:32 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-MiniLM-L6-v2/topics_5_20241102_205523/bertopic_model_5_iter_19_paraphrase-MiniLM-L6-v2_20241102_205523_topics.json\n","2024-11-02 20:55:32 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-MiniLM-L6-v2/topics_5_20241102_205523/bertopic_model_5_iter_19_paraphrase-MiniLM-L6-v2_20241102_205523_topics.json\n","INFO:BERTopic_Training:Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-MiniLM-L6-v2/topics_5_20241102_205523/bertopic_model_5_iter_19_paraphrase-MiniLM-L6-v2_20241102_205523_topics.json\n","Training Models:  50%|█████     | 5/10 [32:35<31:56, 383.21s/it]2024-11-02 20:55:33 - INFO - \n","Starting training for model 6/10 with embedding: paraphrase-mpnet-base-v2\n","2024-11-02 20:55:33 - INFO - \n","Starting training for model 6/10 with embedding: paraphrase-mpnet-base-v2\n","2024-11-02 20:55:33 - INFO - \n","Starting training for model 6/10 with embedding: paraphrase-mpnet-base-v2\n","INFO:BERTopic_Training:\n","Starting training for model 6/10 with embedding: paraphrase-mpnet-base-v2\n","DEBUG:BERTopic_Training:Initializing UMAP model...\n","DEBUG:BERTopic_Training:UMAP model initialized.\n","DEBUG:BERTopic_Training:Initializing HDBSCAN model...\n","DEBUG:BERTopic_Training:HDBSCAN model initialized.\n","DEBUG:BERTopic_Training:Initializing CountVectorizer...\n","DEBUG:BERTopic_Training:CountVectorizer initialized.\n","DEBUG:BERTopic_Training:Defining representation model based on POS configuration...\n","DEBUG:BERTopic_Training:Representation model defined successfully.\n","DEBUG:BERTopic_Training:Initializing BERTopic model with multiple representations...\n","DEBUG:BERTopic_Training:BERTopic model initialized with multiple representations.\n","2024-11-02 20:55:34 - INFO - Training BERTopic model...\n","2024-11-02 20:55:34 - INFO - Training BERTopic model...\n","2024-11-02 20:55:34 - INFO - Training BERTopic model...\n","INFO:BERTopic_Training:Training BERTopic model...\n","2024-11-02 21:04:11 - INFO - Model 6 training completed in 517.77 seconds.\n","2024-11-02 21:04:11 - INFO - Model 6 training completed in 517.77 seconds.\n","2024-11-02 21:04:11 - INFO - Model 6 training completed in 517.77 seconds.\n","INFO:BERTopic_Training:Model 6 training completed in 517.77 seconds.\n","2024-11-02 21:04:11 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2\n","2024-11-02 21:04:11 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2\n","2024-11-02 21:04:11 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2\n","INFO:BERTopic_Training:Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2\n","DEBUG:BERTopic_Training:Saving BERTopic model...\n","2024-11-02 21:04:11,796 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n","2024-11-02 21:04:20 - INFO - Model 6 saved at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/bertopic_model_6_iter_13_paraphrase-mpnet-base-v2_20241102_210411.pkl\n","2024-11-02 21:04:20 - INFO - Model 6 saved at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/bertopic_model_6_iter_13_paraphrase-mpnet-base-v2_20241102_210411.pkl\n","2024-11-02 21:04:20 - INFO - Model 6 saved at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/bertopic_model_6_iter_13_paraphrase-mpnet-base-v2_20241102_210411.pkl\n","INFO:BERTopic_Training:Model 6 saved at: /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/bertopic_model_6_iter_13_paraphrase-mpnet-base-v2_20241102_210411.pkl\n","2024-11-02 21:04:20 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 21:04:20 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 21:04:20 - INFO - Saving topics to CSV and JSON...\n","INFO:BERTopic_Training:Saving topics to CSV and JSON...\n","2024-11-02 21:04:20 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_6_20241102_210411/bertopic_model_6_iter_13_paraphrase-mpnet-base-v2_20241102_210411_topics_info.csv\n","2024-11-02 21:04:20 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_6_20241102_210411/bertopic_model_6_iter_13_paraphrase-mpnet-base-v2_20241102_210411_topics_info.csv\n","2024-11-02 21:04:20 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_6_20241102_210411/bertopic_model_6_iter_13_paraphrase-mpnet-base-v2_20241102_210411_topics_info.csv\n","INFO:BERTopic_Training:Topics info saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_6_20241102_210411/bertopic_model_6_iter_13_paraphrase-mpnet-base-v2_20241102_210411_topics_info.csv\n","2024-11-02 21:04:20 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_6_20241102_210411/bertopic_model_6_iter_13_paraphrase-mpnet-base-v2_20241102_210411_topics.json\n","2024-11-02 21:04:20 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_6_20241102_210411/bertopic_model_6_iter_13_paraphrase-mpnet-base-v2_20241102_210411_topics.json\n","2024-11-02 21:04:20 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_6_20241102_210411/bertopic_model_6_iter_13_paraphrase-mpnet-base-v2_20241102_210411_topics.json\n","INFO:BERTopic_Training:Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/paraphrase-mpnet-base-v2/topics_6_20241102_210411/bertopic_model_6_iter_13_paraphrase-mpnet-base-v2_20241102_210411_topics.json\n","Training Models:  60%|██████    | 6/10 [41:23<28:49, 432.49s/it]2024-11-02 21:04:21 - INFO - \n","Starting training for model 7/10 with embedding: multi-qa-mpnet-base-cos-v1\n","2024-11-02 21:04:21 - INFO - \n","Starting training for model 7/10 with embedding: multi-qa-mpnet-base-cos-v1\n","2024-11-02 21:04:21 - INFO - \n","Starting training for model 7/10 with embedding: multi-qa-mpnet-base-cos-v1\n","INFO:BERTopic_Training:\n","Starting training for model 7/10 with embedding: multi-qa-mpnet-base-cos-v1\n","DEBUG:BERTopic_Training:Initializing UMAP model...\n","DEBUG:BERTopic_Training:UMAP model initialized.\n","DEBUG:BERTopic_Training:Initializing HDBSCAN model...\n","DEBUG:BERTopic_Training:HDBSCAN model initialized.\n","DEBUG:BERTopic_Training:Initializing CountVectorizer...\n","DEBUG:BERTopic_Training:CountVectorizer initialized.\n","DEBUG:BERTopic_Training:Defining representation model based on POS configuration...\n","DEBUG:BERTopic_Training:Representation model defined successfully.\n","DEBUG:BERTopic_Training:Initializing BERTopic model with multiple representations...\n","DEBUG:BERTopic_Training:BERTopic model initialized with multiple representations.\n","2024-11-02 21:04:22 - INFO - Training BERTopic model...\n","2024-11-02 21:04:22 - INFO - Training BERTopic model...\n","2024-11-02 21:04:22 - INFO - Training BERTopic model...\n","INFO:BERTopic_Training:Training BERTopic model...\n","2024-11-02 21:13:06 - INFO - Model 7 training completed in 524.44 seconds.\n","2024-11-02 21:13:06 - INFO - Model 7 training completed in 524.44 seconds.\n","2024-11-02 21:13:06 - INFO - Model 7 training completed in 524.44 seconds.\n","INFO:BERTopic_Training:Model 7 training completed in 524.44 seconds.\n","2024-11-02 21:13:06 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1\n","2024-11-02 21:13:06 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1\n","2024-11-02 21:13:06 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1\n","INFO:BERTopic_Training:Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1\n","DEBUG:BERTopic_Training:Saving BERTopic model...\n","2024-11-02 21:13:06,575 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n","2024-11-02 21:13:17 - INFO - Model 7 saved at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/bertopic_model_7_iter_23_multi-qa-mpnet-base-cos-v1_20241102_211306.pkl\n","2024-11-02 21:13:17 - INFO - Model 7 saved at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/bertopic_model_7_iter_23_multi-qa-mpnet-base-cos-v1_20241102_211306.pkl\n","2024-11-02 21:13:17 - INFO - Model 7 saved at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/bertopic_model_7_iter_23_multi-qa-mpnet-base-cos-v1_20241102_211306.pkl\n","INFO:BERTopic_Training:Model 7 saved at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/bertopic_model_7_iter_23_multi-qa-mpnet-base-cos-v1_20241102_211306.pkl\n","2024-11-02 21:13:17 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 21:13:17 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 21:13:17 - INFO - Saving topics to CSV and JSON...\n","INFO:BERTopic_Training:Saving topics to CSV and JSON...\n","2024-11-02 21:13:17 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_7_20241102_211306/bertopic_model_7_iter_23_multi-qa-mpnet-base-cos-v1_20241102_211306_topics_info.csv\n","2024-11-02 21:13:17 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_7_20241102_211306/bertopic_model_7_iter_23_multi-qa-mpnet-base-cos-v1_20241102_211306_topics_info.csv\n","2024-11-02 21:13:17 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_7_20241102_211306/bertopic_model_7_iter_23_multi-qa-mpnet-base-cos-v1_20241102_211306_topics_info.csv\n","INFO:BERTopic_Training:Topics info saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_7_20241102_211306/bertopic_model_7_iter_23_multi-qa-mpnet-base-cos-v1_20241102_211306_topics_info.csv\n","2024-11-02 21:13:17 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_7_20241102_211306/bertopic_model_7_iter_23_multi-qa-mpnet-base-cos-v1_20241102_211306_topics.json\n","2024-11-02 21:13:17 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_7_20241102_211306/bertopic_model_7_iter_23_multi-qa-mpnet-base-cos-v1_20241102_211306_topics.json\n","2024-11-02 21:13:17 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_7_20241102_211306/bertopic_model_7_iter_23_multi-qa-mpnet-base-cos-v1_20241102_211306_topics.json\n","INFO:BERTopic_Training:Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_7_20241102_211306/bertopic_model_7_iter_23_multi-qa-mpnet-base-cos-v1_20241102_211306_topics.json\n","Training Models:  70%|███████   | 7/10 [50:20<23:20, 466.68s/it]2024-11-02 21:13:18 - INFO - \n","Starting training for model 8/10 with embedding: all-MiniLM-L12-v2\n","2024-11-02 21:13:18 - INFO - \n","Starting training for model 8/10 with embedding: all-MiniLM-L12-v2\n","2024-11-02 21:13:18 - INFO - \n","Starting training for model 8/10 with embedding: all-MiniLM-L12-v2\n","INFO:BERTopic_Training:\n","Starting training for model 8/10 with embedding: all-MiniLM-L12-v2\n","DEBUG:BERTopic_Training:Initializing UMAP model...\n","DEBUG:BERTopic_Training:UMAP model initialized.\n","DEBUG:BERTopic_Training:Initializing HDBSCAN model...\n","DEBUG:BERTopic_Training:HDBSCAN model initialized.\n","DEBUG:BERTopic_Training:Initializing CountVectorizer...\n","DEBUG:BERTopic_Training:CountVectorizer initialized.\n","DEBUG:BERTopic_Training:Defining representation model based on POS configuration...\n","DEBUG:BERTopic_Training:Representation model defined successfully.\n","DEBUG:BERTopic_Training:Initializing BERTopic model with multiple representations...\n","DEBUG:BERTopic_Training:BERTopic model initialized with multiple representations.\n","2024-11-02 21:13:19 - INFO - Training BERTopic model...\n","2024-11-02 21:13:19 - INFO - Training BERTopic model...\n","2024-11-02 21:13:19 - INFO - Training BERTopic model...\n","INFO:BERTopic_Training:Training BERTopic model...\n","2024-11-02 21:18:11 - INFO - Model 8 training completed in 292.02 seconds.\n","2024-11-02 21:18:11 - INFO - Model 8 training completed in 292.02 seconds.\n","2024-11-02 21:18:11 - INFO - Model 8 training completed in 292.02 seconds.\n","INFO:BERTopic_Training:Model 8 training completed in 292.02 seconds.\n","2024-11-02 21:18:11 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2\n","2024-11-02 21:18:11 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2\n","2024-11-02 21:18:11 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2\n","INFO:BERTopic_Training:Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2\n","DEBUG:BERTopic_Training:Saving BERTopic model...\n","2024-11-02 21:18:11,289 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n","2024-11-02 21:18:16 - INFO - Model 8 saved at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/bertopic_model_8_iter_67_all-MiniLM-L12-v2_20241102_211811.pkl\n","2024-11-02 21:18:16 - INFO - Model 8 saved at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/bertopic_model_8_iter_67_all-MiniLM-L12-v2_20241102_211811.pkl\n","2024-11-02 21:18:16 - INFO - Model 8 saved at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/bertopic_model_8_iter_67_all-MiniLM-L12-v2_20241102_211811.pkl\n","INFO:BERTopic_Training:Model 8 saved at: /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/bertopic_model_8_iter_67_all-MiniLM-L12-v2_20241102_211811.pkl\n","2024-11-02 21:18:16 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 21:18:16 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 21:18:16 - INFO - Saving topics to CSV and JSON...\n","INFO:BERTopic_Training:Saving topics to CSV and JSON...\n","2024-11-02 21:18:16 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_8_20241102_211811/bertopic_model_8_iter_67_all-MiniLM-L12-v2_20241102_211811_topics_info.csv\n","2024-11-02 21:18:16 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_8_20241102_211811/bertopic_model_8_iter_67_all-MiniLM-L12-v2_20241102_211811_topics_info.csv\n","2024-11-02 21:18:16 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_8_20241102_211811/bertopic_model_8_iter_67_all-MiniLM-L12-v2_20241102_211811_topics_info.csv\n","INFO:BERTopic_Training:Topics info saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_8_20241102_211811/bertopic_model_8_iter_67_all-MiniLM-L12-v2_20241102_211811_topics_info.csv\n","2024-11-02 21:18:16 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_8_20241102_211811/bertopic_model_8_iter_67_all-MiniLM-L12-v2_20241102_211811_topics.json\n","2024-11-02 21:18:16 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_8_20241102_211811/bertopic_model_8_iter_67_all-MiniLM-L12-v2_20241102_211811_topics.json\n","2024-11-02 21:18:16 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_8_20241102_211811/bertopic_model_8_iter_67_all-MiniLM-L12-v2_20241102_211811_topics.json\n","INFO:BERTopic_Training:Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/all-MiniLM-L12-v2/topics_8_20241102_211811/bertopic_model_8_iter_67_all-MiniLM-L12-v2_20241102_211811_topics.json\n","Training Models:  80%|████████  | 8/10 [55:19<13:46, 413.24s/it]2024-11-02 21:18:17 - INFO - \n","Starting training for model 9/10 with embedding: multi-qa-mpnet-base-cos-v1\n","2024-11-02 21:18:17 - INFO - \n","Starting training for model 9/10 with embedding: multi-qa-mpnet-base-cos-v1\n","2024-11-02 21:18:17 - INFO - \n","Starting training for model 9/10 with embedding: multi-qa-mpnet-base-cos-v1\n","INFO:BERTopic_Training:\n","Starting training for model 9/10 with embedding: multi-qa-mpnet-base-cos-v1\n","DEBUG:BERTopic_Training:Initializing UMAP model...\n","DEBUG:BERTopic_Training:UMAP model initialized.\n","DEBUG:BERTopic_Training:Initializing HDBSCAN model...\n","DEBUG:BERTopic_Training:HDBSCAN model initialized.\n","DEBUG:BERTopic_Training:Initializing CountVectorizer...\n","DEBUG:BERTopic_Training:CountVectorizer initialized.\n","DEBUG:BERTopic_Training:Defining representation model based on POS configuration...\n","DEBUG:BERTopic_Training:Representation model defined successfully.\n","DEBUG:BERTopic_Training:Initializing BERTopic model with multiple representations...\n","DEBUG:BERTopic_Training:BERTopic model initialized with multiple representations.\n","2024-11-02 21:18:17 - INFO - Training BERTopic model...\n","2024-11-02 21:18:17 - INFO - Training BERTopic model...\n","2024-11-02 21:18:17 - INFO - Training BERTopic model...\n","INFO:BERTopic_Training:Training BERTopic model...\n","2024-11-02 21:27:03 - INFO - Model 9 training completed in 525.93 seconds.\n","2024-11-02 21:27:03 - INFO - Model 9 training completed in 525.93 seconds.\n","2024-11-02 21:27:03 - INFO - Model 9 training completed in 525.93 seconds.\n","INFO:BERTopic_Training:Model 9 training completed in 525.93 seconds.\n","2024-11-02 21:27:03 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1\n","2024-11-02 21:27:03 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1\n","2024-11-02 21:27:03 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1\n","INFO:BERTopic_Training:Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1\n","DEBUG:BERTopic_Training:Saving BERTopic model...\n","2024-11-02 21:27:03,937 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n","2024-11-02 21:27:10 - INFO - Model 9 saved at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/bertopic_model_9_iter_28_multi-qa-mpnet-base-cos-v1_20241102_212703.pkl\n","2024-11-02 21:27:10 - INFO - Model 9 saved at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/bertopic_model_9_iter_28_multi-qa-mpnet-base-cos-v1_20241102_212703.pkl\n","2024-11-02 21:27:10 - INFO - Model 9 saved at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/bertopic_model_9_iter_28_multi-qa-mpnet-base-cos-v1_20241102_212703.pkl\n","INFO:BERTopic_Training:Model 9 saved at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/bertopic_model_9_iter_28_multi-qa-mpnet-base-cos-v1_20241102_212703.pkl\n","2024-11-02 21:27:10 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 21:27:10 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 21:27:10 - INFO - Saving topics to CSV and JSON...\n","INFO:BERTopic_Training:Saving topics to CSV and JSON...\n","2024-11-02 21:27:10 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_9_20241102_212703/bertopic_model_9_iter_28_multi-qa-mpnet-base-cos-v1_20241102_212703_topics_info.csv\n","2024-11-02 21:27:10 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_9_20241102_212703/bertopic_model_9_iter_28_multi-qa-mpnet-base-cos-v1_20241102_212703_topics_info.csv\n","2024-11-02 21:27:10 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_9_20241102_212703/bertopic_model_9_iter_28_multi-qa-mpnet-base-cos-v1_20241102_212703_topics_info.csv\n","INFO:BERTopic_Training:Topics info saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_9_20241102_212703/bertopic_model_9_iter_28_multi-qa-mpnet-base-cos-v1_20241102_212703_topics_info.csv\n","2024-11-02 21:27:10 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_9_20241102_212703/bertopic_model_9_iter_28_multi-qa-mpnet-base-cos-v1_20241102_212703_topics.json\n","2024-11-02 21:27:10 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_9_20241102_212703/bertopic_model_9_iter_28_multi-qa-mpnet-base-cos-v1_20241102_212703_topics.json\n","2024-11-02 21:27:10 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_9_20241102_212703/bertopic_model_9_iter_28_multi-qa-mpnet-base-cos-v1_20241102_212703_topics.json\n","INFO:BERTopic_Training:Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_9_20241102_212703/bertopic_model_9_iter_28_multi-qa-mpnet-base-cos-v1_20241102_212703_topics.json\n","Training Models:  90%|█████████ | 9/10 [1:04:13<07:31, 451.02s/it]2024-11-02 21:27:11 - INFO - \n","Starting training for model 10/10 with embedding: multi-qa-mpnet-base-cos-v1\n","2024-11-02 21:27:11 - INFO - \n","Starting training for model 10/10 with embedding: multi-qa-mpnet-base-cos-v1\n","2024-11-02 21:27:11 - INFO - \n","Starting training for model 10/10 with embedding: multi-qa-mpnet-base-cos-v1\n","INFO:BERTopic_Training:\n","Starting training for model 10/10 with embedding: multi-qa-mpnet-base-cos-v1\n","DEBUG:BERTopic_Training:Initializing UMAP model...\n","DEBUG:BERTopic_Training:UMAP model initialized.\n","DEBUG:BERTopic_Training:Initializing HDBSCAN model...\n","DEBUG:BERTopic_Training:HDBSCAN model initialized.\n","DEBUG:BERTopic_Training:Initializing CountVectorizer...\n","DEBUG:BERTopic_Training:CountVectorizer initialized.\n","DEBUG:BERTopic_Training:Defining representation model based on POS configuration...\n","DEBUG:BERTopic_Training:Representation model defined successfully.\n","DEBUG:BERTopic_Training:Initializing BERTopic model with multiple representations...\n","DEBUG:BERTopic_Training:BERTopic model initialized with multiple representations.\n","2024-11-02 21:27:12 - INFO - Training BERTopic model...\n","2024-11-02 21:27:12 - INFO - Training BERTopic model...\n","2024-11-02 21:27:12 - INFO - Training BERTopic model...\n","INFO:BERTopic_Training:Training BERTopic model...\n","2024-11-02 21:35:44 - INFO - Model 10 training completed in 512.34 seconds.\n","2024-11-02 21:35:44 - INFO - Model 10 training completed in 512.34 seconds.\n","2024-11-02 21:35:44 - INFO - Model 10 training completed in 512.34 seconds.\n","INFO:BERTopic_Training:Model 10 training completed in 512.34 seconds.\n","2024-11-02 21:35:44 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1\n","2024-11-02 21:35:44 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1\n","2024-11-02 21:35:44 - INFO - Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1\n","INFO:BERTopic_Training:Model output directory created at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1\n","DEBUG:BERTopic_Training:Saving BERTopic model...\n","2024-11-02 21:35:44,570 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n","2024-11-02 21:35:51 - INFO - Model 10 saved at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/bertopic_model_10_iter_11_multi-qa-mpnet-base-cos-v1_20241102_213544.pkl\n","2024-11-02 21:35:51 - INFO - Model 10 saved at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/bertopic_model_10_iter_11_multi-qa-mpnet-base-cos-v1_20241102_213544.pkl\n","2024-11-02 21:35:51 - INFO - Model 10 saved at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/bertopic_model_10_iter_11_multi-qa-mpnet-base-cos-v1_20241102_213544.pkl\n","INFO:BERTopic_Training:Model 10 saved at: /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/bertopic_model_10_iter_11_multi-qa-mpnet-base-cos-v1_20241102_213544.pkl\n","2024-11-02 21:35:51 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 21:35:51 - INFO - Saving topics to CSV and JSON...\n","2024-11-02 21:35:51 - INFO - Saving topics to CSV and JSON...\n","INFO:BERTopic_Training:Saving topics to CSV and JSON...\n","2024-11-02 21:35:52 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_10_20241102_213544/bertopic_model_10_iter_11_multi-qa-mpnet-base-cos-v1_20241102_213544_topics_info.csv\n","2024-11-02 21:35:52 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_10_20241102_213544/bertopic_model_10_iter_11_multi-qa-mpnet-base-cos-v1_20241102_213544_topics_info.csv\n","2024-11-02 21:35:52 - INFO - Topics info saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_10_20241102_213544/bertopic_model_10_iter_11_multi-qa-mpnet-base-cos-v1_20241102_213544_topics_info.csv\n","INFO:BERTopic_Training:Topics info saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_10_20241102_213544/bertopic_model_10_iter_11_multi-qa-mpnet-base-cos-v1_20241102_213544_topics_info.csv\n","2024-11-02 21:35:52 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_10_20241102_213544/bertopic_model_10_iter_11_multi-qa-mpnet-base-cos-v1_20241102_213544_topics.json\n","2024-11-02 21:35:52 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_10_20241102_213544/bertopic_model_10_iter_11_multi-qa-mpnet-base-cos-v1_20241102_213544_topics.json\n","2024-11-02 21:35:52 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_10_20241102_213544/bertopic_model_10_iter_11_multi-qa-mpnet-base-cos-v1_20241102_213544_topics.json\n","INFO:BERTopic_Training:Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models/multi-qa-mpnet-base-cos-v1/topics_10_20241102_213544/bertopic_model_10_iter_11_multi-qa-mpnet-base-cos-v1_20241102_213544_topics.json\n","Training Models: 100%|██████████| 10/10 [1:12:55<00:00, 437.55s/it]\n","2024-11-02 21:35:53 - INFO - All models trained and saved.\n","2024-11-02 21:35:53 - INFO - All models trained and saved.\n","2024-11-02 21:35:53 - INFO - All models trained and saved.\n","INFO:BERTopic_Training:All models trained and saved.\n","2024-11-02 21:35:53 - INFO - BERTopic model training and saving completed.\n","2024-11-02 21:35:53 - INFO - BERTopic model training and saving completed.\n","2024-11-02 21:35:53 - INFO - BERTopic model training and saving completed.\n","INFO:BERTopic_Training:BERTopic model training and saving completed.\n","2024-11-02 21:35:53 - INFO - cuML version: 24.10.00\n","2024-11-02 21:35:53 - INFO - cuML version: 24.10.00\n","2024-11-02 21:35:53 - INFO - cuML version: 24.10.00\n","INFO:BERTopic_Training:cuML version: 24.10.00\n","2024-11-02 21:35:53 - INFO - cuGraph version: 24.10.00\n","2024-11-02 21:35:53 - INFO - cuGraph version: 24.10.00\n","2024-11-02 21:35:53 - INFO - cuGraph version: 24.10.00\n","INFO:BERTopic_Training:cuGraph version: 24.10.00\n","2024-11-02 21:35:53 - INFO - cuSpatial version: 24.10.00\n","2024-11-02 21:35:53 - INFO - cuSpatial version: 24.10.00\n","2024-11-02 21:35:53 - INFO - cuSpatial version: 24.10.00\n","INFO:BERTopic_Training:cuSpatial version: 24.10.00\n","2024-11-02 21:35:53 - INFO - cuxfilter version: 24.10.00\n","2024-11-02 21:35:53 - INFO - cuxfilter version: 24.10.00\n","2024-11-02 21:35:53 - INFO - cuxfilter version: 24.10.00\n","INFO:BERTopic_Training:cuxfilter version: 24.10.00\n"]}]}]}