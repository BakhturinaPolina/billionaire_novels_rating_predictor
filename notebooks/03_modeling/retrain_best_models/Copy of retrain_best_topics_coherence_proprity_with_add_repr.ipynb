{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1lFjJFnZoBWDZSQVgeX4V3kiNe_lOK_ob","timestamp":1730585839269},{"file_id":"16rPidZMyOaYcykI9zB0Ul0phx9suxIvz","timestamp":1730562240174}],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyMJnJ9PPih73eV0yN+3bWSA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# ==============================\n","# 1. Setup and Installation\n","# ==============================\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Check CUDA and driver versions\n","!nvcc --version  # Check CUDA version\n","!nvidia-smi      # Check driver version\n","\n","# Install RAPIDS and other required libraries\n","!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n","!python rapidsai-csp-utils/colab/pip-install.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"9OivEorQmNym","executionInfo":{"status":"ok","timestamp":1761676495560,"user_tz":-60,"elapsed":2538,"user":{"displayName":"Polina Bakhturina","userId":"07881954271877753559"}},"outputId":"6678e6fc-352a-4624-e507-987bff2b10e0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2024 NVIDIA Corporation\n","Built on Thu_Jun__6_02:18:23_PDT_2024\n","Cuda compilation tools, release 12.5, V12.5.82\n","Build cuda_12.5.r12.5/compiler.34385749_0\n","Tue Oct 28 18:34:54 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n","fatal: destination path 'rapidsai-csp-utils' already exists and is not an empty directory.\n","Installing RAPIDS remaining 25.08 libraries\n","Using Python 3.12.12 environment at: /usr\n","Audited 9 packages in 96ms\n","\n","        ***********************************************************************\n","        The pip install of RAPIDS is complete.\n","\n","        Please do not run any further installation from the conda based installation methods, as they may cause issues!\n","\n","        Please ensure that you're pulling from the git repo to remain updated with the latest working install scripts.\n","\n","        Troubleshooting:\n","            - If there is an installation failure, please check back on RAPIDSAI owned templates/notebooks to see how to update your personal files.\n","            - If an installation failure persists when using the latest script, please make an issue on https://github.com/rapidsai-community/rapidsai-csp-utils\n","        ***********************************************************************\n","        \n"]}]},{"cell_type":"code","source":["## After restarting, install remaining necessary libraries\n","# Run this cell after restarting the runtime\n","!pip install bertopic==0.16.3\n","!pip install octis\n","!pip install sentence-transformers\n","!pip install umap-learn==0.5.3  # Specify a compatible version\n","!pip install hdbscan\n","!pip install tqdm\n","!pip install pandas\n","!pip install gensim\n","!pip install wandb\n","!pip install umap\n","!pip install scipy\n","!pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oco0mYO-p5BY","outputId":"3b4107ee-7c33-4fef-95b9-ebfc09491e46","collapsed":true,"executionInfo":{"status":"ok","timestamp":1761676579117,"user_tz":-60,"elapsed":76826,"user":{"displayName":"Polina Bakhturina","userId":"07881954271877753559"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bertopic==0.16.3\n","  Downloading bertopic-0.16.3-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.12/dist-packages (from bertopic==0.16.3) (0.8.40)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.12/dist-packages (from bertopic==0.16.3) (2.0.2)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.12/dist-packages (from bertopic==0.16.3) (2.2.2)\n","Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from bertopic==0.16.3) (5.24.1)\n","Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.12/dist-packages (from bertopic==0.16.3) (1.6.1)\n","Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from bertopic==0.16.3) (5.1.2)\n","Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.12/dist-packages (from bertopic==0.16.3) (4.67.1)\n","Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from bertopic==0.16.3) (0.5.9.post2)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.12/dist-packages (from hdbscan>=0.8.29->bertopic==0.16.3) (1.16.2)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from hdbscan>=0.8.29->bertopic==0.16.3) (1.5.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->bertopic==0.16.3) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->bertopic==0.16.3) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->bertopic==0.16.3) (2025.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly>=4.7.0->bertopic==0.16.3) (8.5.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly>=4.7.0->bertopic==0.16.3) (25.0)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.2.post1->bertopic==0.16.3) (3.6.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=0.4.1->bertopic==0.16.3) (4.57.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=0.4.1->bertopic==0.16.3) (2.8.0+cu126)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=0.4.1->bertopic==0.16.3) (0.36.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=0.4.1->bertopic==0.16.3) (11.3.0)\n","Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=0.4.1->bertopic==0.16.3) (4.15.0)\n","Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.12/dist-packages (from umap-learn>=0.5.0->bertopic==0.16.3) (0.60.0)\n","Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.12/dist-packages (from umap-learn>=0.5.0->bertopic==0.16.3) (0.5.13)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (3.20.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (2025.3.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (6.0.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (2.32.4)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (1.2.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic==0.16.3) (0.43.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic==0.16.3) (1.17.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (3.4.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (2024.11.6)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (0.6.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic==0.16.3) (2025.10.5)\n","Downloading bertopic-0.16.3-py3-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bertopic\n","Successfully installed bertopic-0.16.3\n","Collecting octis\n","  Downloading octis-1.14.0-py2.py3-none-any.whl.metadata (27 kB)\n","Collecting gensim<5.0,>=4.2.0 (from octis)\n","  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from octis) (3.9.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from octis) (2.2.2)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (from octis) (3.8.7)\n","Collecting scikit-learn==1.1.0 (from octis)\n","  Downloading scikit-learn-1.1.0.tar.gz (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","\n","\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n","\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n","Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.10.5)\n","Collecting umap-learn==0.5.3\n","  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from umap-learn==0.5.3) (2.0.2)\n","Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.12/dist-packages (from umap-learn==0.5.3) (1.6.1)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.12/dist-packages (from umap-learn==0.5.3) (1.16.2)\n","Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.12/dist-packages (from umap-learn==0.5.3) (0.60.0)\n","Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.12/dist-packages (from umap-learn==0.5.3) (0.5.13)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from umap-learn==0.5.3) (4.67.1)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.49->umap-learn==0.5.3) (0.43.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from pynndescent>=0.5->umap-learn==0.5.3) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22->umap-learn==0.5.3) (3.6.0)\n","Building wheels for collected packages: umap-learn\n","  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82810 sha256=46c45b87b553d3c930957fe4d9e3e745bb303dfe13cea6f095bd7cb78d451712\n","  Stored in directory: /root/.cache/pip/wheels/6b/a6/5c/466a36f7e4073169aa2ed85b749b1f56c0da07b0c86d0f7750\n","Successfully built umap-learn\n","Installing collected packages: umap-learn\n","  Attempting uninstall: umap-learn\n","    Found existing installation: umap-learn 0.5.9.post2\n","    Uninstalling umap-learn-0.5.9.post2:\n","      Successfully uninstalled umap-learn-0.5.9.post2\n","Successfully installed umap-learn-0.5.3\n","Requirement already satisfied: hdbscan in /usr/local/lib/python3.12/dist-packages (0.8.40)\n","Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.12/dist-packages (from hdbscan) (2.0.2)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.12/dist-packages (from hdbscan) (1.16.2)\n","Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.12/dist-packages (from hdbscan) (1.6.1)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from hdbscan) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.20->hdbscan) (3.6.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Collecting gensim\n","  Using cached gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.2)\n","Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n","Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: gensim\n","Successfully installed gensim-4.4.0\n","Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.2)\n","Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n","Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.10)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.42.1)\n","Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n","Collecting umap\n","  Downloading umap-0.1.1.tar.gz (3.2 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: umap\n","  Building wheel for umap (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap: filename=umap-0.1.1-py3-none-any.whl size=3541 sha256=37671c35714048c68233bb3c23b820e51092421fee764ede201fe0c03fd746f1\n","  Stored in directory: /root/.cache/pip/wheels/48/4a/1c/1d511cbb0413a448d8546e958f8e82b98d9bb493038d19ece2\n","Successfully built umap\n","Installing collected packages: umap\n","Successfully installed umap-0.1.1\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.2)\n","Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy) (2.0.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"]}]},{"cell_type":"code","source":["!pip list | grep umap"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gfgbEMf7F6Ij","executionInfo":{"status":"ok","timestamp":1746896425852,"user_tz":-120,"elapsed":1202,"user":{"displayName":"Polina Bakhturina","userId":"07881954271877753559"}},"outputId":"6f24fb39-aa22-4efa-dc61-4cd6fb4533c3","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["umap                                  0.1.1\n","umap-learn                            0.5.3\n"]}]},{"cell_type":"code","source":["!pip uninstall -y umap"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S93BrsZVF_Dv","executionInfo":{"status":"ok","timestamp":1746896426704,"user_tz":-120,"elapsed":848,"user":{"displayName":"Polina Bakhturina","userId":"07881954271877753559"}},"outputId":"2f10c12f-94ef-4c57-d62b-57d997f88d5d","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: umap 0.1.1\n","Uninstalling umap-0.1.1:\n","  Successfully uninstalled umap-0.1.1\n"]}]},{"cell_type":"code","source":["!find . -type d -name \"__pycache__\" -exec rm -r {} +"],"metadata":{"id":"-aDvGu_mGBU5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install --upgrade bertopic umap-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"jszgh5trGJuL","executionInfo":{"status":"ok","timestamp":1746896496775,"user_tz":-120,"elapsed":2916,"user":{"displayName":"Polina Bakhturina","userId":"07881954271877753559"}},"outputId":"967f9b25-1e8f-407e-e5c3-7ae8e42dd5f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: bertopic in /usr/local/lib/python3.11/dist-packages (0.16.3)\n","Collecting bertopic\n","  Downloading bertopic-0.17.0-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (0.5.3)\n","Collecting umap-learn\n","  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.8.40)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (1.26.4)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.2.2)\n","Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (5.24.1)\n","Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (1.6.1)\n","Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (3.4.1)\n","Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (4.67.1)\n","Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (1.13.1)\n","Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.60.0)\n","Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.5.13)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic) (1.4.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (9.1.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (24.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->bertopic) (3.6.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.51.3)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.6.0+cu124)\n","Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.30.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (11.2.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.3.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (4.13.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.17.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.5.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.4.26)\n","Downloading bertopic-0.17.0-py3-none-any.whl (150 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: umap-learn, bertopic\n","  Attempting uninstall: umap-learn\n","    Found existing installation: umap-learn 0.5.3\n","    Uninstalling umap-learn-0.5.3:\n","      Successfully uninstalled umap-learn-0.5.3\n","  Attempting uninstall: bertopic\n","    Found existing installation: bertopic 0.16.3\n","    Uninstalling bertopic-0.16.3:\n","      Successfully uninstalled bertopic-0.16.3\n","Successfully installed bertopic-0.17.0 umap-learn-0.5.7\n"]}]},{"cell_type":"code","source":["import os\n","import time\n","import logging\n","import traceback\n","import pandas as pd\n","from tqdm import tqdm\n","from datetime import datetime\n","from bertopic import BERTopic\n","from tenacity import (\n","    retry,\n","    stop_after_attempt,\n","    wait_exponential,\n","    retry_if_exception_type\n",")\n","import requests\n","import json\n","\n","# ========== CONFIGURATION ==========\n","OPENROUTER_API_KEY = \"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\"\n","os.environ[\"OPENAI_API_KEY\"] = OPENROUTER_API_KEY\n","\n","# Primary and fallback models\n","PRIMARY_MODEL = \"perplexity/sonar-deep-research\"\n","FALLBACK_MODEL = \"openai/gpt-3.5-turbo\"\n","\n","# File paths\n","FAILED_LOG_PATH = \"topic_labeling_errors.log\"\n","MODEL_PATH = \"/content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-mpnet-base-v2_Model_1_POS_a/bertopic_model_iter_1_paraphrase-mpnet-base-v2_POS_a.pkl\"\n","OUTPUT_CSV = \"/content/drive/MyDrive/BERTTopic_Models_POS/verified_labeled_topics.csv\"\n","TOPIC_LIMIT = 364\n","DEBUG_MODE = True  # Set to True for verbose logging\n","\n","# ========== ENHANCED PROMPT TEMPLATE ==========\n","PROMPT_TEMPLATE = \"\"\"\n","Generate a topic label with EXACTLY 6 TAB-SEPARATED components based on these detailed guidelines:\n","\n","1. CHARACTER DYNAMICS: Relationships, interactions, or conflicts between characters\n","   • Example types: \"Rivalry Turned Alliance\", \"Unrequited Love\", \"Mentor-Protégé Conflict\"\n","   • If keywords like \"friend\", \"love\", \"trust\", \"betray\" appear, include this component\n","   • Use \"None\" if no clear character dynamics are present\n","\n","2. THEMES: Abstract ideas representing moral, philosophical, or ideological concerns\n","   • Example types: \"Duty vs. Desire\", \"The Power of Redemption\", \"Class Struggles\"\n","   • ALWAYS include a theme, even if abstract or general\n","   • For objects/places, focus on what they represent (e.g., \"doors\" → \"Transitions and Boundaries\")\n","\n","3. SETTINGS: Physical locations or conceptual environments\n","   • Example types: \"Haunted Castle\", \"War-Torn Battlefield\", \"Urban Underworld\"\n","   • Use \"None\" if no clear setting is indicated in keywords\n","   • Be specific but not overly speculative\n","\n","4. ACTIONS & EVENTS: Plot-driven occurrences advancing the narrative\n","   • Example types: \"Betrayal and Retribution\", \"Quest for Identity\", \"Escape from Captivity\"\n","   • Focus on actions mentioned in keywords\n","   • Use \"None\" if no clear events are indicated\n","\n","5. EMOTIONAL ATMOSPHERE: Overall mood and emotional impact\n","   • Format: \"Mood - [emotion]\" (e.g., \"Mood - Cheerful\", \"Mood - Tense\")\n","   • Use \"Mood - Cheerful\" for positive emotions (smile, laugh)\n","   • Use \"Mood - Tense\" for conflict/danger (war, fight)\n","   • Default to \"Mood - Neutral\" for neutral topics\n","\n","6. REPRESENTATION: How the topic is portrayed\n","   • Format: \"Portrayal - [tone]\" (e.g., \"Portrayal - Positive\", \"Portrayal - Serious\")\n","   • Use \"Portrayal - Positive\" for topics portrayed favorably\n","   • Use \"Portrayal - Serious\" for grave or solemn topics\n","   • Default to \"Portrayal - Neutral\" for neutral topics\n","\n","IMPORTANT EXAMPLES FROM EXISTING TOPICS:\n","\n","Topic: smile, laugh, grin\n","Friendly Camaraderie\\tJoy and Lightheartedness\\tJoyous Social Gatherings\\tFestive or Cheerful Gatherings\\tMood - Cheerful\\tPortrayal - Positive\n","\n","Topic: war, combat, battle\n","Allies and Enemies in Battle\\tConflict and Warfare\\tWar-Torn Battlefield\\tWar and Combat\\tMood - Tense\\tPortrayal - Serious\n","\n","Topic: door, doorway, entrance\n","None\\tTransitions and Boundaries\\tEntrances & Corridors\\tEntering and Exiting\\tMood - Neutral\\tPortrayal - Neutral\n","\n","Topic: kiss, kissed, embrace\n","Romantic Intimacy\\tLove and Affection\\tPrivate Romantic Spaces\\tKissing and Embracing\\tMood - Affectionate\\tPortrayal - Positive\n","\n","RULES:\n","- Use exactly ONE tab (\\\\t) between components\n","- Be descriptive but concise for each component\n","- Use \"None\" when appropriate for dynamics, settings, or events\n","- ALWAYS provide a theme (never \"None\" for theme component)\n","- Follow the mood and portrayal formats exactly\n","- Return ONLY the 6 tab-separated components with no other text\n","\n","YOUR TASK:\n","For the following keywords, provide 6 tab-separated components following the guidelines above.\n","\n","TOPIC KEYWORDS: [KEYWORDS]\n","REPRESENTATIVE DOCUMENTS:\n","[DOCUMENTS]\n","\"\"\"\n","\n","# ========== LABEL GENERATOR USING OPENROUTER ==========\n","class TopicLabelGenerator:\n","    def __init__(self):\n","        self.api_key = os.environ[\"OPENAI_API_KEY\"]\n","        self.primary_model = PRIMARY_MODEL\n","        self.fallback_model = FALLBACK_MODEL\n","        self.prompt = PROMPT_TEMPLATE\n","        self.api_url = \"https://openrouter.ai/api/v1/chat/completions\"\n","        self.debug = DEBUG_MODE\n","\n","    def generate_label(self, keywords, documents):\n","        \"\"\"Main method to generate labels with fallback mechanism\"\"\"\n","        try:\n","            if self.debug:\n","                print(f\"\\nTrying primary model: {self.primary_model}\")\n","\n","            return self._call_api(self.primary_model, keywords, documents)\n","\n","        except Exception as e:\n","            if self.debug:\n","                print(f\"Primary model failed: {str(e)[:200]}...\")\n","                print(f\"Trying fallback model: {self.fallback_model}\")\n","\n","            try:\n","                return self._call_api(self.fallback_model, keywords, documents)\n","\n","            except Exception as e2:\n","                if self.debug:\n","                    print(f\"Fallback model also failed: {str(e2)[:200]}...\")\n","                    print(\"Using default label generator\")\n","\n","                return self._create_fallback_label(keywords)\n","\n","    @retry(\n","        stop=stop_after_attempt(3),\n","        wait=wait_exponential(multiplier=1, min=2, max=30),\n","        retry=retry_if_exception_type((requests.exceptions.RequestException, ValueError)),\n","        reraise=True\n","    )\n","    def _call_api(self, model, keywords, documents):\n","        \"\"\"Make the actual API call with retries\"\"\"\n","        truncated_docs = [doc[:300] + \"...\" if len(doc) > 300 else doc for doc in documents[:3]]\n","        prompt = self.prompt.replace(\"[KEYWORDS]\", \", \".join(keywords))\n","        prompt = prompt.replace(\"[DOCUMENTS]\", \"\\n---\\n\".join(truncated_docs))\n","\n","        payload = {\n","            \"model\": model,\n","            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n","        }\n","\n","        headers = {\n","            \"Authorization\": f\"Bearer {self.api_key}\",\n","            \"Content-Type\": \"application/json\",\n","            \"HTTP-Referer\": \"https://yourdomain.com\",\n","            \"X-Title\": \"BERTopic_Labeling_Pipeline\"\n","        }\n","\n","        try:\n","            response = requests.post(self.api_url, headers=headers, json=payload, timeout=60)\n","\n","            # Debug response info\n","            if self.debug:\n","                print(f\"Status code: {response.status_code}\")\n","\n","            if response.status_code != 200:\n","                error_msg = f\"HTTP {response.status_code}: {response.text}\"\n","                if self.debug:\n","                    print(f\"API error: {error_msg}\")\n","                raise ValueError(error_msg)\n","\n","            try:\n","                result = response.json()\n","            except json.JSONDecodeError:\n","                if self.debug:\n","                    print(f\"Failed to parse JSON from response: {response.text[:500]}...\")\n","                raise ValueError(\"Invalid JSON response\")\n","\n","            # Verbose debugging of the response\n","            if self.debug:\n","                print(f\"Response keys: {list(result.keys())}\")\n","\n","            # Check if choices exists\n","            if 'choices' not in result:\n","                if self.debug:\n","                    print(f\"Missing 'choices' key. Response: {json.dumps(result)[:500]}...\")\n","                raise ValueError(f\"Missing 'choices' in response: {json.dumps(result)[:200]}...\")\n","\n","            if not result['choices'] or not isinstance(result['choices'], list):\n","                if self.debug:\n","                    print(f\"Invalid 'choices' format: {result.get('choices', 'None')}\")\n","                raise ValueError(\"Invalid choices format in response\")\n","\n","            try:\n","                content = result[\"choices\"][0][\"message\"][\"content\"].strip()\n","                return self._validate_label(content, keywords)\n","            except (KeyError, IndexError, TypeError) as e:\n","                if self.debug:\n","                    print(f\"Error extracting content: {str(e)}\")\n","                    print(f\"Choices structure: {json.dumps(result.get('choices', []))[:300]}...\")\n","                raise ValueError(f\"Bad response format: {str(e)}\")\n","\n","        except requests.exceptions.RequestException as e:\n","            if self.debug:\n","                print(f\"Request exception: {str(e)}\")\n","            raise\n","\n","    def _create_fallback_label(self, keywords):\n","        \"\"\"Create a fallback label when both APIs fail\"\"\"\n","        topic_name = keywords[0].capitalize() if keywords else \"Unknown Topic\"\n","        secondary_word = keywords[1].capitalize() if len(keywords) > 1 else \"\"\n","        theme = f\"{topic_name} and {secondary_word}\" if secondary_word else f\"{topic_name} and Related Concepts\"\n","\n","        return {\n","            \"Character_Dynamics\": \"None\",\n","            \"Themes\": theme,\n","            \"Settings\": \"None\",\n","            \"Actions_Events\": \"None\",\n","            \"Emotional_Atmosphere\": \"Mood - Neutral\",\n","            \"Representation\": \"Portrayal - Neutral\"\n","        }\n","\n","    def _validate_label(self, label, keywords):\n","        \"\"\"Validate and fix the label structure if needed\"\"\"\n","        if not label or not isinstance(label, str):\n","            if self.debug:\n","                print(f\"Invalid label response: {label}\")\n","            return self._create_fallback_label(keywords)\n","\n","        try:\n","            parts = label.split('\\t')\n","\n","            # Handle case where model doesn't use tabs properly\n","            if len(parts) == 1:\n","                parts = label.split('   ')\n","\n","            # If still not good, try line breaks\n","            if len(parts) == 1:\n","                parts = label.split('\\n')\n","\n","            # Filter out empty parts\n","            parts = [p for p in parts if p.strip()]\n","\n","            if self.debug:\n","                print(f\"Split result: {parts} (length: {len(parts)})\")\n","\n","            # If we don't have 6 components, create reasonable defaults\n","            if len(parts) != 6:\n","                if self.debug:\n","                    print(f\"Expected 6 components, got {len(parts)}: {parts}\")\n","                return self._create_fallback_label(keywords)\n","\n","            dynamic, theme, setting, action_event, mood, portrayal = [p.strip() for p in parts]\n","\n","            # Fix common issues\n","            if not theme or theme.lower() == \"none\":\n","                theme = f\"{keywords[0].capitalize()} and Related Concepts\" if keywords else \"Topic\"\n","            if not mood.startswith(\"Mood - \"):\n","                mood = \"Mood - \" + mood\n","            if not portrayal.startswith(\"Portrayal - \"):\n","                portrayal = \"Portrayal - \" + portrayal\n","\n","            return {\n","                \"Character_Dynamics\": dynamic,\n","                \"Themes\": theme,\n","                \"Settings\": setting,\n","                \"Actions_Events\": action_event,\n","                \"Emotional_Atmosphere\": mood,\n","                \"Representation\": portrayal\n","            }\n","\n","        except Exception as e:\n","            if self.debug:\n","                print(f\"Label validation error: {str(e)}\")\n","            return self._create_fallback_label(keywords)\n","\n","# ========== PIPELINE FUNCTIONS ==========\n","\n","def initialize_logging():\n","    \"\"\"Set up logging to file and console\"\"\"\n","    logging.basicConfig(\n","        filename=FAILED_LOG_PATH,\n","        level=logging.INFO,\n","        format=\"%(asctime)s - %(levelname)s - Topic %(topic_id)s: %(message)s\",\n","        filemode='w'\n","    )\n","    console = logging.StreamHandler()\n","    console.setLevel(logging.INFO)\n","    formatter = logging.Formatter('%(message)s')\n","    console.setFormatter(formatter)\n","    logging.getLogger('').addHandler(console)\n","\n","def load_model():\n","    \"\"\"Load the BERTopic model from disk\"\"\"\n","    print(f\"\\n🔍 Loading BERTopic model from: {MODEL_PATH}\")\n","    try:\n","        model = BERTopic.load(MODEL_PATH)\n","        topic_info = model.get_topic_info()\n","        print(f\"✅ Successfully loaded model with {len(topic_info)} topics\")\n","        print(\"\\nSample topics:\")\n","        print(topic_info.head(3))\n","        return model\n","    except Exception as e:\n","        logging.critical(f\"Model loading failed: {str(e)}\")\n","        raise RuntimeError(f\"Could not load model: {str(e)}\")\n","\n","def process_topics(model, limit=TOPIC_LIMIT):\n","    \"\"\"Process topics to generate labels\"\"\"\n","    generator = TopicLabelGenerator()\n","    results = []\n","\n","    # Get topics (excluding -1 which is typically outliers/noise)\n","    valid_topics = [t for t in model.get_topics() if t != -1][:limit]\n","    print(f\"Processing {len(valid_topics)} topics...\")\n","\n","    for topic_id in tqdm(valid_topics, desc=\"Labeling Topics\"):\n","        try:\n","            # Extract keywords and documents\n","            keywords = [w for w, _ in model.get_topic(topic_id)[:8]]\n","            docs = model.get_representative_docs(topic_id) or [\"No documents available\"]\n","\n","            # Try to generate the label\n","            label_data = generator.generate_label(keywords, docs)\n","\n","            # Store the result\n","            result = {\n","                \"Topic_ID\": topic_id,\n","                \"Keywords\": \", \".join(keywords),\n","                **label_data,\n","                \"Sample_Document\": docs[0][:200] + \"...\" if docs else \"No document\",\n","                \"Status\": \"Success\"\n","            }\n","            results.append(result)\n","\n","            # Small delay to avoid rate limits\n","            time.sleep(1)\n","\n","        except Exception as e:\n","            error_msg = str(e)[:200]\n","            logging.error(\n","                f\"Topic {topic_id} processing failed: {error_msg}\",\n","                extra={\"topic_id\": topic_id}\n","            )\n","\n","            # Still add an entry with the error info\n","            fallback_theme = f\"{keywords[0].capitalize()} and Related Concepts\" if 'keywords' in locals() and keywords else \"Unknown\"\n","            results.append({\n","                \"Topic_ID\": topic_id,\n","                \"Keywords\": \", \".join(keywords) if 'keywords' in locals() else \"Unknown\",\n","                \"Character_Dynamics\": \"Error\",\n","                \"Themes\": fallback_theme,\n","                \"Settings\": \"Error\",\n","                \"Actions_Events\": \"Error\",\n","                \"Emotional_Atmosphere\": \"Mood - Neutral\",\n","                \"Representation\": \"Portrayal - Neutral\",\n","                \"Sample_Document\": docs[0][:200] + \"...\" if 'docs' in locals() and docs else \"\",\n","                \"Status\": f\"Error: {error_msg}\"\n","            })\n","\n","    return pd.DataFrame(results)\n","\n","def save_results(df):\n","    \"\"\"Save results to CSV with timestamp\"\"\"\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    output_dir = os.path.dirname(OUTPUT_CSV)\n","\n","    # Create directory if it doesn't exist\n","    if output_dir and not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    output_path = f\"{os.path.splitext(OUTPUT_CSV)[0]}_{timestamp}.csv\"\n","\n","    # Calculate success rate\n","    success_rate = len(df[df['Status'] == 'Success']) / len(df) if len(df) > 0 else 0\n","    df['Metadata'] = f\"Success rate: {success_rate:.1%} | Generated: {timestamp}\"\n","\n","    # Save to CSV\n","    df.to_csv(output_path, index=False)\n","    print(f\"\\n💾 Saved results to: {output_path}\")\n","    print(f\"✅ Success rate: {success_rate:.1%}\")\n","\n","    # Print sample successful labels\n","    if success_rate > 0:\n","        print(\"\\nSample successful labels:\")\n","        success_df = df[df['Status'] == 'Success'].head(3)\n","        for _, row in success_df.iterrows():\n","            print(f\"\\nTopic {row['Topic_ID']}: {row['Keywords']}\")\n","            print(f\"  • Character Dynamics: {row['Character_Dynamics']}\")\n","            print(f\"  • Theme: {row['Themes']}\")\n","            print(f\"  • Setting: {row['Settings']}\")\n","            print(f\"  • Actions/Events: {row['Actions_Events']}\")\n","            print(f\"  • Mood: {row['Emotional_Atmosphere']}\")\n","            print(f\"  • Portrayal: {row['Representation']}\")\n","\n","    return output_path\n","\n","def main():\n","    \"\"\"Main pipeline function\"\"\"\n","    initialize_logging()\n","    try:\n","        model = load_model()\n","        print(f\"\\n🚀 Starting to process up to {TOPIC_LIMIT} topics...\")\n","        start_time = time.time()\n","        results_df = process_topics(model)\n","        output_file = save_results(results_df)\n","        elapsed = time.time() - start_time\n","        print(f\"\\n🏁 Process completed in {elapsed:.1f} seconds\")\n","        print(f\"📊 Results saved to: {output_file}\")\n","        print(f\"📋 Error log: {FAILED_LOG_PATH}\")\n","    except Exception as e:\n","        logging.critical(f\"Pipeline failed: {str(e)}\\n{traceback.format_exc()}\")\n","        print(f\"⛔ Critical error: {str(e)}\")\n","        print(f\"Stack trace:\\n{traceback.format_exc()}\")\n","        exit(1)\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZgijYJ-yqJKb","outputId":"b830bb38-7d64-4188-a561-fbed89d2e658"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","🔍 Loading BERTopic model from: /content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-mpnet-base-v2_Model_1_POS_a/bertopic_model_iter_1_paraphrase-mpnet-base-v2_POS_a.pkl\n","✅ Successfully loaded model with 364 topics\n","\n","Sample topics:\n","   Topic   Count                             Name  \\\n","0     -1  113001  -1_thought_think_thoughts_speak   \n","1      0    4846   0_smiled_smile_smiles_grinning   \n","2      1    2847     1_dress_dresses_gowns_attire   \n","\n","                                      Representation  \\\n","0  [thought, think, thoughts, speak, seemed, say,...   \n","1  [smiled, smile, smiles, grinning, smirking, gr...   \n","2  [dress, dresses, gowns, attire, clothing, gown...   \n","\n","                                               NOUNS  \\\n","0  [hands, way, words, arms, room, body, arm, mom...   \n","1  [smile, grin, smiles, joke, laughs, chuckle, g...   \n","2  [dress, hat, shirt, gown, trousers, clothes, j...   \n","\n","                                 Representative_Docs  \n","0  [says hard say words inside released hit chest...  \n","1  [help smile back, bit back smile, smiled smile...  \n","2  [appeared wearing elegant dress matching hat, ...  \n","\n","🚀 Starting to process up to 364 topics...\n","Processing 363 topics...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   0%|          | 0/363 [00:00<?, ?it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Friendly Camaraderie', 'Joy and Lightheartedness', 'Joyous Social Gatherings', 'Festive or Cheerful Gatherings', 'Mood - Cheerful', 'Portrayal - Positive'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   0%|          | 1/363 [00:43<4:20:52, 43.24s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Clothing as Identity and Social Stratification', 'Social and Cultural Spheres', 'Dressing and Adornment', 'Mood - Contemplative', 'Portrayal - Serious'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   1%|          | 2/363 [01:25<4:17:29, 42.80s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Allies and Enemies in Battle', 'Conflict and Warfare', 'War-Torn Battlefield', 'War and Combat', 'Mood - Tense', 'Portrayal - Serious'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   1%|          | 3/363 [02:40<5:44:23, 57.40s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Transitions and Boundaries', 'Threshold Spaces', 'Entering and Exiting', 'Mood - Neutral', 'Portrayal - Neutral'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   1%|          | 4/363 [03:17<4:56:10, 49.50s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Spousal Relationships and Conflicts', 'Marital Bonds and Challenges', 'Domestic and Social Spheres', 'Weddings and Marital Conflict Resolution', 'Mood - Complex', 'Portrayal - Analytical'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   1%|▏         | 5/363 [04:32<5:49:44, 58.62s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Romantic Intimacy', 'Love and Affection', 'Private Romantic Spaces', 'Kissing and Caressing', 'Mood - Affectionate', 'Portrayal - Positive'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   2%|▏         | 6/363 [05:06<4:58:48, 50.22s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Inner Self and Psychological Spaces', 'Multilevel Domestic Spaces', 'Navigation of Domestic Spaces', 'Mood - Neutral', 'Portrayal - Analytical'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   2%|▏         | 7/363 [05:41<4:28:49, 45.31s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Instructor-Student Instructional Relationships', 'Knowledge as Empowerment through Education', 'Academic Lecture Halls and Classrooms', 'Teaching and Lecturing Strategies', 'Mood - Neutral', 'Portrayal - Positive'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   2%|▏         | 8/363 [06:31<4:35:54, 46.63s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Mystery and Transition', 'Nighttime Environments', 'None', 'Mood - Neutral', 'Portrayal - Neutral'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   2%|▏         | 9/363 [07:18<4:36:38, 46.89s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Collaborative Knowledge Sharing', 'Access to Knowledge and Learning', 'Libraries & Bookstores', 'Reading and Organizing Literature', 'Mood - Neutral', 'Portrayal - Positive'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   3%|▎         | 10/363 [08:18<4:58:40, 50.77s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Life Force and Spiritual Connection', 'None', 'Breathing and Exhalation', 'Mood - Neutral', 'Portrayal - Positive'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   3%|▎         | 11/363 [08:47<4:19:17, 44.20s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Power Dynamics Through Observation', 'Power Dynamics and Perception', 'None', 'Acts of Observation and Scrutiny', 'Mood - Intense', 'Portrayal - Serious'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   3%|▎         | 12/363 [09:19<3:57:10, 40.54s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Grief Support Bonds', 'Catharsis Through Tears', 'Therapeutic Spaces', 'Emotional Release Episodes', 'Mood - Melancholic', 'Portrayal - Therapeutic'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   4%|▎         | 13/363 [09:52<3:42:54, 38.21s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Gender Identity and Empowerment', 'None', 'None', 'Mood - Neutral', 'Portrayal - Positive'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   4%|▍         | 14/363 [10:23<3:30:23, 36.17s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Wealth and Morality', 'None', 'Financial Transactions and Management', 'Mood - Tense', 'Portrayal - Serious'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   4%|▍         | 15/363 [11:45<4:49:59, 50.00s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Communication Dynamics Between Speaker and Listener', 'Communication and Expression', 'Oral Communication Contexts', 'Verbal Expression and Consumption', 'Mood - Neutral', 'Portrayal - Neutral'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   4%|▍         | 16/363 [12:16<4:14:39, 44.03s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Rest and Vulnerability', 'None', 'Sleeping and Resting', 'Mood - Neutral', 'Portrayal - Neutral'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   5%|▍         | 17/363 [13:03<4:19:17, 44.96s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Interpersonal Engagement', 'Communication and Understanding', 'Social Interaction Contexts', 'Engaging in Dialogue', 'Mood - Neutral', 'Portrayal - Neutral'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   5%|▍         | 18/363 [14:02<4:43:02, 49.22s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Non-Verbal Consensus Building', 'Silent Communication and Understanding', 'None', 'Agreeing and Acknowledging', 'Mood - Neutral', 'Portrayal - Neutral'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   5%|▌         | 19/363 [14:45<4:30:56, 47.26s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Blood Feuds and Conflicts', 'Life, Death, and Transformation', 'War-Torn and Ritualistic Environments', 'Bloodshed and Sacrifice', 'Mood - Tense', 'Portrayal - Serious'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   6%|▌         | 20/363 [15:29<4:25:05, 46.37s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Enlightenment and Spiritual Illumination', 'Sacred or Enlightened Spaces', 'Rituals of Illumination', 'Mood - Peaceful', 'Portrayal - Positive'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   6%|▌         | 21/363 [16:00<3:58:11, 41.79s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Authority and Social Status', 'Ceremonial and Institutional Spaces', 'Presiding and Reflective Practices', 'Mood - Neutral', 'Portrayal - Serious'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   6%|▌         | 22/363 [16:53<4:15:52, 45.02s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Isolation and Emotional Detachment', 'Frigid Environments and Winter Landscapes', 'Enduring Harsh Climates', 'Mood - Desolate', 'Portrayal - Serious'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   6%|▋         | 23/363 [17:30<4:01:28, 42.61s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['error', 'user_id']\n","Missing 'choices' key. Response: {\"error\": {\"message\": \"Provider returned error\", \"code\": 400, \"metadata\": {\"raw\": \"{\\\"error\\\":{\\\"message\\\":\\\"Requested 114307 to generate tokens, following a prompt of length 15308, which exceeds the max limit of 128000 tokens.\\\",\\\"type\\\":\\\"requested_too_many_tokens\\\",\\\"code\\\":400}}\", \"provider_name\": \"Perplexity\"}}, \"user_id\": \"user_2toLRwggKYSW1mBKEkndzXpsiSp\"}...\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Maritime Exploration and Trade', 'Maritime Ports and Waterways', 'Sailing and Docking Procedures', 'Mood - Neutral', 'Portrayal - Neutral'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   7%|▋         | 24/363 [18:46<4:57:15, 52.61s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Communication and Desire', 'California', 'Verbal Interaction and Action', 'Mood - Neutral', 'Portrayal - Neutral'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   7%|▋         | 25/363 [19:36<4:52:58, 52.01s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Social Bonding and Status', 'Social Gatherings and Celebrations', 'Consumption and Celebration', 'Mood - Cheerful', 'Portrayal - Positive'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   7%|▋         | 26/363 [20:07<4:15:49, 45.55s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Transitions and Boundaries', 'None', 'Opening and Closing', 'Mood - Neutral', 'Portrayal - Neutral'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   7%|▋         | 27/363 [20:37<3:50:00, 41.07s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Power Dynamics and Control', 'Equestrian Settings', 'Horsemanship and Discipline', 'Mood - Tense', 'Portrayal - Serious'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   8%|▊         | 28/363 [21:23<3:57:21, 42.51s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Moral and Legal Consequences of Homicide', 'None', 'Acts of Homicide', 'Mood - Tense', 'Portrayal - Serious'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   8%|▊         | 29/363 [22:01<3:49:46, 41.28s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Growth and Renewal', 'Tranquil and Therapeutic Spaces', 'Planting and Cultivating', 'Mood - Peaceful', 'Portrayal - Positive'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   8%|▊         | 30/363 [22:39<3:42:48, 40.15s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Hierarchy and Transition', 'Architectural Structures', 'Ascending and Descending', 'Mood - Neutral', 'Portrayal - Neutral'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   9%|▊         | 31/363 [23:16<3:37:29, 39.30s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Communal Bonds and Conflicts', 'Communal Identity and Conflict', 'Communal Dining Spaces', 'Shared Dining Experiences', 'Mood - Neutral', 'Portrayal - Neutral'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   9%|▉         | 32/363 [24:13<4:06:06, 44.61s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Purification and Societal Boundaries', 'Bathrooms and Bathhouses', 'Bathing and Cleansing Rituals', 'Mood - Tense', 'Portrayal - Serious'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   9%|▉         | 33/363 [24:57<4:04:01, 44.37s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Epistolary Bonds and Trust', 'Communication and Connection', 'None', 'Written Correspondence Exchange', 'Mood - Neutral', 'Portrayal - Neutral'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:   9%|▉         | 34/363 [25:24<3:34:04, 39.04s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Resentment-Driven Conflict', 'The Destructive Power of Wrath', 'None', 'Outbursts of Rage', 'Mood - Tense', 'Portrayal - Serious'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:  10%|▉         | 35/363 [26:15<3:53:49, 42.77s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Urgency and Time Pressure', 'None', 'Rushing and Hastening Actions', 'Mood - Tense', 'Portrayal - Serious'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:  10%|▉         | 36/363 [26:58<3:52:33, 42.67s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Collaborative Recollection Bonds', 'Memory and Identity Formation', 'None', 'Reconstructing Personal Narratives', 'Mood - Reflective', 'Portrayal - Serious'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:  10%|█         | 37/363 [27:35<3:43:34, 41.15s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Understanding and Managing Emotions', 'None', 'Exploring Emotional States', 'Mood - Neutral', 'Portrayal - Serious'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:  10%|█         | 38/363 [27:59<3:15:18, 36.06s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Order and Chaos', 'Systematic Environments', 'Organizing and Discovering', 'Mood - Neutral', 'Portrayal - Neutral'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:  11%|█         | 39/363 [29:03<3:59:21, 44.33s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Community Bonds and Conflicts', 'Community Life and Identity', 'Rural and Small-Town Settings', 'Community Building and Gatherings', 'Mood - Neutral', 'Portrayal - Positive'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:  11%|█         | 40/363 [29:47<3:58:36, 44.32s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Yearning for Connection', 'Belonging and Identity', 'Domestic Spaces and Homelands', 'Returning Home', 'Mood - Melancholic', 'Portrayal - Neutral'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:  11%|█▏        | 41/363 [30:21<3:40:48, 41.15s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Life Cycles and Connection', 'Forests and Groves', 'None', 'Mood - Neutral', 'Portrayal - Positive'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:  12%|█▏        | 42/363 [31:38<4:38:04, 51.98s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Domestic Nurturing and Transformation', 'Domestic Kitchen Space', 'Culinary Preparation and Sustenance', 'Mood - Neutral', 'Portrayal - Positive'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:  12%|█▏        | 43/363 [32:31<4:37:51, 52.10s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Self-Discovery and Contemplation', 'Urban and Natural Pathways', 'Journeying and Meditative Movement', 'Mood - Reflective', 'Portrayal - Positive'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:  12%|█▏        | 44/363 [33:28<4:45:17, 53.66s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Aspirations and Fulfillment', 'None', 'Wish-Making and Fulfillment', 'Mood - Hopeful', 'Portrayal - Positive'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:  12%|█▏        | 45/363 [34:55<5:37:03, 63.60s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Ritual and Connection', 'Coffee Shops & Homes', 'Serving and Customization', 'Mood - Comforting', 'Portrayal - Positive'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:  13%|█▎        | 46/363 [35:28<4:47:14, 54.37s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Power and Control Through Firearms', 'Western or Military Environments', 'Carrying and Using Firearms', 'Mood - Tense', 'Portrayal - Serious'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:  13%|█▎        | 47/363 [36:07<4:23:09, 49.97s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Destruction and Renewal', 'Sacred Ritual Spaces', 'Ritual Bonfires', 'Mood - Tense', 'Portrayal - Serious'] (length: 6)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rLabeling Topics:  13%|█▎        | 48/363 [37:43<5:34:30, 63.72s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Altruism and Compassion', 'None', 'Acts of Generosity and Gratitude', 'Mood - Compassionate', 'Portrayal - Positive'] (length: 6)\n"]},{"output_type":"stream","name":"stderr","text":["\rLabeling Topics:  13%|█▎        | 49/363 [38:37<5:18:21, 60.83s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Transportation as Societal Symbol', 'Historical Travel Routes', 'Transportation and Movement', 'Mood - Neutral', 'Portrayal - Serious'] (length: 6)\n"]},{"output_type":"stream","name":"stderr","text":["\rLabeling Topics:  14%|█▍        | 50/363 [39:25<4:56:29, 56.84s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Cooperative and Competitive Interactions', 'Strategic Interaction and Player Engagement', 'None', 'Competitive and Cooperative Play', 'Mood - Neutral', 'Portrayal - Neutral'] (length: 6)\n"]},{"output_type":"stream","name":"stderr","text":["\rLabeling Topics:  14%|█▍        | 51/363 [40:10<4:37:39, 53.40s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['Secretive Interactions', 'Secrecy and Confidentiality', 'Private/Intimate Spaces', 'Hushed Communication', 'Mood - Intimate', 'Portrayal - Positive'] (length: 6)\n"]},{"output_type":"stream","name":"stderr","text":["\rLabeling Topics:  14%|█▍        | 52/363 [41:34<5:24:35, 62.62s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Cultural Symbolism and Tradition', 'Kitchen and Bakery Settings', 'Baking and Creation', 'Mood - Cheerful', 'Portrayal - Positive'] (length: 6)\n"]},{"output_type":"stream","name":"stderr","text":["\rLabeling Topics:  15%|█▍        | 53/363 [42:07<4:37:57, 53.80s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Technology and Communication', 'Everyday Technological Spaces', 'Telephoning and Texting', 'Mood - Neutral', 'Portrayal - Neutral'] (length: 6)\n"]},{"output_type":"stream","name":"stderr","text":["\rLabeling Topics:  15%|█▍        | 54/363 [42:52<4:22:52, 51.04s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Communion and Hospitality', 'Dining Environments', 'Setting the Table', 'Mood - Warm', 'Portrayal - Positive'] (length: 6)\n"]},{"output_type":"stream","name":"stderr","text":["\rLabeling Topics:  15%|█▌        | 55/363 [43:34<4:07:16, 48.17s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Embodied Experience and Digestion', 'None', 'Digestive Processes and Discomfort', 'Mood - Unsettled', 'Portrayal - Symbolic'] (length: 6)\n"]},{"output_type":"stream","name":"stderr","text":["\rLabeling Topics:  15%|█▌        | 56/363 [44:48<4:46:10, 55.93s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Social Connection Through Movement', 'Social Dance Floors', 'Group Coordination and Performance', 'Mood - Joyful', 'Portrayal - Positive'] (length: 6)\n"]},{"output_type":"stream","name":"stderr","text":["\rLabeling Topics:  16%|█▌        | 57/363 [45:26<4:18:19, 50.65s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Vulnerability and Resilience', 'None', 'Stress-Induced Tremors', 'Mood - Tense', 'Portrayal - Neutral'] (length: 6)\n"]},{"output_type":"stream","name":"stderr","text":["\rLabeling Topics:  16%|█▌        | 58/363 [45:57<3:47:23, 44.73s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Identity and Cultural Heritage', 'Cultural and Societal Contexts', 'Naming Practices and Rituals', 'Mood - Neutral', 'Portrayal - Serious'] (length: 6)\n"]},{"output_type":"stream","name":"stderr","text":["\rLabeling Topics:  16%|█▋        | 59/363 [46:29<3:27:01, 40.86s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Physical Foundations and Symbolism', 'None', 'Mobility and Anatomical Movements', 'Mood - Neutral', 'Portrayal - Neutral'] (length: 6)\n"]},{"output_type":"stream","name":"stderr","text":["\rLabeling Topics:  17%|█▋        | 60/363 [47:33<4:01:24, 47.80s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Trying primary model: perplexity/sonar-deep-research\n","Status code: 200\n","Response keys: ['id', 'provider', 'model', 'object', 'created', 'choices', 'citations', 'usage']\n","Split result: ['None', 'Passage of Time and Deadlines', 'None', 'Time Progression and Deadlines', 'Mood - Tense', 'Portrayal - Serious'] (length: 6)\n"]},{"output_type":"stream","name":"stderr","text":["\rLabeling Topics:  17%|█▋        | 61/363 [48:10<3:45:06, 44.73s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Trying primary model: perplexity/sonar-deep-research\n"]}]},{"cell_type":"code","source":["import os\n","import time\n","import logging\n","import traceback\n","import pandas as pd\n","from tqdm import tqdm\n","from datetime import datetime\n","from bertopic import BERTopic\n","from tenacity import (\n","    retry,\n","    stop_after_attempt,\n","    wait_exponential,\n","    retry_if_exception_type\n",")\n","import openai\n","\n","# ========== CONFIGURATION ==========\n","OPENROUTER_API_KEY = \"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\"  # Replace with your actual key\n","os.environ[\"OPENAI_API_KEY\"] = OPENROUTER_API_KEY\n","\n","MODEL_NAME = \"deepseek/deepseek-r1:free\"\n","FAILED_LOG_PATH = \"topic_labeling_errors.log\"\n","MODEL_PATH = \"/content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-mpnet-base-v2_Model_1_POS_a/bertopic_model_iter_1_paraphrase-mpnet-base-v2_POS_a.pkl\"\n","OUTPUT_CSV = \"/content/drive/MyDrive/BERTTopic_Models_POS/verified_labeled_topics.csv\"\n","TOPIC_LIMIT = 10  # Start small, then increase\n","\n","# ========== ENHANCED PROMPT TEMPLATE WITH YOUR DETAILED GUIDELINES ==========\n","PROMPT_TEMPLATE = \"\"\"\n","Generate a topic label with EXACTLY 6 TAB-SEPARATED components based on these detailed guidelines:\n","\n","1. CHARACTER DYNAMICS: Relationships, interactions, or conflicts between characters\n","   • Example types: \"Rivalry Turned Alliance\", \"Unrequited Love\", \"Mentor-Protégé Conflict\"\n","   • If keywords like \"friend\", \"love\", \"trust\", \"betray\" appear, include this component\n","   • Use \"None\" if no clear character dynamics are present\n","\n","2. THEMES: Abstract ideas representing moral, philosophical, or ideological concerns\n","   • Example types: \"Duty vs. Desire\", \"The Power of Redemption\", \"Class Struggles\"\n","   • ALWAYS include a theme, even if abstract or general\n","   • For objects/places, focus on what they represent (e.g., \"doors\" → \"Transitions and Boundaries\")\n","\n","3. SETTINGS: Physical locations or conceptual environments\n","   • Example types: \"Haunted Castle\", \"War-Torn Battlefield\", \"Urban Underworld\"\n","   • Use \"None\" if no clear setting is indicated in keywords\n","   • Be specific but not overly speculative\n","\n","4. ACTIONS & EVENTS: Plot-driven occurrences advancing the narrative\n","   • Example types: \"Betrayal and Retribution\", \"Quest for Identity\", \"Escape from Captivity\"\n","   • Focus on actions mentioned in keywords\n","   • Use \"None\" if no clear events are indicated\n","\n","5. EMOTIONAL ATMOSPHERE: Overall mood and emotional impact\n","   • Format: \"Mood - [emotion]\" (e.g., \"Mood - Cheerful\", \"Mood - Tense\")\n","   • Use \"Mood - Cheerful\" for positive emotions (smile, laugh)\n","   • Use \"Mood - Tense\" for conflict/danger (war, fight)\n","   • Default to \"Mood - Neutral\" for neutral topics\n","\n","6. REPRESENTATION: How the topic is portrayed\n","   • Format: \"Portrayal - [tone]\" (e.g., \"Portrayal - Positive\", \"Portrayal - Serious\")\n","   • Use \"Portrayal - Positive\" for topics portrayed favorably\n","   • Use \"Portrayal - Serious\" for grave or solemn topics\n","   • Default to \"Portrayal - Neutral\" for neutral topics\n","\n","IMPORTANT EXAMPLES FROM EXISTING TOPICS:\n","\n","Topic: smile, laugh, grin\n","Friendly Camaraderie\\tJoy and Lightheartedness\\tJoyous Social Gatherings\\tFestive or Cheerful Gatherings\\tMood - Cheerful\\tPortrayal - Positive\n","\n","Topic: war, combat, battle\n","Allies and Enemies in Battle\\tConflict and Warfare\\tWar-Torn Battlefield\\tWar and Combat\\tMood - Tense\\tPortrayal - Serious\n","\n","Topic: door, doorway, entrance\n","None\\tTransitions and Boundaries\\tEntrances & Corridors\\tEntering and Exiting\\tMood - Neutral\\tPortrayal - Neutral\n","\n","Topic: kiss, kissed, embrace\n","Romantic Intimacy\\tLove and Affection\\tPrivate Romantic Spaces\\tKissing and Embracing\\tMood - Affectionate\\tPortrayal - Positive\n","\n","RULES:\n","- Use exactly ONE tab (\\\\t) between components\n","- Be descriptive but concise for each component\n","- Use \"None\" when appropriate for dynamics, settings, or events\n","- ALWAYS provide a theme (never \"None\" for theme component)\n","- Follow the mood and portrayal formats exactly\n","- Return ONLY the 6 tab-separated components with no other text\n","\n","YOUR TASK:\n","For the following keywords, provide 6 tab-separated components following the guidelines above.\n","\n","TOPIC KEYWORDS: [KEYWORDS]\n","REPRESENTATIVE DOCUMENTS:\n","[DOCUMENTS]\n","\"\"\"\n","\n","# ========== ROBUST LABEL GENERATOR ==========\n","class TopicLabelGenerator:\n","    def __init__(self):\n","        self.client = openai.OpenAI(\n","            api_key=os.environ[\"OPENAI_API_KEY\"],\n","            base_url=\"https://openrouter.ai/api/v1\",\n","            timeout=30  # Timeout set at client level\n","        )\n","        self.model = MODEL_NAME\n","        self.prompt = PROMPT_TEMPLATE\n","\n","    @retry(\n","        stop=stop_after_attempt(5),\n","        wait=wait_exponential(multiplier=1, min=4, max=20),\n","        retry=retry_if_exception_type(\n","            (openai.APITimeoutError,\n","             openai.APIError,\n","             openai.APIConnectionError)\n","        ),\n","        reraise=True\n","    )\n","    def generate_label(self, keywords, documents):\n","        \"\"\"Generate and validate topic label with retry logic\"\"\"\n","        try:\n","            # Prepare prompt with safe document truncation\n","            truncated_docs = [doc[:500] + \"...\" if len(doc) > 500 else doc\n","                            for doc in documents[:3]]\n","\n","            prompt = self.prompt.replace(\"[KEYWORDS]\", \", \".join(keywords))\n","            prompt = prompt.replace(\"[DOCUMENTS]\", \"\\n---\\n\".join(truncated_docs))\n","\n","            # API call without request_timeout parameter\n","            response = self.client.chat.completions.create(\n","                model=self.model,\n","                messages=[{\"role\": \"user\", \"content\": prompt}],\n","                temperature=0.3,\n","                max_tokens=250\n","            )\n","\n","            if not response.choices:\n","                raise ValueError(\"Empty API response\")\n","\n","            content = response.choices[0].message.content.strip()\n","            return self._validate_label(content, keywords)\n","\n","        except Exception as e:\n","            logging.error(f\"Label generation failed: {str(e)}\")\n","            raise\n","\n","    def _validate_label(self, label, keywords):\n","        \"\"\"Strict validation of label format\"\"\"\n","        if not label:\n","            raise ValueError(\"Empty label response\")\n","\n","        parts = label.split('\\t')\n","        if len(parts) != 6:\n","            raise ValueError(f\"Expected 6 components, got {len(parts)}\")\n","\n","        # Make sure we have valid parts\n","        dynamic = parts[0].strip()\n","        theme = parts[1].strip()\n","        setting = parts[2].strip()\n","        action_event = parts[3].strip()\n","        mood = parts[4].strip()\n","        portrayal = parts[5].strip()\n","\n","        # Ensure theme is never None\n","        if not theme or theme.lower() == \"none\":\n","            theme = f\"{keywords[0].capitalize()} and Related Concepts\" if keywords else \"Topic\"\n","\n","        # Ensure mood has proper format\n","        if not mood.startswith(\"Mood - \"):\n","            mood = \"Mood - \" + mood\n","\n","        # Ensure portrayal has proper format\n","        if not portrayal.startswith(\"Portrayal - \"):\n","            portrayal = \"Portrayal - \" + portrayal\n","\n","        # Create result dictionary\n","        result = {\n","            \"Character_Dynamics\": dynamic,\n","            \"Themes\": theme,\n","            \"Settings\": setting,\n","            \"Actions_Events\": action_event,\n","            \"Emotional_Atmosphere\": mood,\n","            \"Representation\": portrayal\n","        }\n","\n","        return result\n","\n","# ========== PROCESSING PIPELINE ==========\n","def initialize_logging():\n","    \"\"\"Configure logging with timestamp and topic context\"\"\"\n","    logging.basicConfig(\n","        filename=FAILED_LOG_PATH,\n","        level=logging.INFO,\n","        format=\"%(asctime)s - %(levelname)s - Topic %(topic_id)s: %(message)s\",\n","        filemode='w'\n","    )\n","    console = logging.StreamHandler()\n","    console.setLevel(logging.INFO)\n","    formatter = logging.Formatter('%(message)s')\n","    console.setFormatter(formatter)\n","    logging.getLogger('').addHandler(console)\n","\n","def load_model():\n","    \"\"\"Load BERTopic model with validation\"\"\"\n","    print(f\"\\n🔍 Loading BERTopic model from: {MODEL_PATH}\")\n","    try:\n","        model = BERTopic.load(MODEL_PATH)\n","        topic_info = model.get_topic_info()\n","        print(f\"✅ Successfully loaded model with {len(topic_info)} topics\")\n","        print(\"\\nSample topics:\")\n","        print(topic_info.head(3))\n","        return model\n","    except Exception as e:\n","        logging.critical(f\"Model loading failed: {str(e)}\")\n","        raise RuntimeError(f\"Could not load model: {str(e)}\")\n","\n","def process_topics(model, limit=TOPIC_LIMIT):\n","    \"\"\"Main processing loop with enhanced error handling\"\"\"\n","    generator = TopicLabelGenerator()\n","    results = []\n","\n","    valid_topics = [t for t in model.get_topics() if t != -1][:limit]\n","\n","    for topic_id in tqdm(valid_topics, desc=\"Labeling Topics\"):\n","        try:\n","            # Get topic data\n","            keywords = [w for w, _ in model.get_topic(topic_id)[:5]]\n","            docs = model.get_representative_docs(topic_id) or [\"No documents available\"]\n","\n","            # Generate label\n","            label_data = generator.generate_label(keywords, docs)\n","\n","            # Prepare result entry\n","            result = {\n","                \"Topic_ID\": topic_id,\n","                \"Keywords\": \", \".join(keywords),\n","                **label_data,\n","                \"Sample_Document\": docs[0][:200] + \"...\" if docs else \"\",\n","                \"Status\": \"Success\"\n","            }\n","            results.append(result)\n","\n","        except Exception as e:\n","            error_msg = str(e)[:200]  # Truncate long error messages\n","            logging.error(\n","                f\"Topic {topic_id} processing failed: {error_msg}\",\n","                extra={\"topic_id\": topic_id}\n","            )\n","\n","            # Create error entry with fallback theme\n","            fallback_theme = f\"{keywords[0].capitalize()} and Related Concepts\" if 'keywords' in locals() and keywords else \"Unknown Topic\"\n","            results.append({\n","                \"Topic_ID\": topic_id,\n","                \"Keywords\": \", \".join(keywords) if 'keywords' in locals() else \"Unknown\",\n","                \"Character_Dynamics\": \"Error\",\n","                \"Themes\": fallback_theme,  # Always provide a theme even for errors\n","                \"Settings\": \"Error\",\n","                \"Actions_Events\": \"Error\",\n","                \"Emotional_Atmosphere\": \"Mood - Neutral\",\n","                \"Representation\": \"Portrayal - Neutral\",\n","                \"Sample_Document\": docs[0][:200] + \"...\" if 'docs' in locals() and docs else \"\",\n","                \"Status\": f\"Error: {error_msg}\"\n","            })\n","            continue\n","\n","    return pd.DataFrame(results)\n","\n","def save_results(df):\n","    \"\"\"Save results with timestamp and validation stats\"\"\"\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    output_path = f\"{OUTPUT_CSV[:-4]}_{timestamp}.csv\"\n","\n","    # Add validation metadata\n","    success_rate = len(df[df['Status'] == 'Success']) / len(df) if len(df) > 0 else 0\n","    df['Metadata'] = f\"Success rate: {success_rate:.1%} | Generated: {timestamp}\"\n","\n","    df.to_csv(output_path, index=False)\n","\n","    print(f\"\\n💾 Saved results to: {output_path}\")\n","    print(f\"✅ Success rate: {success_rate:.1%}\")\n","\n","    # Show samples\n","    if success_rate > 0:\n","        print(\"\\nSample successful labels:\")\n","        successful = df[df['Status'] == 'Success']\n","        if len(successful) > 0:\n","            try:\n","                print(successful.head(3).to_markdown(index=False))\n","            except:\n","                print(successful.head(3))\n","\n","    return output_path\n","\n","# ========== MAIN EXECUTION ==========\n","def main():\n","    initialize_logging()\n","\n","    try:\n","        # Load model\n","        model = load_model()\n","\n","        # Process topics\n","        print(f\"\\n🚀 Starting to process {TOPIC_LIMIT} topics...\")\n","        start_time = time.time()\n","        results_df = process_topics(model)\n","\n","        # Save results\n","        output_file = save_results(results_df)\n","\n","        # Final report\n","        elapsed = time.time() - start_time\n","        print(f\"\\n🏁 Process completed in {elapsed:.1f} seconds\")\n","        print(f\"📊 Results saved to: {output_file}\")\n","        print(f\"📋 Error log: {FAILED_LOG_PATH}\")\n","\n","    except Exception as e:\n","        logging.critical(f\"Pipeline failed: {str(e)}\\n{traceback.format_exc()}\")\n","        print(f\"⛔ Critical error: {str(e)}\")\n","        exit(1)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"nXw14Lcslec1","executionInfo":{"status":"ok","timestamp":1743264467432,"user_tz":-60,"elapsed":9136,"user":{"displayName":"Polina Bakhturina","userId":"07881954271877753559"}},"outputId":"7ed6a656-caa9-483b-cd19-4d14ff5d2c3e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","🔍 Loading BERTopic model from: /content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-mpnet-base-v2_Model_1_POS_a/bertopic_model_iter_1_paraphrase-mpnet-base-v2_POS_a.pkl\n","✅ Successfully loaded model with 364 topics\n","\n","Sample topics:\n","   Topic   Count                             Name  \\\n","0     -1  113001  -1_thought_think_thoughts_speak   \n","1      0    4846   0_smiled_smile_smiles_grinning   \n","2      1    2847     1_dress_dresses_gowns_attire   \n","\n","                                      Representation  \\\n","0  [thought, think, thoughts, speak, seemed, say,...   \n","1  [smiled, smile, smiles, grinning, smirking, gr...   \n","2  [dress, dresses, gowns, attire, clothing, gown...   \n","\n","                                               NOUNS  \\\n","0  [hands, way, words, arms, room, body, arm, mom...   \n","1  [smile, grin, smiles, joke, laughs, chuckle, g...   \n","2  [dress, hat, shirt, gown, trousers, clothes, j...   \n","\n","                                 Representative_Docs  \n","0  [says hard say words inside released hit chest...  \n","1  [help smile back, bit back smile, smiled smile...  \n","2  [appeared wearing elegant dress matching hat, ...  \n","\n","🚀 Starting to process 10 topics...\n"]},{"output_type":"stream","name":"stderr","text":["\rLabeling Topics:   0%|          | 0/10 [00:00<?, ?it/s]ERROR:root:Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","ERROR:root:Topic 0 processing failed: Empty API response\n","Topic 0 processing failed: Empty API response\n","Topic 0 processing failed: Empty API response\n","Topic 0 processing failed: Empty API response\n","Topic 0 processing failed: Empty API response\n","Topic 0 processing failed: Empty API response\n","Topic 0 processing failed: Empty API response\n","Topic 0 processing failed: Empty API response\n","Topic 0 processing failed: Empty API response\n","Labeling Topics:  10%|█         | 1/10 [00:00<00:02,  3.38it/s]ERROR:root:Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","ERROR:root:Topic 1 processing failed: Empty API response\n","Topic 1 processing failed: Empty API response\n","Topic 1 processing failed: Empty API response\n","Topic 1 processing failed: Empty API response\n","Topic 1 processing failed: Empty API response\n","Topic 1 processing failed: Empty API response\n","Topic 1 processing failed: Empty API response\n","Topic 1 processing failed: Empty API response\n","Topic 1 processing failed: Empty API response\n","Labeling Topics:  20%|██        | 2/10 [00:00<00:02,  3.29it/s]ERROR:root:Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","ERROR:root:Topic 2 processing failed: Empty API response\n","Topic 2 processing failed: Empty API response\n","Topic 2 processing failed: Empty API response\n","Topic 2 processing failed: Empty API response\n","Topic 2 processing failed: Empty API response\n","Topic 2 processing failed: Empty API response\n","Topic 2 processing failed: Empty API response\n","Topic 2 processing failed: Empty API response\n","Topic 2 processing failed: Empty API response\n","Labeling Topics:  30%|███       | 3/10 [00:00<00:01,  4.25it/s]ERROR:root:Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","ERROR:root:Topic 3 processing failed: Empty API response\n","Topic 3 processing failed: Empty API response\n","Topic 3 processing failed: Empty API response\n","Topic 3 processing failed: Empty API response\n","Topic 3 processing failed: Empty API response\n","Topic 3 processing failed: Empty API response\n","Topic 3 processing failed: Empty API response\n","Topic 3 processing failed: Empty API response\n","Topic 3 processing failed: Empty API response\n","Labeling Topics:  40%|████      | 4/10 [00:00<00:01,  5.18it/s]ERROR:root:Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","ERROR:root:Topic 4 processing failed: Empty API response\n","Topic 4 processing failed: Empty API response\n","Topic 4 processing failed: Empty API response\n","Topic 4 processing failed: Empty API response\n","Topic 4 processing failed: Empty API response\n","Topic 4 processing failed: Empty API response\n","Topic 4 processing failed: Empty API response\n","Topic 4 processing failed: Empty API response\n","Topic 4 processing failed: Empty API response\n","Labeling Topics:  50%|█████     | 5/10 [00:01<00:00,  5.62it/s]ERROR:root:Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","ERROR:root:Topic 5 processing failed: Empty API response\n","Topic 5 processing failed: Empty API response\n","Topic 5 processing failed: Empty API response\n","Topic 5 processing failed: Empty API response\n","Topic 5 processing failed: Empty API response\n","Topic 5 processing failed: Empty API response\n","Topic 5 processing failed: Empty API response\n","Topic 5 processing failed: Empty API response\n","Topic 5 processing failed: Empty API response\n","Labeling Topics:  60%|██████    | 6/10 [00:01<00:00,  6.37it/s]ERROR:root:Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","ERROR:root:Topic 6 processing failed: Empty API response\n","Topic 6 processing failed: Empty API response\n","Topic 6 processing failed: Empty API response\n","Topic 6 processing failed: Empty API response\n","Topic 6 processing failed: Empty API response\n","Topic 6 processing failed: Empty API response\n","Topic 6 processing failed: Empty API response\n","Topic 6 processing failed: Empty API response\n","Topic 6 processing failed: Empty API response\n","Labeling Topics:  70%|███████   | 7/10 [00:01<00:00,  6.73it/s]ERROR:root:Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","ERROR:root:Topic 7 processing failed: Empty API response\n","Topic 7 processing failed: Empty API response\n","Topic 7 processing failed: Empty API response\n","Topic 7 processing failed: Empty API response\n","Topic 7 processing failed: Empty API response\n","Topic 7 processing failed: Empty API response\n","Topic 7 processing failed: Empty API response\n","Topic 7 processing failed: Empty API response\n","Topic 7 processing failed: Empty API response\n","Labeling Topics:  80%|████████  | 8/10 [00:01<00:00,  5.97it/s]ERROR:root:Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","ERROR:root:Topic 8 processing failed: Empty API response\n","Topic 8 processing failed: Empty API response\n","Topic 8 processing failed: Empty API response\n","Topic 8 processing failed: Empty API response\n","Topic 8 processing failed: Empty API response\n","Topic 8 processing failed: Empty API response\n","Topic 8 processing failed: Empty API response\n","Topic 8 processing failed: Empty API response\n","Topic 8 processing failed: Empty API response\n","Labeling Topics:  90%|█████████ | 9/10 [00:01<00:00,  6.23it/s]ERROR:root:Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","Label generation failed: Empty API response\n","ERROR:root:Topic 9 processing failed: Empty API response\n","Topic 9 processing failed: Empty API response\n","Topic 9 processing failed: Empty API response\n","Topic 9 processing failed: Empty API response\n","Topic 9 processing failed: Empty API response\n","Topic 9 processing failed: Empty API response\n","Topic 9 processing failed: Empty API response\n","Topic 9 processing failed: Empty API response\n","Topic 9 processing failed: Empty API response\n","Labeling Topics: 100%|██████████| 10/10 [00:01<00:00,  5.63it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","💾 Saved results to: /content/drive/MyDrive/BERTTopic_Models_POS/verified_labeled_topics_20250329_160747.csv\n","✅ Success rate: 0.0%\n","\n","🏁 Process completed in 1.8 seconds\n","📊 Results saved to: /content/drive/MyDrive/BERTTopic_Models_POS/verified_labeled_topics_20250329_160747.csv\n","📋 Error log: topic_labeling_errors.log\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["import os\n","import time\n","import pandas as pd\n","from bertopic import BERTopic\n","from tqdm import tqdm\n","from datetime import datetime\n","from openai import OpenAI\n","\n","# 🔐 OpenRouter API Key\n","client = OpenAI(\n","    base_url=\"https://openrouter.ai/api/v1\",\n","    api_key=\"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\",  # Replace with your actual key\n",")\n","\n","# 📁 Path to your saved BERTopic model\n","model_path = \"/content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-mpnet-base-v2_Model_1_POS_a/bertopic_model_iter_1_paraphrase-mpnet-base-v2_POS_a.pkl\"\n","\n","def generate_prompt(topic_words):\n","    examples = (\n","        \"-1_thought_think_thoughts_speak\\tCommunication\\tCommunication\\tNone\\tDialogue and Reflection\\n\"\n","        \"0_smiled_smile_smiles_grinning\\tFriendly Camaraderie\\tJoy and Lightheartedness\\tJoyous Social Gatherings\\tFestive or Cheerful Gatherings\\n\"\n","        \"1_dress_dresses_gowns_attire\\tNone\\tFashion & Identity\\tDressing Room\\tDressing Up\\n\"\n","        \"2_war_wars_combat_battle\\tAllies and Enemies in Battle\\tAllies and Enemies in Battle\\tWar-Torn Battlefield\\tWar and Combat\\n\"\n","        \"3_door_doors_doorframe_opened\\tNone\\tOpening & Closing Doors\\tEntrances & Corridors\\tEntering and Exiting\\n\"\n","        \"4_married_marriage_wedded_marriages\\tMarriage and Commitment\\tMarriage and Commitment\\tWedding Ceremonies\\tEngagements and Weddings\\n\"\n","        \"5_kiss_kissed_kisses_kissing\\tRomantic Intimacy\\tRomantic Intimacy\\tPrivate Romantic Spaces\\tKissing and Embracing\\n\"\n","        \"6_room_rooms_indoors_downstairs\\tDomestic Interactions\\tDomestic Interactions\\tDomestic Interiors\\tEntering and Exiting Rooms\\n\"\n","        \"7_course_courses_taught_lecture\\tTeacher-Student Relationships\\tEducation and Knowledge\\tAcademic Environment\\tTeaching and Learning\\n\"\n","        \"8_night_tonight_nights_nighttime\\tLate Night Interactions\\tLate Night Interactions\\tNocturnal Setting\\tLate Night Interactions\\n\"\n","        \"9_book_books_bookroom_librarian\\tNone\\tReading & Studying\\tLibraries and Bookshops\\tReading and Studying\\n\"\n","        # ... You can include the rest if needed; truncated here for brevity\n","    )\n","    prompt = f\"\"\"\n","You are an expert in literary and fanfiction topic analysis. For each topic, generate labels for the following columns in exactly this order:\n","    Name    Character Dynamics    Themes    Settings    Actions & Events    Representation\n","\n","The output must be a single line with tab-separated values. If a column is not applicable, output \"None\" for that column.\n","\n","Below are examples based on manually generated labels for topics produced by this model:\n","{examples}\n","\n","Now, given the topic words: {', '.join(topic_words)}, generate the appropriate labels as instructed.\n","\"\"\"\n","    return prompt\n","\n","def generate_topic_label(topic_words):\n","    prompt = generate_prompt(topic_words)\n","    completion = client.chat.completions.create(\n","        extra_headers={\n","            \"HTTP-Referer\": \"<YOUR_SITE_URL>\",\n","            \"X-Title\": \"<YOUR_SITE_NAME>\",\n","        },\n","        model=\"deepseek/deepseek-r1\",\n","        messages=[\n","            {\"role\": \"user\", \"content\": prompt}\n","        ],\n","        temperature=0.5,\n","        max_tokens=150,\n","    )\n","    return completion.choices[0].message.content.strip()\n","\n","def verify_and_save_labels(model, output_csv=\"verified_labeled_topics.csv\"):\n","    topic_info = model.get_topic_info()\n","\n","    def detect_invalid_labels(label):\n","        if label is None or label.strip() == \"\":\n","            return \"❌ Empty Label\"\n","        if \"L, a, b, e, l\" in label or \"Labeling\" in label:\n","            return \"⚠️ Garbled Label\"\n","        if \"The topic appears to be\" in label or \"not clear\" in label:\n","            return \"⚠️ Placeholder Label\"\n","        return \"✅ Valid\"\n","\n","    topic_info[\"Label_Validity\"] = topic_info[\"Name\"].apply(detect_invalid_labels)\n","    topic_info.to_csv(output_csv, index=False)\n","    print(f\"\\n📂 Verified labeled topics saved to: {output_csv}\")\n","    print(\"\\n✅ Sample of Correct Labels:\")\n","    print(topic_info[topic_info[\"Label_Validity\"] == \"✅ Valid\"][[\"Topic\", \"Name\"]].head(10))\n","\n","def main():\n","    print(f\"[{datetime.now()}] 🔄 Loading BERTopic model from: {model_path}\")\n","    model = BERTopic.load(model_path)\n","\n","    topics = model.get_topics()\n","    new_labels = {}\n","    print(f\"[{datetime.now()}] 🔄 Generating new labels for {len(topics)} topics...\")\n","    for topic_id, words in tqdm(topics.items(), desc=\"Processing Topics\"):\n","        topic_words = [word for word, _ in words]\n","        label = generate_topic_label(topic_words)\n","        new_labels[topic_id] = label\n","        time.sleep(1.1)  # Respect API rate limits\n","\n","    model.set_topic_labels(new_labels)\n","    updated_model_path = model_path.replace(\".pkl\", \"_labeled.pkl\")\n","    model.save(updated_model_path)\n","    print(f\"[{datetime.now()}] ✅ Updated model with new labels saved as: {updated_model_path}\")\n","\n","    verify_and_save_labels(model, output_csv=\"/content/drive/MyDrive/BERTTopic_Models_POS/verified_labeled_topics.csv\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ksywHTKQUuS","executionInfo":{"status":"ok","timestamp":1743196034692,"user_tz":-60,"elapsed":5121195,"user":{"displayName":"Polina Bakhturina","userId":"07881954271877753559"}},"outputId":"95c1f6ab-8e17-4c42-8b3c-02470b04a7af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2025-03-28 19:41:53.391031] 🔄 Loading BERTopic model from: /content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-mpnet-base-v2_Model_1_POS_a/bertopic_model_iter_1_paraphrase-mpnet-base-v2_POS_a.pkl\n","[2025-03-28 19:42:00.319777] 🔄 Generating new labels for 364 topics...\n"]},{"output_type":"stream","name":"stderr","text":["Processing Topics: 100%|██████████| 364/364 [1:24:18<00:00, 13.90s/it]\n","2025-03-28 21:06:18,491 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"]},{"output_type":"stream","name":"stdout","text":["[2025-03-28 21:07:13.917505] ✅ Updated model with new labels saved as: /content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-mpnet-base-v2_Model_1_POS_a/bertopic_model_iter_1_paraphrase-mpnet-base-v2_POS_a_labeled.pkl\n","\n","📂 Verified labeled topics saved to: /content/drive/MyDrive/BERTTopic_Models_POS/verified_labeled_topics.csv\n","\n","✅ Sample of Correct Labels:\n","   Topic                                 Name\n","0     -1      -1_thought_think_thoughts_speak\n","1      0       0_smiled_smile_smiles_grinning\n","2      1         1_dress_dresses_gowns_attire\n","3      2             2_war_wars_combat_battle\n","4      3        3_door_doors_doorframe_opened\n","5      4  4_married_marriage_wedded_marriages\n","6      5         5_kiss_kissed_kisses_kissing\n","7      6      6_room_rooms_indoors_downstairs\n","8      7      7_course_courses_taught_lecture\n","9      8     8_night_tonight_nights_nighttime\n"]}]},{"cell_type":"code","source":["from bertopic import BERTopic"],"metadata":{"id":"v7qTb0tWGNjy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import time\n","import requests\n","import pandas as pd\n","from bertopic import BERTopic\n","from tqdm import tqdm\n","from datetime import datetime\n","\n","# ✅ Your Together AI API Key\n","TOGETHER_API_KEY = \"4a24bea11227b835632c6d87732fcea473561ecad2b3c0a20cd38360d45d830e\"\n","\n","# Path to the specific restored model\n","model_path = \"/content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-mpnet-base-v2_Model_1_POS_a/bertopic_model_iter_1_paraphrase-mpnet-base-v2_POS_a.pkl\"\n","\n","\n","def generate_prompt(topic_words):\n","    # Define the manual examples as a multi-line string with tab-separated values.\n","    examples = (\n","        \"-1_thought_think_thoughts_speak\\tCommunication\\tCommunication\\tNone\\tDialogue and Reflection\\n\"\n","        \"0_smiled_smile_smiles_grinning\\tFriendly Camaraderie\\tJoy and Lightheartedness\\tJoyous Social Gatherings\\tFestive or Cheerful Gatherings\\n\"\n","        \"1_dress_dresses_gowns_attire\\tNone\\tFashion & Identity\\tDressing Room\\tDressing Up\\n\"\n","        \"2_war_wars_combat_battle\\tAllies and Enemies in Battle\\tAllies and Enemies in Battle\\tWar-Torn Battlefield\\tWar and Combat\\n\"\n","        \"3_door_doors_doorframe_opened\\tNone\\tOpening & Closing Doors\\tEntrances & Corridors\\tEntering and Exiting\\n\"\n","        \"4_married_marriage_wedded_marriages\\tMarriage and Commitment\\tMarriage and Commitment\\tWedding Ceremonies\\tEngagements and Weddings\\n\"\n","        \"5_kiss_kissed_kisses_kissing\\tRomantic Intimacy\\tRomantic Intimacy\\tPrivate Romantic Spaces\\tKissing and Embracing\\n\"\n","        \"6_room_rooms_indoors_downstairs\\tDomestic Interactions\\tDomestic Interactions\\tDomestic Interiors\\tEntering and Exiting Rooms\\n\"\n","        \"7_course_courses_taught_lecture\\tTeacher-Student Relationships\\tEducation and Knowledge\\tAcademic Environment\\tTeaching and Learning\\n\"\n","        \"8_night_tonight_nights_nighttime\\tLate Night Interactions\\tLate Night Interactions\\tNocturnal Setting\\tLate Night Interactions\\n\"\n","        \"9_book_books_bookroom_librarian\\tNone\\tReading & Studying\\tLibraries and Bookshops\\tReading and Studying\\n\"\n","        \"10_breath_breaths_breathed_breathes\\tNone\\tBreathing & Gasping\\tNone\\tBreathing & Gasping\\n\"\n","        \"11_stared_gazes_gazed_gaze\\tSilent Communication\\tStaring & Gazing\\tNone\\tIntense Staring\\n\"\n","        \"12_crying_cry_cries_sobbed\\tEmotional Breakdowns\\tPain and Loss\\tNone\\tExpressing Sorrow\\n\"\n","        \"13_women_females_feminist_womanhood\\tDebating Gender Roles\\tGender and Sexuality\\tNone\\tChallenging Gender Norms\\n\"\n","        \"14_money_financial_cash_pays\\tFinancial Ties\\tWealth and Economics\\tNone\\tFinancial Transactions\\n\"\n","        \"15_mouth_mouths_lips_tongue\\tCommunication & Expression\\tSpeaking, Biting & Licking\\tNone\\tSpeaking, Biting & Licking\\n\"\n","        \"16_asleep_sleepily_slept_sleeping\\tSleeping and Awakening\\tSleeping and Awakening\\tSleeping Quarters\\tSlumber and Wakefulness\\n\"\n","        \"17_conversation_conversational_conversations_conversationist\\tConversation and Discussion\\tConversation and Discussion\\tNone\\tConversation and Discussion\\n\"\n","        \"18_nodded_nods_nod_agreed\\tNonverbal Communication\\tAcknowledgment and Agreement\\tNone\\tAgreement and Acknowledgment\\n\"\n","        \"19_blood_bloodier_bloodied_bloodstains\\tInjury and Violence\\tInjury and Violence\\tBloody or Violent Scenes\\tInjury and Violence\\n\"\n","        \"20_light_lightness_lights_illuminated\\tNone\\tIlluminated Spaces\\tBrightly Lit Spaces\\tLighting & Shining\\n\"\n","        \"21_chair_chairs_seat_armchair\\tCasual Encounters\\tEveryday Domestic Details\\tEveryday Domestic Details\\tTaking a Seat\\n\"\n","        \"22_coldness_cold_chilly_colder\\tNone\\tFrosty Landscapes\\tFrosty Landscapes\\tShivering & Freezing\\n\"\n","        \"23_ship_boat_sailed_vessel\\tCrew Interactions\\tSailing and Voyaging\\tShips and the Sea\\tSailing and Voyaging\\n\"\n","        \"24_ca_california_act_see\\tNone\\tUncertainty and Possibility\\tNone\\tNone\\n\"\n","        \"25_wine_wines_drank_sipped\\tToasting and Drinking\\tToasting and Drinking\\tTaverns or Banquets\\tDrinking and Toasting\\n\"\n","        \"26_window_windowpane_windows_open\\tNone\\tLooking Outside\\tWindows and Balconies\\tWindow Gazing and Observation\\n\"\n","        \"27_horse_horsewhipped_horseman_horseback\\tNone\\tHorseback Riding\\tEquestrian and Rural Paths\\tRiding & Galloping\\n\"\n","        \"28_kill_kills_killing_murdering\\tViolent Conflict\\tActs of Violence\\tCrime or Battle Scenes\\tMurder and Violence\\n\"\n","        \"29_garden_gardens_gardenia_gardening\\tNone\\tPlanting and Gardening\\tLush Gardens\\tPlanting and Gardening\\n\"\n","        \"30_stairs_staircase_staircases_stairway\\tNone\\tMoving Up or Down Staircases\\tStaircases and Corridors\\tMoving Up or Down Staircases\\n\"\n","        \"31_dinner_dinners_dining_meal\\tShared Meals and Social Bonding\\tShared Meals and Social Bonding\\tDining Rooms or Restaurants\\tEating and Feasting\\n\"\n","        \"32_bathroom_bathrooms_washroom_restroom\\tNone\\tBathrooms and Washrooms\\tBathrooms and Washrooms\\tBathing and Cleaning\\n\"\n","        \"33_letter_wrote_letters_received\\tPostal or Digital Messaging\\tPostal or Digital Messaging\\tNone\\tWriting and Sending Letters and Emails\\n\"\n","        \"34_anger_angry_rage_angered\\tOutbursts and Accusations\\tWrath and Frustration\\tNone\\tOutbursts and Accusations\\n\"\n","        \"35_hurry_hurried_hastened_hastening\\tNone\\tRushing and Hastening\\tNone\\tRushing and Hastening\\n\"\n","        \"36_memory_remembering_memories_remembers\\tNone\\tMemory and Nostalgia\\tNone\\tRecollection and Reminiscence\\n\"\n","        \"37_feelings_emotions_emotion_emotional\\tNone\\tComplex Emotions and Uncertainty\\tNone\\tExperiencing and Expressing Emotions\\n\"\n","        \"38_sort_sorts_sorting_sorted\\tNone\\tSorting and Categorizing\\tNone\\tSorting and Categorizing\\n\"\n","        \"39_town_townsfolk_towns_village\\tNone\\tTowns or Villages and Neighbors\\tTowns or Villages\\tNone\\n\"\n","        \"40_home_homely_homed_homesick\\tNone\\tReturning or Homecoming\\tHome and Domestic Spaces\\tReturning or Homecoming\\n\"\n","        \"41_tree_trees_grove_forest\\tNone\\tForests and Woodlands\\tForests and Woodlands\\tNone\\n\"\n","        \"42_kitchen_kitchens_kitchenette_countertop\\tNone\\tCooking and Cleaning\\tKitchens\\tCooking and Cleaning\\n\"\n","        \"43_walked_walking_walks_walk\\tNone\\tWalking and Strolling\\tRoads and Paths\\tWalking and Strolling\\n\"\n","        \"44_wish_wishes_wished_wishing\\tNone\\tWishing and Hoping\\tNone\\tWishing and Hoping\\n\"\n","        \"45_cup_teacup_cups_coffee\\tNone\\tDrinking Coffee or Tea\\tCafés or Tea Rooms\\tDrinking and Coffee or Tea\\n\"\n","        \"46_pistol_holstered_pistols_revolvers\\tWeaponized Confrontations\\tWeaponized Confrontations\\tArmed Confrontations\\tFiring and Aiming\\n\"\n","        \"47_flames_flame_blazes_blazing\\tNone\\tIgniting and Burning\\tBurning Landscapes\\tIgniting and Burning\\n\"\n","        \"48_kindness_gratefulness_kindest_generosity\\tCaring Interactions\\tCaring Interactions\\tNone\\tCaring and Expressing Gratitude\\n\"\n","        \"49_carriage_carriages_wagon_cart\\tNone\\tRoads and Carriages\\tRoads and Carriages\\tTravelling\\n\"\n","        \"50_game_games_played_play\\tCompetitive Interactions\\tPlay and Competition\\tRecreational or Gaming Areas\\tPlaying and Competing\\n\"\n","        \"51_whispered_whispers_whisper_murmured\\tSecrets and Soft Communication\\tSecrets and Soft Communication\\tQuiet, Private Spaces\\tWhispering and Murmuring\\n\"\n","        \"52_cake_cakes_desserts_baking\\tNone\\tBaking and Serving Desserts\\tBakeries or Dining Tables\\tBaking and Serving Desserts\\n\"\n","        \"53_phone_phones_cellphone_smartphone\\tDigital Communication\\tDigital Communication\\tModern Tech Environments\\tCalling and Texting\\n\"\n","        \"54_table_tables_tablecloth_tableau\\tNone\\tSetting and Arranging Tables\\tRestaurants\\tSetting and Arranging Tables\\n\"\n","        \"55_stomach_stomachs_tummy_gut\\tNone\\tNone\\tNone\\tNone\\n\"\n","        \"56_dancing_dancefloor_dances_danced\\tDancing and Moving\\tDancing and Moving\\tDance Halls or Clubs\\tDancing and Moving\\n\"\n","        \"57_shook_shaken_shaking_trembled\\tNone\\tShaking and Trembling\\tChaotic or Unstable Environments\\tShaking and Trembling\\n\"\n","        \"58_name_surname_naming_names\\tNaming and Introducing\\tNaming and Introducing\\tSocial or Formal Introductions\\tNaming and Introducing\\n\"\n","        \"59_leg_legs_knees_knee\\tNone\\tNone\\tNone\\tNone\\n\"\n","        \"60_months_month_weeks_monthly\\tNone\\tPassage of Time\\tTemporal or Calendar Contexts\\tMarking Time\\n\"\n","        \"61_leave_leaving_depart_departure\\tParting or Farewell Dynamics\\tParting or Farewell Dynamics\\tNone\\tLeaving or Departing\\n\"\n","        \"62_medical_hospital_physicians_physician\\tPatient–Doctor Interactions\\tHealth and Healing\\tHospitals and Clinics\\tTreatment and Surgery\\n\"\n","        \"63_trust_trusts_trustworthiness_trusting\\tTrust and Betrayal\\tTrust and Betrayal\\tNone\\tTrusting and Discerning\\n\"\n","        \"64_scent_smelling_scents_scenting\\tNone\\tAromas and Sensory Experience\\tNone\\tSmelling and Inhaling\\n\"\n","        \"65_minutes_minute_hour_seconds\\tNone\\tTime and Duration\\tNone\\tCounting and Measuring Time\\n\"\n","        \"66_yes_yeah_sure_ok\\tAffirmative Exchanges\\tAgreement and Confirmation\\tConversational Settings\\tResponding and Confirming\\n\"\n","        \"67_seat_seated_seats_sit\\tNone\\tNone\\tNone\\tNone\\n\"\n","        \"68_believe_believes_belief_believed\\tNone\\tFaith and Conviction\\tIntellectual or Spiritual Contexts\\tBelieving and Considering\\n\"\n","        \"69_bag_bags_handbag_luggage\\tNone\\tPacking and Carrying\\tTravel or Shopping Contexts\\tPacking and Carrying\\n\"\n","        \"70_train_trains_railway_railroad\\tNone\\tRailway Stations and Locomotives\\tRailway Stations and Locomotives\\tBoarding and Traveling by Train\\n\"\n","        \"71_parents_parent_grandparents_fathers\\tNone\\tParenthood and Kinship\\tHome or Family Gatherings\\tNone\\n\"\n","        \"72_curls_curled_hairs_whiskers\\tNone\\tStyling and Combing\\tBeauty or Grooming Spaces\\tStyling and Combing\\n\"\n","        \"73_eyebrow_eyebrows_glanced_brow\\tSubtle Interactions\\tSkepticism and Curiosity\\tFace-to-Face Encounters\\tRaising and Questioning\\n\"\n","        \"74_hug_hugs_hugged_hugging\\tAffectionate Connections\\tComfort and Support\\tIntimate or Friendly Spaces\\tHugging and Embracing\\n\"\n","        \"75_heard_hears_overheard_hearing\\tHearing and Listening\\tHearing and Listening\\tAuditory or Conversational Spaces\\tHearing and Listening\\n\"\n","        \"76_towel_washcloth_cleans_towels\\tNone\\tHygiene and Cleanliness\\tBathrooms or Laundry Rooms\\tWiping and Cleaning\\n\"\n","        \"77_hate_hatefully_hating_hateful\\tHostility and Disdain\\tHostility and Disdain\\tNone\\tExpressing Hatred\\n\"\n","        \"78_eat_eating_eaten_food\\tNone\\tNourishment and Appetite\\tDining or Kitchen Spaces\\tEating and Consuming\\n\"\n","        \"79_mask_masks_masked_disguise\\tNone\\tDisguise and Concealment\\tCostume or Masquerade Settings\\tMasking and Hiding\\n\"\n","        \"80_mirror_mirrors_reflected_mirroring\\tNone\\tNone\\tDressing Rooms or Bathrooms\\tNone\\n\"\n","        \"81_case_cases_circumstances_trial\\tInvestigative Partners\\tInvestigating and Solving Cases\\tCourtrooms and Investigation Scenes\\tInvestigating and Solving Cases\\n\"\n","        \"82_rain_rained_raining_rains\\tNone\\tStorming and Pouring Rain\\tRainy Outdoors\\tStorming and Pouring Rain\\n\"\n","        \"83_lie_lied_lies_liar\\tDishonest Relationships\\tTruth vs. Deception\\tNone\\tLying and Deceiving\\n\"\n","        \"84_cock_cocks_cockhead_cockstand\\tSexual Intimacy\\tDesire and Sexuality\\tPrivate, Intimate Spaces\\tSexual Acts and Arousal\\n\"\n","        \"85_apologize_apologizes_apologized_apology\\tReconciliation Attempts\\tApologizing and Forgiving\\tInterpersonal Conversations\\tApologizing and Forgiving\\n\"\n","        \"86_dogs_canines_pets_pups\\tHuman-Animal Companionship\\tCaring for Pets\\tHomes and Outdoors\\tCaring for Pets\\n\"\n","        \"87_pregnancy_birth_pregnant_birthing\\tNone\\tGiving Birth and Expecting Children\\tHomes and Birthplaces\\tGiving Birth and Expecting Children\\n\"\n","        \"88_safe_safest_safes_safekeeping\\tProtective Relationships\\tSafety and Security\\tNone\\tEnsuring Safety\\n\"\n","        \"89_party_parties_festivities_guests\\tSocializing and Friendships\\tParties and Social Gatherings\\tParties and Social Gatherings\\tCelebrating and Entertaining\\n\"\n","        \"90_shoulder_shoulders_neck_back\\tConsoling and Supporting\\tEmpathy and Support\\tQuiet, Intimate Spaces\\tConsoling and Supporting\\n\"\n","        \"91_business_dealings_companies_firm\\tProfessional and Business Relationships\\tCommerce and Negotiation\\tOffices and Marketplaces\\tConducting Business\\n\"\n","        \"92_feet_legs_footfalls_footstep\\tNone\\tWalking and Traveling\\tRoads, Paths, and Streets\\tWalking and Traveling\\n\"\n","        \"93_fact_facts_incontrovertible_corroborated\\tNone\\tProving and Establishing Facts\\tIntellectual Discussions\\tProving and Establishing Facts\\n\"\n","        \"94_piano_pianist_pianoforte_pianos\\tNone\\tMusical Performance\\tConcerts and Salons\\tPlaying Instruments\\n\"\n","        \"95_crowd_crowds_onlookers_crowding\\tSpectacle and Group Dynamics\\tSpectacle and Group Dynamics\\tPublic Places and Events\\tWatching and Gathering\\n\"\n","        \"96_birds_birders_birding_birdsong\\tNone\\tBird Watching\\tOutdoor, Nature\\tBird Watching\\n\"\n","        \"97_throat_cleared_clears_swallowing\\tNone\\tCommunication and Awkwardness\\tNone\\tClearing Throat and Pausing\\n\"\n","        \"98_afraid_fearful_feared_scared\\tNone\\tVulnerability and Anxiety\\tThreatening Situations\\tExperiencing Fear\\n\"\n","        \"99_paper_ink_papers_penmanship\\tNone\\tWriting and Recording\\tStudies\\tWriting and Recording\\n\"\n","        \"100_waves_wave_surf_ocean\\tNone\\tSwimming and Surfing\\tBeaches and Oceansides\\tSwimming and Surfing\\n\"\n","        \"101_police_policemen_policeman_cops\\tLaw Enforcement Encounters\\tOrder and Justice\\tCrime Scenes and Stations\\tArresting and Patrolling\\n\"\n","        \"102_singing_sings_sang_sung\\tNone\\tMusical Performances\\tConcerts and Gatherings\\tSinging and Performing\\n\"\n","        \"103_friendship_friendships_befriend_companionship\\tFriendly Bonds\\tCompanionship and Trust\\tNone\\tBefriending and Bonding\\n\"\n","        \"104_chance_chances_maybe_hoping\\tNone\\tTaking Chances\\tUnpredictable Situations\\tTaking Chances\\n\"\n","        \"105_done_enough_finished_finish\\tNone\\tFinishing and Completing\\tWorkspaces and Tasks\\tFinishing and Completing\\n\"\n","        \"106_bedroom_bedrooms_bedchamber_bedchambers\\tNone\\tBedrooms and Sleeping Areas\\tBedrooms and Sleeping Areas\\tNone\\n\"\n","        \"107_dreams_dreaming_dreamed_dreamt\\tNone\\tBedrooms and Sleeping Areas\\tBedrooms and Sleeping Areas\\tNone\\n\"\n","        \"108_pillow_pillows_pillowcase_mattress\\tNone\\tResting and Sleeping\\tBedrooms and Sleeping Areas\\tResting and Sleeping\\n\"\n","        \"109_cigarette_cigarettes_smokes_smoked\\tNone\\tSmoking and Puffing\\tNone\\tSmoking and Puffing\\n\"\n","        \"110_danger_dangers_dangerous_threat\\tNone\\tPeril and Caution\\tPeril Situations\\tFacing Danger\"\n","    )\n","    prompt = f\"\"\"\n","You are an expert in literary and fanfiction topic analysis. For each topic, generate labels for the following columns in exactly this order:\n","    Name    Character Dynamics    Themes    Settings    Actions & Events    Representation\n","\n","The output must be a single line with tab-separated values. If a column is not applicable, output \"None\" for that column.\n","\n","Below are examples based on manually generated labels for topics produced by this model:\n","{examples}\n","\n","Now, given the topic words: {', '.join(topic_words)}, generate the appropriate labels as instructed.\n","\"\"\"\n","    return prompt\n","\n","\n","def generate_topic_label(topic_words):\n","    prompt = generate_prompt(topic_words)\n","    headers = {\n","        \"Authorization\": f\"Bearer {TOGETHER_API_KEY}\",\n","        \"Content-Type\": \"application/json\"\n","    }\n","    payload = {\n","        \"model\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n","        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n","        \"temperature\": 0.5,\n","        \"max_tokens\": 150\n","    }\n","    while True:\n","        try:\n","            response = requests.post(\"https://api.together.xyz/v1/chat/completions\", json=payload, headers=headers)\n","            if response.status_code == 200:\n","                return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n","            elif response.status_code == 429:\n","                print(\"⚠️ Rate limit hit! Waiting 2 seconds before retrying...\")\n","                time.sleep(2)\n","            else:\n","                return \"Unknown Topic\"\n","        except requests.exceptions.RequestException:\n","            return \"Unknown Topic\"\n","\n","\n","def verify_and_save_labels(model, output_csv=\"verified_labeled_topics.csv\"):\n","    topic_info = model.get_topic_info()\n","\n","    def detect_invalid_labels(label):\n","        if label is None or label.strip() == \"\":\n","            return \"❌ Empty Label\"\n","        if \"L, a, b, e, l\" in label or \"Labeling\" in label:\n","            return \"⚠️ Garbled Label\"\n","        if \"The topic appears to be\" in label or \"not clear\" in label:\n","            return \"⚠️ Placeholder Label\"\n","        return \"✅ Valid\"\n","\n","    topic_info[\"Label_Validity\"] = topic_info[\"Name\"].apply(detect_invalid_labels)\n","    topic_info.to_csv(output_csv, index=False)\n","    print(f\"\\n📂 Verified labeled topics saved to: {output_csv}\")\n","    print(\"\\n✅ Sample of Correct Labels:\")\n","    print(topic_info[topic_info[\"Label_Validity\"] == \"✅ Valid\"][[\"Topic\", \"Name\"]].head(10))\n","\n","\n","def main():\n","    print(f\"[{datetime.now()}] 🔄 Loading BERTopic model from: {model_path}\")\n","    model = BERTopic.load(model_path)\n","\n","    topics = model.get_topics()\n","    new_labels = {}\n","    print(f\"[{datetime.now()}] 🔄 Generating new labels for {len(topics)} topics...\")\n","    for topic_id, words in tqdm(topics.items(), desc=\"Processing Topics\"):\n","        topic_words = [word for word, _ in words]\n","        label = generate_topic_label(topic_words)\n","        new_labels[topic_id] = label\n","        time.sleep(1.1)  # Enforce API rate limit\n","    model.set_topic_labels(new_labels)\n","\n","    updated_model_path = model_path.replace(\".pkl\", \"_labeled.pkl\")\n","    model.save(updated_model_path)\n","    print(f\"[{datetime.now()}] ✅ Updated model with new labels saved as: {updated_model_path}\")\n","\n","    verify_and_save_labels(model, output_csv=\"/content/drive/MyDrive/BERTTopic_Models_POS/verified_labeled_topics.csv\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"31_89ceUXfoN","executionInfo":{"status":"ok","timestamp":1742674096771,"user_tz":-60,"elapsed":896165,"user":{"displayName":"Polina Bakhturina","userId":"07881954271877753559"}},"outputId":"84c7ae64-0a33-40bb-d860-53a50748a0a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2025-03-22 19:53:21.148195] 🔄 Loading BERTopic model from: /content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-mpnet-base-v2_Model_1_POS_a/bertopic_model_iter_1_paraphrase-mpnet-base-v2_POS_a.pkl\n","[2025-03-22 19:54:20.129804] 🔄 Generating new labels for 364 topics...\n"]},{"output_type":"stream","name":"stderr","text":["Processing Topics: 100%|██████████| 364/364 [13:48<00:00,  2.28s/it]\n","2025-03-22 20:08:08,435 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"]},{"output_type":"stream","name":"stdout","text":["[2025-03-22 20:08:17.239159] ✅ Updated model with new labels saved as: /content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-mpnet-base-v2_Model_1_POS_a/bertopic_model_iter_1_paraphrase-mpnet-base-v2_POS_a_labeled.pkl\n","\n","📂 Verified labeled topics saved to: /content/drive/MyDrive/BERTTopic_Models_POS/verified_labeled_topics.csv\n","\n","✅ Sample of Correct Labels:\n","   Topic                                 Name\n","0     -1      -1_thought_think_thoughts_speak\n","1      0       0_smiled_smile_smiles_grinning\n","2      1         1_dress_dresses_gowns_attire\n","3      2             2_war_wars_combat_battle\n","4      3        3_door_doors_doorframe_opened\n","5      4  4_married_marriage_wedded_marriages\n","6      5         5_kiss_kissed_kisses_kissing\n","7      6      6_room_rooms_indoors_downstairs\n","8      7      7_course_courses_taught_lecture\n","9      8     8_night_tonight_nights_nighttime\n"]}]},{"cell_type":"code","source":["# =====================================\n","# 1. Import Libraries\n","# =====================================\n","import nltk\n","nltk.download('punkt_tab')\n","import os\n","import time\n","import logging\n","import pandas as pd\n","import numpy as np\n","import re\n","from datetime import datetime\n","import torch\n","import gc\n","from tqdm import tqdm\n","from bertopic import BERTopic\n","from sentence_transformers import SentenceTransformer\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Import RAPIDS' UMAP and HDBSCAN\n","from cuml.manifold import UMAP  # GPU-accelerated UMAP\n","from cuml.cluster import HDBSCAN  # GPU-accelerated HDBSCAN\n","import cupy as cp  # For GPU arrays\n","\n","# Import NLTK modules for text processing\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","# Import BERTopic's representation models\n","from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, PartOfSpeech\n","\n","# Import json module\n","import json\n","\n","# Import string module for punctuation handling\n","import string\n","\n","# =====================================\n","# 2. Configure Logging\n","# =====================================\n","\n","# Define logging configuration\n","LOG_FILENAME = 'bertopic_training.log'\n","\n","# Create a custom logger\n","logger = logging.getLogger('BERTopic_Training')\n","logger.setLevel(logging.DEBUG)\n","\n","# Prevent adding multiple handlers in environments like Google Colab\n","if not logger.handlers:\n","    # Create handlers\n","    c_handler = logging.StreamHandler()\n","    f_handler = logging.FileHandler(LOG_FILENAME)\n","    c_handler.setLevel(logging.INFO)\n","    f_handler.setLevel(logging.DEBUG)\n","\n","    # Create formatters and add them to handlers\n","    c_format = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n","    f_format = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n","    c_handler.setFormatter(c_format)\n","    f_handler.setFormatter(f_format)\n","\n","    # Add handlers to the logger\n","    logger.addHandler(c_handler)\n","    logger.addHandler(f_handler)\n","\n","# =====================================\n","# 3. Check and Load SpaCy Model for POS Tagging\n","# =====================================\n","\n","# Load spaCy's English model for POS tagging, with error handling if the model is missing\n","import spacy\n","from spacy.cli import download as spacy_download\n","\n","try:\n","    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n","except OSError:\n","    logger.info(\"Downloading 'en_core_web_sm' model for spaCy as it was not found...\")\n","    spacy_download(\"en_core_web_sm\")\n","    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n","\n","# =====================================\n","# 4. Define Paths and Load Stop Words\n","# =====================================\n","\n","# Define the paths for datasets, models, and resources\n","dataset_path = '/content/drive/MyDrive/fanfiction_project_data_and_models/processed_novels_sentences_new.csv'\n","additional_stop_words_characters_names = '/content/drive/MyDrive/fanfiction_project_data_and_models/fanfiction_additional_stop_list_character_names.txt'\n","\n","def preprocess_stopwords(stopwords_file_path):\n","    \"\"\"\n","    Preprocess the stop words list by lowercasing, removing punctuation, and splitting multi-word entries.\n","    \"\"\"\n","    try:\n","        with open(stopwords_file_path, 'r', encoding='utf-8') as file:\n","            raw_stop_words = file.read().splitlines()\n","\n","        processed_stop_words = set()\n","        translator = str.maketrans('', '', string.punctuation)\n","\n","        for stop_word in raw_stop_words:\n","            stop_word = stop_word.lower().translate(translator)\n","            words = stop_word.split()\n","            for word in words:\n","                if word:\n","                    processed_stop_words.add(word)\n","\n","        logger.info(f\"Processed stop words count: {len(processed_stop_words)}\")\n","        return processed_stop_words\n","\n","    except Exception as e:\n","        logger.error(f\"Error processing stop words: {e}\")\n","        return set(stopwords.words('english'))  # Fallback to NLTK's stop words\n","\n","logger.info(\"Loading and preprocessing additional stop words...\")\n","custom_stop_words = preprocess_stopwords(additional_stop_words_characters_names)\n","\n","# Combine with NLTK's stop words\n","stop_words = set(stopwords.words('english'))\n","stop_words.update(custom_stop_words)\n","logger.info(f\"Total stop words after preprocessing: {len(stop_words)}\")\n","\n","# =====================================\n","# 5. Load and Preprocess the Dataset\n","# =====================================\n","\n","def load_dataset(path, stop_words, test_mode=False, sample_size=10000, chunksize=None):\n","    \"\"\"\n","    Load and preprocess the dataset.\n","    \"\"\"\n","    logger.info(\"Loading and preprocessing dataset...\")\n","    start_time = time.time()\n","\n","    try:\n","        if test_mode:\n","            logger.info(f\"Test mode enabled. Sampling {sample_size} sentences from the dataset.\")\n","            if chunksize is None:\n","                chunksize = 1000\n","            df_iter = pd.read_csv(path, chunksize=chunksize)\n","            sampled_chunks = []\n","            total_sampled = 0\n","            for chunk in df_iter:\n","                remaining = sample_size - total_sampled\n","                if remaining <= 0:\n","                    break\n","                n_samples = min(remaining, len(chunk))\n","                sampled = chunk.sample(n=n_samples, random_state=42)\n","                sampled_chunks.append(sampled)\n","                total_sampled += n_samples\n","            df = pd.concat(sampled_chunks) if sampled_chunks else pd.DataFrame()\n","        else:\n","            df = pd.read_csv(path)\n","\n","        df['Sentence'] = df['Sentence'].astype(str).apply(lambda x: re.sub(r'\\n+', ' ', x))\n","        df['Sentence'] = df['Sentence'].str.replace(r'\\s+', ' ', regex=True).str.strip().str.lower()\n","\n","        processed_docs = []\n","        for sentence in df['Sentence']:\n","            tokens = word_tokenize(sentence)\n","            tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n","            processed_sentence = ' '.join(tokens)\n","            processed_docs.append(processed_sentence)\n","\n","        corpus_filtered = [sentence for sentence in processed_docs if len(sentence.split()) >= 3]\n","        logger.info(f\"Filtered corpus size: {len(corpus_filtered)}\")\n","        logger.info(f\"Time taken for loading and preprocessing: {time.time() - start_time:.2f} seconds\")\n","        return corpus_filtered\n","\n","    except Exception as e:\n","        logger.error(f\"Failed to load and preprocess dataset: {e}\")\n","        return []\n","\n","# =====================================\n","# 6. Create Parameters DataFrame\n","# =====================================\n","\n","import pandas as pd\n","\n","import pandas as pd\n","\n","def create_dataframe():\n","    \"\"\"\n","    Create the dataframe containing the top 10 models (new version) without the extra columns.\n","    \"\"\"\n","    models = [\n","        {\n","            \"Embeddings_Model\": \"paraphrase-mpnet-base-v2\",\n","            \"Iteration\": 1,\n","            \"Coherence\": 0.488537,\n","            \"Topic_Diversity\": 0.986667,\n","            \"bertopic__min_topic_size\": 57,\n","            \"bertopic__top_n_words\": 37,\n","            \"hdbscan__min_cluster_size\": 132,\n","            \"hdbscan__min_samples\": 57,\n","            \"umap__min_dist\": 0.053015,\n","            \"umap__n_components\": 4,\n","            \"umap__n_neighbors\": 39,\n","            \"vectorizer__min_df\": 0.004806\n","        },\n","        {\n","            \"Embeddings_Model\": \"paraphrase-MiniLM-L6-v2\",\n","            \"Iteration\": 1,\n","            \"Coherence\": 0.416477,\n","            \"Topic_Diversity\": 1.000000,\n","            \"bertopic__min_topic_size\": 57,\n","            \"bertopic__top_n_words\": 37,\n","            \"hdbscan__min_cluster_size\": 132,\n","            \"hdbscan__min_samples\": 57,\n","            \"umap__min_dist\": 0.053015,\n","            \"umap__n_components\": 4,\n","            \"umap__n_neighbors\": 39,\n","            \"vectorizer__min_df\": 0.004806\n","        },\n","        {\n","            \"Embeddings_Model\": \"all-MiniLM-L12-v2\",\n","            \"Iteration\": 101,\n","            \"Coherence\": 0.392483,\n","            \"Topic_Diversity\": 0.975000,\n","            \"bertopic__min_topic_size\": 127,\n","            \"bertopic__top_n_words\": 26,\n","            \"hdbscan__min_cluster_size\": 128,\n","            \"hdbscan__min_samples\": 68,\n","            \"umap__min_dist\": 0.066224,\n","            \"umap__n_components\": 2,\n","            \"umap__n_neighbors\": 20,\n","            \"vectorizer__min_df\": 0.002257\n","        },\n","        {\n","            \"Embeddings_Model\": \"all-MiniLM-L12-v2\",\n","            \"Iteration\": 66,\n","            \"Coherence\": 0.419094,\n","            \"Topic_Diversity\": 0.825000,\n","            \"bertopic__min_topic_size\": 228,\n","            \"bertopic__top_n_words\": 27,\n","            \"hdbscan__min_cluster_size\": 105,\n","            \"hdbscan__min_samples\": 22,\n","            \"umap__min_dist\": 0.011738,\n","            \"umap__n_components\": 2,\n","            \"umap__n_neighbors\": 41,\n","            \"vectorizer__min_df\": 0.006573\n","        },\n","        {\n","            \"Embeddings_Model\": \"paraphrase-MiniLM-L6-v2\",\n","            \"Iteration\": 112,\n","            \"Coherence\": 0.379404,\n","            \"Topic_Diversity\": 0.937500,\n","            \"bertopic__min_topic_size\": 131,\n","            \"bertopic__top_n_words\": 22,\n","            \"hdbscan__min_cluster_size\": 86,\n","            \"hdbscan__min_samples\": 73,\n","            \"umap__min_dist\": 0.083975,\n","            \"umap__n_components\": 2,\n","            \"umap__n_neighbors\": 3,\n","            \"vectorizer__min_df\": 0.001335\n","        },\n","        {\n","            \"Embeddings_Model\": \"paraphrase-MiniLM-L6-v2\",\n","            \"Iteration\": 59,\n","            \"Coherence\": 0.400154,\n","            \"Topic_Diversity\": 0.761755,\n","            \"bertopic__min_topic_size\": 26,\n","            \"bertopic__top_n_words\": 38,\n","            \"hdbscan__min_cluster_size\": 120,\n","            \"hdbscan__min_samples\": 95,\n","            \"umap__min_dist\": 0.052454,\n","            \"umap__n_components\": 2,\n","            \"umap__n_neighbors\": 2,\n","            \"vectorizer__min_df\": 0.007219\n","        },\n","        {\n","            \"Embeddings_Model\": \"paraphrase-mpnet-base-v2\",\n","            \"Iteration\": 38,\n","            \"Coherence\": 0.323946,\n","            \"Topic_Diversity\": 1.000000,\n","            \"bertopic__min_topic_size\": 187,\n","            \"bertopic__top_n_words\": 35,\n","            \"hdbscan__min_cluster_size\": 60,\n","            \"hdbscan__min_samples\": 88,\n","            \"umap__min_dist\": 0.011252,\n","            \"umap__n_components\": 4,\n","            \"umap__n_neighbors\": 42,\n","            \"vectorizer__min_df\": 0.009032\n","        },\n","        {\n","            \"Embeddings_Model\": \"paraphrase-MiniLM-L6-v2\",\n","            \"Iteration\": 13,\n","            \"Coherence\": 0.358554,\n","            \"Topic_Diversity\": 0.820319,\n","            \"bertopic__min_topic_size\": 59,\n","            \"bertopic__top_n_words\": 16,\n","            \"hdbscan__min_cluster_size\": 54,\n","            \"hdbscan__min_samples\": 74,\n","            \"umap__min_dist\": 0.020023,\n","            \"umap__n_components\": 4,\n","            \"umap__n_neighbors\": 11,\n","            \"vectorizer__min_df\": 0.002484\n","        },\n","        {\n","            \"Embeddings_Model\": \"all-MiniLM-L12-v2\",\n","            \"Iteration\": 60,\n","            \"Coherence\": 0.366164,\n","            \"Topic_Diversity\": 0.761207,\n","            \"bertopic__min_topic_size\": 77,\n","            \"bertopic__top_n_words\": 13,\n","            \"hdbscan__min_cluster_size\": 144,\n","            \"hdbscan__min_samples\": 51,\n","            \"umap__min_dist\": 0.069807,\n","            \"umap__n_components\": 4,\n","            \"umap__n_neighbors\": 2,\n","            \"vectorizer__min_df\": 0.002135\n","        },\n","        {\n","            \"Embeddings_Model\": \"all-MiniLM-L12-v2\",\n","            \"Iteration\": 52,\n","            \"Coherence\": 0.331452,\n","            \"Topic_Diversity\": 0.900000,\n","            \"bertopic__min_topic_size\": 245,\n","            \"bertopic__top_n_words\": 38,\n","            \"hdbscan__min_cluster_size\": 98,\n","            \"hdbscan__min_samples\": 30,\n","            \"umap__min_dist\": 0.044896,\n","            \"umap__n_components\": 9,\n","            \"umap__n_neighbors\": 28,\n","            \"vectorizer__min_df\": 0.005585\n","        }\n","    ]\n","    return pd.DataFrame(models)\n","\n","\n","params_df = create_dataframe()\n","\n","# =====================================\n","# 7. Load Embedding Models\n","# =====================================\n","\n","def load_embedding_models(model_names):\n","    embedding_models = {}\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    logger.info(f\"Using device for embeddings: {device}\")\n","\n","    for model_name in model_names:\n","        try:\n","            embedding_model = SentenceTransformer(model_name, device=device)\n","            embedding_models[model_name] = embedding_model\n","            logger.info(f\"Model {model_name} loaded successfully.\")\n","        except Exception as e:\n","            logger.error(f\"Failed to load embedding model {model_name}: {e}\")\n","    return embedding_models\n","\n","embedding_model_names = params_df['Embeddings_Model'].unique()\n","embedding_models = load_embedding_models(embedding_model_names)\n","\n","# =====================================\n","# 8. Define POS Configurations\n","# =====================================\n","\n","def get_representation_model(pos_configuration):\n","    \"\"\"\n","    Return the representation model based on POS configuration.\n","    \"\"\"\n","    main_representation = KeyBERTInspired(top_n_words=30)\n","    if pos_configuration == 'a':\n","        # a) ONLY NOUNS\n","        pos_nouns = PartOfSpeech(pos_patterns=[[{\"POS\": \"NOUN\"}]])\n","        return {\"Main\": main_representation, \"NOUNS\": pos_nouns}\n","    elif pos_configuration == 'b':\n","        # b) NOUNS AND ADJECTIVES\n","        pos_nouns = PartOfSpeech(pos_patterns=[[{\"POS\": \"NOUN\"}]])\n","        pos_adjectives = PartOfSpeech(pos_patterns=[[{\"POS\": \"ADJ\"}]])\n","        return {\"Main\": main_representation, \"NOUNS\": pos_nouns, \"ADJECTIVES\": pos_adjectives}\n","    elif pos_configuration == 'c':\n","        # c) NOUNS AND VERBS\n","        pos_nouns = PartOfSpeech(pos_patterns=[[{\"POS\": \"NOUN\"}]])\n","        pos_verbs = PartOfSpeech(pos_patterns=[[{\"POS\": \"VERB\"}]])\n","        return {\"Main\": main_representation, \"NOUNS\": pos_nouns, \"VERBS\": pos_verbs}\n","    else:\n","        raise ValueError(f\"Invalid POS configuration: {pos_configuration}\")\n","\n","# =====================================\n","# 9. Train and Save BERTopic Models\n","# =====================================\n","\n","def train_and_save_models(corpus, params_df, embedding_models, stop_words):\n","    main_output_dir = \"/content/drive/MyDrive/BERTTopic_Models_POS\"\n","    os.makedirs(main_output_dir, exist_ok=True)\n","\n","    for idx, row in tqdm(params_df.iterrows(), total=params_df.shape[0], desc=\"Training Models\"):\n","        embedding_model_name = row['Embeddings_Model']\n","        iteration = row['Iteration']\n","        embedding_model = embedding_models.get(embedding_model_name)\n","        if embedding_model is None:\n","            logger.error(f\"Embedding model {embedding_model_name} not found.\")\n","            continue\n","\n","        for pos_config in ['a', 'b', 'c']:\n","            try:\n","                representation_model = get_representation_model(pos_config)\n","            except ValueError as e:\n","                logger.error(e)\n","                continue\n","\n","            try:\n","                topic_model = BERTopic(\n","                    embedding_model=embedding_model,\n","                    representation_model=representation_model,\n","                    top_n_words=row['bertopic__top_n_words'],\n","                    min_topic_size=row['bertopic__min_topic_size'],\n","                    language='english'\n","                )\n","                topics, probs = topic_model.fit_transform(corpus)\n","            except Exception as e:\n","                logger.error(f\"Error during training: {e}\")\n","                continue\n","\n","            safe_embedding = embedding_model_name.replace('/', '_')\n","            model_output_dir = os.path.join(main_output_dir, f\"{safe_embedding}_Model_{idx+1}_POS_{pos_config}\")\n","            os.makedirs(model_output_dir, exist_ok=True)\n","\n","            model_filename = f\"bertopic_model_iter_{iteration}_{safe_embedding}_POS_{pos_config}.pkl\"\n","            model_path = os.path.join(model_output_dir, model_filename)\n","            topic_model.save(model_path)\n","\n","            try:\n","                topics_info = topic_model.get_topic_info()\n","                topics_dict = topic_model.get_topics()\n","\n","                # Save topics information to CSV file\n","                csv_filename = f\"topics_info_iter_{iteration}_POS_{pos_config}.csv\"\n","                topics_info.to_csv(os.path.join(model_output_dir, csv_filename), index=False)\n","\n","                # Prepare topics data for JSON serialization with float conversion\n","                topics_json = {}\n","                for topic_num, words in topics_dict.items():\n","                    if topic_num == -1:  # Skip outlier topic\n","                        continue\n","\n","                    # Convert probabilities to standard floats for JSON serialization\n","                    filtered_words = [{word: float(prob)} for word, prob in words if word.strip()]\n","                    if filtered_words:  # Ensure we only add non-empty topics\n","                        topics_json[str(topic_num)] = filtered_words\n","\n","                # Save topics to JSON file\n","                json_filename = f\"topics_iter_{iteration}_POS_{pos_config}.json\"\n","                json_path = os.path.join(model_output_dir, json_filename)\n","                with open(json_path, 'w') as json_file:\n","                    json.dump(topics_json, json_file, indent=4)\n","                logger.info(f\"Topics JSON saved to {json_path}\")\n","\n","            except Exception as e:\n","                logger.error(f\"Failed to save topics: {e}\")\n","\n","            del topic_model\n","            gc.collect()\n","\n","# =====================================\n","# 10. Execute the Training Pipeline\n","# =====================================\n","\n","def main():\n","    TEST_MODE = False\n","    SAMPLE_SIZE = 1000\n","\n","    logger.info(\"Starting data loading and preprocessing...\")\n","    corpus = load_dataset(dataset_path, stop_words, test_mode=TEST_MODE, sample_size=SAMPLE_SIZE)\n","    if not corpus:\n","        logger.error(\"No data to train on.\")\n","        return\n","\n","    train_and_save_models(corpus, params_df, embedding_models, stop_words)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"nabSVddNpGIx","outputId":"4ec23ca6-cae1-40d1-967f-1735526c3ab5","executionInfo":{"status":"error","timestamp":1742415566298,"user_tz":-60,"elapsed":1729608,"user":{"displayName":"Polina Bakhturina","userId":"07881954271877753559"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","2025-03-19 19:50:39 - INFO - Loading and preprocessing additional stop words...\n","INFO:BERTopic_Training:Loading and preprocessing additional stop words...\n","2025-03-19 19:50:39 - INFO - Processed stop words count: 5181\n","INFO:BERTopic_Training:Processed stop words count: 5181\n","2025-03-19 19:50:39 - INFO - Total stop words after preprocessing: 5284\n","INFO:BERTopic_Training:Total stop words after preprocessing: 5284\n","2025-03-19 19:50:39 - INFO - Using device for embeddings: cuda\n","INFO:BERTopic_Training:Using device for embeddings: cuda\n","2025-03-19 19:50:45 - INFO - Model paraphrase-mpnet-base-v2 loaded successfully.\n","INFO:BERTopic_Training:Model paraphrase-mpnet-base-v2 loaded successfully.\n","2025-03-19 19:50:46 - INFO - Model paraphrase-MiniLM-L6-v2 loaded successfully.\n","INFO:BERTopic_Training:Model paraphrase-MiniLM-L6-v2 loaded successfully.\n","2025-03-19 19:50:48 - INFO - Model all-MiniLM-L12-v2 loaded successfully.\n","INFO:BERTopic_Training:Model all-MiniLM-L12-v2 loaded successfully.\n","2025-03-19 19:50:48 - INFO - Starting data loading and preprocessing...\n","INFO:BERTopic_Training:Starting data loading and preprocessing...\n","2025-03-19 19:50:48 - INFO - Loading and preprocessing dataset...\n","INFO:BERTopic_Training:Loading and preprocessing dataset...\n","2025-03-19 19:51:24 - INFO - Filtered corpus size: 216044\n","INFO:BERTopic_Training:Filtered corpus size: 216044\n","2025-03-19 19:51:24 - INFO - Time taken for loading and preprocessing: 35.63 seconds\n","INFO:BERTopic_Training:Time taken for loading and preprocessing: 35.63 seconds\n","Training Models:   0%|          | 0/10 [00:00<?, ?it/s]2025-03-19 19:58:05,523 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n","2025-03-19 19:58:39 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-mpnet-base-v2_Model_1_POS_a/topics_iter_1_POS_a.json\n","INFO:BERTopic_Training:Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-mpnet-base-v2_Model_1_POS_a/topics_iter_1_POS_a.json\n","2025-03-19 20:05:36,710 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n","2025-03-19 20:06:02 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-mpnet-base-v2_Model_1_POS_b/topics_iter_1_POS_b.json\n","INFO:BERTopic_Training:Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-mpnet-base-v2_Model_1_POS_b/topics_iter_1_POS_b.json\n","2025-03-19 20:12:59,704 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n","2025-03-19 20:13:23 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-mpnet-base-v2_Model_1_POS_c/topics_iter_1_POS_c.json\n","INFO:BERTopic_Training:Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-mpnet-base-v2_Model_1_POS_c/topics_iter_1_POS_c.json\n","Training Models:  10%|█         | 1/10 [21:59<3:17:57, 1319.76s/it]2025-03-19 20:17:42,876 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n","2025-03-19 20:18:00 - INFO - Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-MiniLM-L6-v2_Model_2_POS_a/topics_iter_1_POS_a.json\n","INFO:BERTopic_Training:Topics JSON saved to /content/drive/MyDrive/BERTTopic_Models_POS/paraphrase-MiniLM-L6-v2_Model_2_POS_a/topics_iter_1_POS_a.json\n","Training Models:  10%|█         | 1/10 [28:02<4:12:18, 1682.00s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-c20c5612c85c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-c20c5612c85c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m     \u001b[0mtrain_and_save_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-c20c5612c85c>\u001b[0m in \u001b[0;36mtrain_and_save_models\u001b[0;34m(corpus, params_df, embedding_models, stop_words)\u001b[0m\n\u001b[1;32m    411\u001b[0m                     \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                 )\n\u001b[0;32m--> 413\u001b[0;31m                 \u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error during training: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bertopic/_bertopic.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, documents, embeddings, images, y)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;31m# Reduce dimensionality and fit UMAP model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mumap_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reduce_dimensionality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;31m# Zero-shot Topic Modeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/bertopic/_bertopic.py\u001b[0m in \u001b[0;36m_reduce_dimensionality\u001b[0;34m(self, embeddings, y, partial_fit)\u001b[0m\n\u001b[1;32m   3774\u001b[0m                 \u001b[0;31m# cuml umap needs y to be an numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3775\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3776\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mumap_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3777\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3778\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mumap_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, force_all_finite, **kwargs)\u001b[0m\n\u001b[1;32m   2660\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rhos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_dists_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2662\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuzzy_simplicial_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2663\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36mfuzzy_simplicial_set\u001b[0;34m(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose, return_dists)\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mtranspose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0mprod_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         result = (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;34m\"\"\"Point-wise multiplication by another array/matrix.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_compressed.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_binopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_elmul_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"broadcast from a 1d array not yet supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_compressed.py\u001b[0m in \u001b[0;36m_binopt\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1310\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxnnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m         fn(self.shape[0], self.shape[1],\n\u001b[0m\u001b[1;32m   1313\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m            \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}