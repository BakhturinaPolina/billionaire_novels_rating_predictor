{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyOK78PxMHq45jyys6UMuMO9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**This code is designed to preprocess and analyze textual data from fanfiction using the BookNLP framework.**\n","\n","The primary goal is to prepare text data for advanced natural language processing tasks such as entity recognition, coreference resolution, event detection, and quote attribution.\n","\n","The code integrates BookNLP with custom pre-processing of machine learning models to enhance compatibility and performance.\n","\n","**The methodology involves three key steps:**\n","\n","    1. Model Preprocessing: Custom models are loaded, and unnecessary parameters like position IDs\n","    are removed to optimize their structure.\n","\n","    2. Text Processing: The script scans a designated directory for .txt files, assigns unique identifiers to each file,\n","    and sets up corresponding output directories for processed data.\n","    \n","    3. NLP Analysis: Each text file is analyzed by BookNLP, with outputs saved systematically for downstream analysis.\n","    The framework efficiently handles multiple files and ensures compatibility with GPU acceleration\n","    for improved processing speed."],"metadata":{"id":"MttDfnd_IpUN"}},{"cell_type":"code","source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8HCiGdExi2o0","executionInfo":{"status":"aborted","timestamp":1737820713261,"user_tz":-60,"elapsed":15,"user":{"displayName":"Polina Bakhturina","userId":"07881954271877753559"}},"outputId":"821ca7b9-4db3-4039-985a-49aacb28d8e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install booknlp\n","!python -m spacy download en_core_web_sm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"2ruo4D-P6hfr","executionInfo":{"status":"aborted","timestamp":1737820713261,"user_tz":-60,"elapsed":14,"user":{"displayName":"Polina Bakhturina","userId":"07881954271877753559"}},"outputId":"07143512-58e2-46ae-94b9-ab100595204e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: booknlp in /usr/local/lib/python3.11/dist-packages (1.0.8)\n","Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from booknlp) (2.5.1+cu121)\n","Requirement already satisfied: tensorflow>=1.15 in /usr/local/lib/python3.11/dist-packages (from booknlp) (2.17.1)\n","Requirement already satisfied: spacy>=3 in /usr/local/lib/python3.11/dist-packages (from booknlp) (3.7.5)\n","Requirement already satisfied: transformers>=4.11.3 in /usr/local/lib/python3.11/dist-packages (from booknlp) (4.47.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (0.15.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (4.67.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (2.10.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (3.1.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (75.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (3.5.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->booknlp) (1.26.4)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (25.1.21)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (3.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (4.25.5)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (1.69.0)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.15->booknlp) (0.37.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->booknlp) (3.17.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->booknlp) (3.4.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->booknlp) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->booknlp) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->booknlp) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->booknlp) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->booknlp) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->booknlp) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->booknlp) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->booknlp) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->booknlp) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->booknlp) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->booknlp) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->booknlp) (12.1.105)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->booknlp) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->booknlp) (1.13.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.1->booknlp) (12.6.85)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.1->booknlp) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.11.3->booknlp) (0.27.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.11.3->booknlp) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.11.3->booknlp) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.11.3->booknlp) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.11.3->booknlp) (0.5.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=1.15->booknlp) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow>=1.15->booknlp) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow>=1.15->booknlp) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow>=1.15->booknlp) (0.14.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->booknlp) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->booknlp) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->booknlp) (2.27.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->booknlp) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->booknlp) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->booknlp) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->booknlp) (2024.12.14)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.15->booknlp) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.15->booknlp) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.15->booknlp) (3.1.3)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->booknlp) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3->booknlp) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->booknlp) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->booknlp) (1.5.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->booknlp) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->booknlp) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy>=3->booknlp) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->booknlp) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow>=1.15->booknlp) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow>=1.15->booknlp) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow>=1.15->booknlp) (0.1.2)\n","Collecting en-core-web-sm==3.7.1\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.12.14)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["from booknlp.booknlp import BookNLP\n","from pathlib import Path\n","import os\n","import torch\n","\n","# Set up your input and output directories\n","# In this scenario, .txt files are stored directly in \"fanfiction project_texts\"\n","input_root = Path(\"/content/drive/MyDrive/fanfiction project_texts\")\n","output_root = Path(\"/content/drive/MyDrive/fanfiction project_texts/booknlp_outputs\")\n","output_root.mkdir(parents=True, exist_ok=True)\n","\n","def remove_position_ids_and_save(model_file, device, save_path):\n","    state_dict = torch.load(model_file, map_location=device)\n","    if 'bert.embeddings.position_ids' in state_dict:\n","        print(f'Removing \"position_ids\" from the state dictionary of {model_file}')\n","        del state_dict['bert.embeddings.position_ids']\n","    torch.save(state_dict, save_path)\n","    print(f'Modified state dict saved to {save_path}')\n","\n","def process_model_files(model_params, device):\n","    updated_params = {}\n","    for key, path in model_params.items():\n","        if isinstance(path, str) and os.path.isfile(path) and path.endswith('.model'):\n","            save_path = path.replace('.model', '_modified.model')\n","            remove_position_ids_and_save(path, device, save_path)\n","            updated_params[key] = save_path\n","        else:\n","            updated_params[key] = path\n","    return updated_params\n","\n","def process_books_with_booknlp(input_root, output_root):\n","    user_dir = Path.home()\n","\n","    # Set up model parameters with paths to BookNLP models\n","    model_params = {\n","        'pipeline': 'entity,quote,supersense,event,coref',\n","        'model': 'custom',\n","        'entity_model_path': f'{user_dir}/booknlp_models/entities_google_bert_uncased_L-6_H-768_A-12-v1.0.model',\n","        'coref_model_path': f'{user_dir}/booknlp_models/coref_google_bert_uncased_L-12_H-768_A-12-v1.0.model',\n","        'quote_attribution_model_path': f'{user_dir}/booknlp_models/speaker_google_bert_uncased_L-12_H-768_A-12-v1.0.1.model',\n","        'bert_model_path': f'{user_dir}/.cache/huggingface/hub/'\n","    }\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model_params = process_model_files(model_params, device)  # Modify model files if needed\n","\n","    # Initialize BookNLP\n","    booknlp = BookNLP('en', model_params)\n","\n","    # --- KEY CHANGE HERE ---\n","    # Instead of iterating over subfolders, we directly glob all *.txt files in input_root\n","    txt_files = list(input_root.glob(\"*.txt\"))\n","    if not txt_files:\n","        print(f\"No TXT files found directly under {input_root}\")\n","        return\n","\n","    for input_file in txt_files:\n","        # Only proceed if it's really a file\n","        if input_file.is_file():\n","            # Create a book ID from the file name\n","            book_id = input_file.stem.replace(' ', '_')\n","\n","            # Create an output folder per text file\n","            book_output_dir = output_root / f\"{book_id}_BookNLP_output\"\n","            book_output_dir.mkdir(parents=True, exist_ok=True)\n","\n","            # Process each .txt file with BookNLP\n","            try:\n","                print(f\"Processing {input_file} with BookNLP...\")\n","                booknlp.process(input_file, book_output_dir, book_id)\n","                print(f\"Processed {input_file}; output saved in {book_output_dir}\")\n","            except Exception as e:\n","                print(f\"Error processing {input_file}: {e}\")\n","\n","# Run the processing function\n","process_books_with_booknlp(input_root, output_root)"],"metadata":{"id":"-BXo5gno_tKM","executionInfo":{"status":"aborted","timestamp":1737820713262,"user_tz":-60,"elapsed":18,"user":{"displayName":"Polina Bakhturina","userId":"07881954271877753559"}},"collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# The same code with added part for parsing books in EPUB format and turning them in TXT format before processing texts with BookNLP pipeline (since BookNLP is not working with any text formats exept TXT)"],"metadata":{"id":"kaS9gYmgGLuz"}},{"cell_type":"code","source":["! pip install ebooklib\n","! pip install beautifulsoup4\n","\n","import os\n","from pathlib import Path\n","from ebooklib import epub\n","from ebooklib import ITEM_DOCUMENT\n","from bs4 import BeautifulSoup\n","\n","def convert_epub_to_txt(epub_path, txt_output_folder):\n","    \"\"\"\n","    Converts an EPUB file to a TXT file and saves it to a specified output folder.\n","    Args:\n","        epub_path (str): Path to the EPUB file.\n","        txt_output_folder (str): Directory where the converted TXT file will be saved.\n","    \"\"\"\n","    # Load the EPUB file\n","    book = epub.read_epub(epub_path)\n","    text_content = []\n","\n","    # Extract text from each document in the EPUB file\n","    for item in book.get_items():\n","        if item.get_type() == ITEM_DOCUMENT:\n","            # Parse HTML content and extract text\n","            soup = BeautifulSoup(item.get_body_content(), 'html.parser')\n","            text_content.append(soup.get_text())\n","\n","    # Join all extracted text into a single string\n","    full_text = '\\n'.join(text_content)\n","\n","    # Write the text to a .txt file\n","    book_name = Path(epub_path).stem  # Get book name without extension\n","    os.makedirs(txt_output_folder, exist_ok=True)  # Create the book-specific output directory\n","    txt_file_path = os.path.join(txt_output_folder, f\"{book_name}.txt\")\n","\n","    with open(txt_file_path, 'w', encoding='utf-8') as f:\n","        f.write(full_text)\n","\n","    print(f\"Converted {epub_path} to {txt_file_path}\")\n","\n","def convert_all_epubs_to_txt(input_root, txt_output_root):\n","    \"\"\"\n","    Converts all EPUB files in a root directory to TXT files, saving each as specified.\n","    Args:\n","        input_root (str): Root directory containing EPUB files to convert.\n","        txt_output_root (str): Root directory to store the converted TXT files.\n","    \"\"\"\n","    for epub_path in Path(input_root).rglob(\"*.epub\"):  # Find all .epub files recursively\n","        book_name = epub_path.stem  # Use the EPUB file name without extension\n","        book_output_folder = os.path.join(txt_output_root, book_name)  # Create a subfolder for each book\n","        convert_epub_to_txt(epub_path, book_output_folder)  # Convert and save to book-specific folder\n","\n","if __name__ == \"__main__\":\n","    # Input root directory containing EPUB files\n","    input_root = '/content/drive/MyDrive/full_list_of_romantic_novels'\n","    # Output root directory where TXT files will be saved\n","    txt_output_root = os.path.join(input_root, \"txt_books\")\n","\n","    # Ensure the root output directory exists\n","    os.makedirs(txt_output_root, exist_ok=True)\n","\n","    # Convert all EPUB files to TXT and store in the organized structure\n","    convert_all_epubs_to_txt(input_root, txt_output_root)"],"metadata":{"collapsed":true,"id":"e3v6Fc-Hnx0v","executionInfo":{"status":"aborted","timestamp":1737820713262,"user_tz":-60,"elapsed":17,"user":{"displayName":"Polina Bakhturina","userId":"07881954271877753559"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from booknlp.booknlp import BookNLP\n","from pathlib import Path\n","import os\n","import torch\n","\n","# Set up your input and output directories here\n","#input_root = Path(\"/content/drive/MyDrive/full_list_of_romantic_novels/txt_books\")\n","#output_root = Path(\"/content/drive/MyDrive/full_list_of_romantic_novels/booknlp_outputs\")\n","#output_root.mkdir(parents=True, exist_ok=True)\n","\n","input_root = Path(\"/content/drive/MyDrive/fanfiction project_texts\")\n","output_root = Path(\"/content/drive/MyDrive/fanfiction project_texts\")\n","output_root.mkdir(parents=True, exist_ok=True)\n","\n","\n","def remove_position_ids_and_save(model_file, device, save_path):\n","    state_dict = torch.load(model_file, map_location=device)\n","    if 'bert.embeddings.position_ids' in state_dict:\n","        print(f'Removing \"position_ids\" from the state dictionary of {model_file}')\n","        del state_dict['bert.embeddings.position_ids']\n","    torch.save(state_dict, save_path)\n","    print(f'Modified state dict saved to {save_path}')\n","\n","def process_model_files(model_params, device):\n","    updated_params = {}\n","    for key, path in model_params.items():\n","        if isinstance(path, str) and os.path.isfile(path) and path.endswith('.model'):\n","            save_path = path.replace('.model', '_modified.model')\n","            remove_position_ids_and_save(path, device, save_path)\n","            updated_params[key] = save_path\n","        else:\n","            updated_params[key] = path\n","    return updated_params\n","\n","def process_books_with_booknlp(input_root, output_root):\n","    user_dir = Path.home()\n","\n","    # Set up model parameters with paths to BookNLP models\n","    model_params = {\n","        'pipeline': 'entity,quote,supersense,event,coref',\n","        'model': 'custom',\n","        'entity_model_path': f'{user_dir}/booknlp_models/entities_google_bert_uncased_L-6_H-768_A-12-v1.0.model',\n","        'coref_model_path': f'{user_dir}/booknlp_models/coref_google_bert_uncased_L-12_H-768_A-12-v1.0.model',\n","        'quote_attribution_model_path': f'{user_dir}/booknlp_models/speaker_google_bert_uncased_L-12_H-768_A-12-v1.0.1.model',\n","        'bert_model_path': f'{user_dir}/.cache/huggingface/hub/'\n","    }\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model_params = process_model_files(model_params, device)  # Modify model files if needed\n","\n","    # Initialize BookNLP\n","    booknlp = BookNLP('en', model_params)\n","\n","    # Iterate through each book folder in the input root directory\n","    for book_folder in input_root.iterdir():\n","        if book_folder.is_dir():\n","            # Find the TXT file in the book's folder\n","            txt_files = list(book_folder.glob(\"*.txt\"))\n","            if not txt_files:\n","                print(f\"No TXT file found in {book_folder}, skipping.\")\n","                continue\n","\n","            # Use the first TXT file found (assuming only one per folder)\n","            input_file = txt_files[0]\n","            book_id = input_file.stem.replace(' ', '_')\n","\n","            # Set up the output directory for the book\n","            book_output_dir = output_root / f\"{book_folder.name}_BookNLP_output\"\n","            book_output_dir.mkdir(parents=True, exist_ok=True)\n","\n","            # Process the book with BookNLP\n","            try:\n","                print(f\"Processing {input_file} with BookNLP...\")\n","                booknlp.process(input_file, book_output_dir, book_id)\n","                print(f\"Processed {input_file} with BookNLP; output saved in {book_output_dir}\")\n","            except Exception as e:\n","                print(f\"Error processing {input_file}: {e}\")\n","\n","# Run the processing function\n","process_books_with_booknlp(input_root, output_root)"],"metadata":{"id":"AsRj-tlVzd48","collapsed":true},"execution_count":null,"outputs":[]}]}